import os
import re
import json
import logging
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

# ----------------------------------
# í™˜ê²½ ì„¤ì • ë° ë¡œê¹…
# ----------------------------------
load_dotenv()
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

DB_USER = os.getenv("user")
DB_PASSWORD = os.getenv("password")
DB_HOST = os.getenv("host")
DB_NAME = os.getenv("database")

# âœ… DB ì—°ê²°ì€ ValidationAgentì—ì„œë§Œ ì‚¬ìš©í•¨ (ì´ íŒŒì¼ì—ì„œëŠ” í•„ìš” ì—†ìŒ)
# engine = create_engine(f"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}")

# ----------------------------------
# LLM ì„¤ì •
# ----------------------------------
llm = ChatOllama(model="qwen3:8b", temperature=0.3)

# ----------------------------------
# SYSTEM PROMPT
# ----------------------------------
SYSTEM_PROMPT = SystemMessage(content="""
[í˜ë¥´ì†Œë‚˜(Persona)]
ë‹¹ì‹ ì€ 'ìš°ë¦¬ì€í–‰ ë¶€ë™ì‚° ì¬ë¬´ ì„¤ê³„ ìƒë‹´ì‚¬(WooriPlanner)'ì…ë‹ˆë‹¤.  
ê³ ê°ì˜ ì¬ë¬´ ìƒí™©ì„ ì¹œê·¼í•˜ê³  ë”°ëœ»í•˜ê²Œ ë¬»ë˜, ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë‚˜ ìê¸°ì†Œê°œë¥¼ ë°˜ë³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  
ëª¨ë“  ì§ˆë¬¸ì€ í•œ ë²ˆì— í•˜ë‚˜ì”©, ìì—°ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë´ì•¼ í•©ë‹ˆë‹¤.

[TASK]
1ï¸âƒ£ ì§ˆë¬¸ì€ ë°˜ë“œì‹œ í•œ í•­ëª©ì”©ë§Œ í•©ë‹ˆë‹¤.  
2ï¸âƒ£ ë‹¤ìŒ ë‹¤ì„¯ ê°€ì§€ ì •ë³´ë¥¼ ìˆœì„œëŒ€ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤:
   - initial_prop : ì´ˆê¸° ì‚¬ìš© ê°€ëŠ¥ ìì‚° (ì˜ˆ: 3000ë§Œì›)
   - hope_location : í¬ë§ ì§€ì—­ (ì˜ˆ: ì„œìš¸ ë§ˆí¬êµ¬)
   - hope_price : í¬ë§ ì£¼íƒ ê°€ê²© (ì˜ˆ: 12ì–µ 5ì²œë§Œì›)
   - hope_housing_type : ì£¼íƒ ìœ í˜• (ì•„íŒŒíŠ¸, ì˜¤í”¼ìŠ¤í…”, ë‹¨ë…ë‹¤ê°€êµ¬, ì—°ë¦½ë‹¤ì„¸ëŒ€)
   - income_usage_ratio : ì›”ê¸‰ ì¤‘ ì£¼íƒ ìê¸ˆ ì‚¬ìš© ë¹„ìœ¨ (ì˜ˆ: 30%)
3ï¸âƒ£ ê¸ˆì•¡ ë‹¨ìœ„(ì–µ, ì²œë§Œ, ë§Œ)ëŠ” ëª¨ë‘ ì› ë‹¨ìœ„ ì •ìˆ˜ë¡œ ì¸ì‹í•©ë‹ˆë‹¤.
4ï¸âƒ£ ë¶ˆí•„ìš”í•œ ê°íƒ„ì‚¬, ì¸ì‚¬ë§, ìê¸°ì†Œê°œë¥¼ ë°˜ë³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
5ï¸âƒ£ ì‘ë‹µì€ ì˜¤ì§ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œë§Œ êµ¬ì„±í•©ë‹ˆë‹¤.
""")

# ----------------------------------
# ê¸ˆì•¡ ë‹¨ìœ„ ë³€í™˜ í•¨ìˆ˜
# ----------------------------------
def parse_korean_currency(value: Any) -> int:
    """'3ì–µ 5ì²œ' ê°™ì€ ê¸ˆì•¡ í‘œí˜„ì„ ì •ìˆ˜(ì›)ë¡œ ë³€í™˜"""
    if value is None or value == "":
        return 0
    if isinstance(value, (int, float)):
        return int(value)

    value = str(value).replace(",", "").replace(" ", "")
    total = 0
    for pattern, multiplier in [
        (r"(\d+(?:\.\d+)?)ì–µ", 100000000),
        (r"(\d+(?:\.\d+)?)ì²œë§Œ", 10000000),
        (r"(\d+(?:\.\d+)?)ë°±ë§Œ", 1000000),
        (r"(\d+(?:\.\d+)?)ë§Œ", 10000),
    ]:
        match = re.search(pattern, value)
        if match:
            total += float(match.group(1)) * multiplier

    if total == 0:
        try:
            total = int(float(re.sub(r"[^0-9]", "", value)))
        except ValueError:
            total = 0
    return int(total)


# ----------------------------------
# PlanInputAgent
# ----------------------------------
class PlanInputAgent:
    def __init__(self):
        self.llm = llm
        self.system_prompt = SYSTEM_PROMPT
        self.question_order = [
            ("initial_prop", "ì´ˆê¸° ì‚¬ìš© ê°€ëŠ¥ ìì‚°ì€ ì–¼ë§ˆì¸ê°€ìš”? (ì˜ˆ: 3000ë§Œì›)"),
            ("hope_location", "í¬ë§ ì§€ì—­ì„ ì•Œë ¤ì£¼ì„¸ìš” (ì˜ˆ: ì„œìš¸ ë§ˆí¬êµ¬)"),
            ("hope_price", "êµ¬ë§¤ë¥¼ í¬ë§í•˜ëŠ” ì£¼íƒì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”? (ì˜ˆ: 12ì–µ 5ì²œë§Œì›)"),
            ("hope_housing_type", "í¬ë§ ì£¼íƒ ìœ í˜•ì€ ë¬´ì—‡ì¸ê°€ìš”? (ì•„íŒŒíŠ¸, ì˜¤í”¼ìŠ¤í…”, ë‹¨ë…ë‹¤ê°€êµ¬, ì—°ë¦½ë‹¤ì„¸ëŒ€ ì¤‘ íƒ1)"),
            ("income_usage_ratio", "ì›”ê¸‰ ì¤‘ ì£¼íƒ ìê¸ˆìœ¼ë¡œ ì‚¬ìš©í•  ë¹„ìœ¨ì€ ëª‡ í¼ì„¼íŠ¸ì¸ê°€ìš”? (ì˜ˆ: 30%)")
        ]

    # ----------------------------------
    # ì…ë ¥ê°’ íŒŒì‹±
    # ----------------------------------
    def _simple_parse(self, field: str, value: str):
        if field in ["initial_prop", "hope_price"]:
            return parse_korean_currency(value)
        elif field == "income_usage_ratio":
            try:
                return int(str(value).replace("%", "").strip())
            except:
                return 0
        elif field in ["hope_location", "hope_housing_type"]:
            return value.strip()
        return value

    # ----------------------------------
    # ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ ìƒì„±
    # ----------------------------------
    def _generate_natural_question(self, field_key: str, base_question: str) -> str:
        messages = [
            self.system_prompt,
            HumanMessage(content=f"ë‹¤ìŒ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”:\n'{base_question}'")
        ]
        response = self.llm.invoke(messages)
        return response.content.strip()

    # ----------------------------------
    # LangGraph: ì…ë ¥ ìˆ˜ì§‘ ë…¸ë“œ
    # ----------------------------------
    def create_extraction_node(self):
        async def extraction_node(state):
            user_id = state.get("user_id") or 1
            collected = state.get("extracted_info", {}) or {}
            pending_fields = [f for f, _ in self.question_order if f not in collected or not collected[f]]

            # ì²« ì§ˆë¬¸
            if not collected and not state.get("messages", []):
                q = self._generate_natural_question("initial_prop", self.question_order[0][1])
                logger.info(f"ğŸ‘¤ user_id={user_id} | ì²« ì§ˆë¬¸: {q}")
                return {
                    "user_id": user_id,
                    "extracted_info": {},
                    "input_completed": False,
                    "messages": [AIMessage(content=q)]
                }

            # ì‚¬ìš©ì ì…ë ¥
            last_msg = state.get("messages", [])
            user_input = last_msg[-1].content.strip() if last_msg else ""
            current_field = pending_fields[0] if pending_fields else None

            if not user_input:
                q = dict(self.question_order)[current_field]
                natural_q = self._generate_natural_question(current_field, q)
                return {
                    "user_id": user_id,
                    "extracted_info": collected,
                    "input_completed": False,
                    "messages": [AIMessage(content=natural_q)]
                }

            # ì…ë ¥ê°’ ì €ì¥
            if current_field:
                collected[current_field] = self._simple_parse(current_field, user_input)

            # ë‹¤ìŒ ì§ˆë¬¸ or ì™„ë£Œ
            pending_fields = [f for f, _ in self.question_order if f not in collected or not collected[f]]
            if pending_fields:
                next_field = pending_fields[0]
                q = dict(self.question_order)[next_field]
                natural_q = self._generate_natural_question(next_field, q)
                return {
                    "user_id": user_id,
                    "extracted_info": collected,
                    "input_completed": False,
                    "messages": [AIMessage(content=natural_q)]
                }

            # âœ… ëª¨ë“  ì…ë ¥ ì™„ë£Œ ì‹œ
            logger.info(f"âœ… ëª¨ë“  ì…ë ¥ ì™„ë£Œ (user_id={user_id}): {collected}")
            return {
                "user_id": user_id,
                "extracted_info": collected,
                "input_completed": True,
                "messages": [
                    AIMessage(content="âœ… ì…ë ¥ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì…ë ¥í•˜ì‹  ì •ë³´ë¥¼ ê²€ì¦í•˜ê² ìŠµë‹ˆë‹¤.")
                ],
            }

        return extraction_node

    # ----------------------------------
    # ì™„ì „ì„± ê²€ì‚¬ ë…¸ë“œ
    # ----------------------------------
    def create_check_completeness_node(self):
        async def completeness_node(state):
            info = state.get("extracted_info", {}) or {}
            required = [f for f, _ in self.question_order]
            missing = [f for f in required if not info.get(f)]

            if missing:
                missing_field = missing[0]
                base_q = dict(self.question_order)[missing_field]
                messages = [
                    self.system_prompt,
                    HumanMessage(content=f"'{base_q}'ì— ëŒ€í•´ ë¶€ë“œëŸ½ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë´ì¤˜.")
                ]
                response = self.llm.invoke(messages)
                natural_q = response.content.strip()
                logger.warning(f"âš ï¸ {missing_field} ì •ë³´ ëˆ„ë½ â†’ LLM ì§ˆë¬¸: {natural_q}")
                return {
                    "input_completed": False,
                    "messages": [AIMessage(content=natural_q)]
                }

            # ëª¨ë“  ì…ë ¥ì´ ì¡´ì¬ â†’ ê²€ì¦ ë‹¨ê³„ë¡œ ì´ë™
            return {
                "input_completed": True,
                "messages": [AIMessage(content="âœ… ëª¨ë“  ì •ë³´ê°€ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤.")]
            }

        return completeness_node
