from abc import ABC, abstractmethod
import asyncio
import json
import re
from datetime import datetime
from typing import Any, Dict, Optional, List
from enum import Enum

from agents.config.base_config import (
    BaseAgentConfig,
    AgentState,
    StateBuilder,
    StateValidator,
    ExecutionStatus
)

from agents.base.agent_base_prompts import DECISION_PROMPT
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage

from core.mcp.mcp_manager import MCPManager
from core.logging.logger import setup_logger
from core.llm.llm_manger import LLMHelper

logger = setup_logger()


# =============================
# Agent ê´€ë ¨ í´ë˜ìŠ¤
# =============================

class AgentAction(Enum):
    """Agentê°€ ì·¨í•  ìˆ˜ ìˆëŠ” í–‰ë™ íƒ€ì…"""
    USE_TOOL = "use_tool"
    RESPOND = "respond"
    DELEGATE = "delegate"  # âœ… ìƒˆë¡œ ì¶”ê°€: ë‹¤ë¥¸ Agentë¡œ ìœ„ì„


class AgentDecision:
    """Agentì˜ ì˜ì‚¬ê²°ì • ê²°ê³¼"""
    def __init__(
        self,
        action: AgentAction,
        reasoning: str,
        tool_name: Optional[str] = None,
        tool_arguments: Optional[Dict] = None,
        tool_use_id: Optional[str] = None,  # â­ Bedrock toolUseId
        next_agent: Optional[str] = None,
        response_text: Optional[str] = None  # â­ end_turn ì‹œ LLM ì‘ë‹µ
    ):
        self.action = action
        self.reasoning = reasoning
        self.tool_name = tool_name
        self.tool_arguments = tool_arguments or {}
        self.tool_use_id = tool_use_id  # â­ ì¶”ê°€
        self.next_agent = next_agent
        self.response_text = response_text  # â­ ì¶”ê°€


class AgentBase(ABC):
    """
    ë©€í‹°í„´ Tool í˜¸ì¶œì„ ì§€ì›í•˜ëŠ” Agent ë² ì´ìŠ¤ í´ë˜ìŠ¤
    
    í•µì‹¬ ì„¤ê³„:
    - LLMHelperë¥¼ í†µí•œ Ollama Chat API ì§ì ‘ í˜¸ì¶œ
    - LangChain ë©”ì‹œì§€ëŠ” LangGraph í˜¸í™˜ì„ ìœ„í•´ ìœ ì§€
    - LLM í˜¸ì¶œ ì‹œì—ë§Œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©
    - Agentë³„ LLM ì„¤ì • ì§€ì›
    - DELEGATE ì•¡ì…˜ìœ¼ë¡œ ë‹¤ë¥¸ Agentì—ê²Œ ì‘ì—… ìœ„ì„ ê°€ëŠ¥
    """

    def __init__(self, config: BaseAgentConfig):
        self.name = config.name
        self.config = config
        self.mcp = MCPManager().get_instance()
        
        # âœ… agents.yaml ì„¤ì • ìš°ì„  ì ìš©
        from agents.config.agent_config_loader import AgentConfigLoader
        
        yaml_config = AgentConfigLoader.get_agent_config_from_current(self.name)
        
        if yaml_config:
            # agents.yaml ì„¤ì •ì´ ìˆìœ¼ë©´ ìš°ì„  ì ìš©
            self.max_iterations = yaml_config.max_iterations
            self.config.max_retries = yaml_config.max_retries
            self.config.timeout = yaml_config.timeout
            self.config.tags = yaml_config.tags
            
            # LLM ì„¤ì • ë³‘í•© (agents.yaml > BaseAgentConfig > ì „ì—­ ì„¤ì •)
            if yaml_config.llm_config:
                # agents.yamlì˜ llm_configë¥¼ ìš°ì„  ì ìš©
                merged_llm = {**config.get_llm_config_dict(), **yaml_config.llm_config}
                self.llm_config = merged_llm
            else:
                self.llm_config = config.get_llm_config_dict()
            
            logger.info(f"[{self.name}] âœ… Applied agents.yaml config:")
            logger.info(f"   max_retries: {self.config.max_retries}")
            logger.info(f"   timeout: {self.config.timeout}")
            logger.info(f"   max_iterations: {self.max_iterations}")
            logger.info(f"   tags: {self.config.tags}")
        else:
            # agents.yaml ì„¤ì •ì´ ì—†ìœ¼ë©´ BaseAgentConfig ì‚¬ìš©
            self.max_iterations = config.max_iterations
            self.llm_config = config.get_llm_config_dict()
            logger.info(f"[{self.name}] Using BaseAgentConfig defaults")
        
        logger.info(f"[{self.name}] Agent initialized")
        logger.info(f"[{self.name}] LLM config: {self.llm_config if self.llm_config else 'Using global settings'}")
        
        self._validate_config()

    # =============================
    # LLM í˜¸ì¶œ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _langchain_to_dict(self, message) -> Dict[str, Any]:
        """LangChain ë©”ì‹œì§€ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        
        Args:
            message: LangChain ë©”ì‹œì§€ ê°ì²´
            
        Returns:
            Dict[str, Any]: {"role": role, "content": content, ...} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        if isinstance(message, HumanMessage):
            return {"role": "user", "content": message.content}
        elif isinstance(message, AIMessage):
            return {"role": "assistant", "content": message.content}
        elif isinstance(message, SystemMessage):
            return {"role": "system", "content": message.content}
        elif isinstance(message, ToolMessage):
            # ToolMessageëŠ” tool_call_idë„ í•¨ê»˜ ì „ë‹¬í•´ì•¼ í•¨
            result = {"role": "tool", "content": message.content}
            if hasattr(message, 'tool_call_id') and message.tool_call_id:
                result["tool_call_id"] = message.tool_call_id
            return result
        else:
            return {"role": "user", "content": str(message)}
    
    def _convert_messages_to_dict(self, messages: List) -> List[Dict[str, str]]:
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ì¼ê´„ ë³€í™˜
        
        Args:
            messages: LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[Dict[str, str]]: ë³€í™˜ëœ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        return [self._langchain_to_dict(msg) for msg in messages]
        
    # =============================
    # Message í¬ë§·íŒ… ë° LLM í˜¸ì¶œ (Debugìš©)
    # =============================
    def _pretty_messages(self, messages: List) -> str:
        """LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ë¬¸ìì—´ë¡œ ì˜ˆì˜ê²Œ ë³€í™˜
        
        Args:
            messages: LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            str: JSON í˜•íƒœì˜ ë¬¸ìì—´
        """
        converted = self._convert_messages_to_dict(messages)
        return json.dumps(converted, ensure_ascii=False, indent=2)

    def _prepare_llm_params(
        self,
        use_agent_config: bool = True,
        stream: Optional[bool] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """LLM í˜¸ì¶œ íŒŒë¼ë¯¸í„° ì¤€ë¹„
        
        Args:
            use_agent_config: Agent ì„¤ì • ì‚¬ìš© ì—¬ë¶€
            stream: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
            format: ì‘ë‹µ í¬ë§·
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
            
        Returns:
            Dict[str, Any]: ì¤€ë¹„ëœ LLM íŒŒë¼ë¯¸í„°
        """
        # Agent ì„¤ì • ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ê¸°ë³¸ê°’ ì„¤ì •
        if use_agent_config:
            llm_params = {**self.llm_config, **kwargs}
        else:
            llm_params = {**kwargs}
        
        # stream ëª…ì‹œì  ì²˜ë¦¬
        if stream is not None:
            llm_params["stream"] = stream
            
        return llm_params
    
    def _call_llm(
        self,
        messages: List,
        stream: Optional[bool] = None,
        **kwargs
    ) -> str:
        """LLM í˜¸ì¶œ (ë™ê¸° ë°©ì‹)
        
        ìš°ì„ ìˆœìœ„:
        1. ë©”ì„œë“œ í˜¸ì¶œ ì‹œ ì „ë‹¬ëœ kwargs
        2. Agentë³„ llm_config
        3. ì „ì—­ ì„¤ì • (LLMHelper ê¸°ë³¸ê°’)
        
        Args:
            messages: LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            stream: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
            **kwargs: ì¶”ê°€ LLM íŒŒë¼ë¯¸í„°
            
        Returns:
            str: LLM ì‘ë‹µ
        """
        llm_params = self._prepare_llm_params(
            use_agent_config=True,
            stream=stream,
            **kwargs
        )
        
        logger.debug(f"[{self.name}] LLM Call Parameters: {llm_params}")
        
        # LangChain ë©”ì‹œì§€ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        formatted_messages = self._convert_messages_to_dict(messages)
        
        return LLMHelper.invoke_with_history(
            history=formatted_messages,
            **llm_params
        )
        


    # =============================
    # ìƒíƒœ ê´€ë¦¬ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _add_message_to_state(self, state: AgentState, message) -> AgentState:
        """ìƒíƒœì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ê³  global_messages ì—…ë°ì´íŠ¸
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            message: ì¶”ê°€í•  LangChain ë©”ì‹œì§€
            
        Returns:
            AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        global_messages = state.get("global_messages", [])
        global_messages.append(message)
        state["global_messages"] = global_messages
        return state

    # =============================
    # ë©€í‹°í„´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
    # =============================
    
    async def run(self, state: AgentState) -> AgentState:
        """Agent ì‹¤í–‰ ë©”ì¸ í”Œë¡œìš°"""
        self._log_start(state)

        if not self.validate_input(state):
            error = ValueError(f"Invalid input for {self.name}")
            state = StateBuilder.add_error(state, error, self.name)
            state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
            return state
        
        # Agent ì§„ì… ì‹œ iteration ì´ˆê¸°í™”
        state["iteration"] = 0
        logger.info(f"[{self.name}] Iteration reset to 0 for this agent")

        state = self.pre_execute(state)

        for attempt in range(1, self.config.max_retries + 1):
            try:
                async with asyncio.timeout(self.config.timeout):
                    result = await self.execute_multi_turn(state)
                break
                
            except asyncio.TimeoutError:
                error_msg = f"Timeout after {self.config.timeout} seconds"
                logger.warning(f"[{self.name}] attempt {attempt} failed: {error_msg}")
                
                if attempt == self.config.max_retries:
                    error = TimeoutError(f"{self.name} execution timed out")
                    state = StateBuilder.add_error(state, error, self.name)
                    state = StateBuilder.finalize_state(state, ExecutionStatus.TIMEOUT)
                    return state
                
                await asyncio.sleep(1.5 * attempt)
                
            except Exception as e:
                logger.warning(f"[{self.name}] attempt {attempt} failed: {e}")
                
                if attempt == self.config.max_retries:
                    state = StateBuilder.add_error(state, e, self.name)
                    state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
                    return state
                
                await asyncio.sleep(1.5 * attempt)

        self._log_end(result)
        return result

    # =============================
    # ë©€í‹°í„´ ì‹¤í–‰ ë¡œì§ (ReAct Loop)
    # =============================
    
    async def execute_multi_turn(self, state: AgentState) -> AgentState:
        """ë©€í‹°í„´ ì‹¤í–‰ í”Œë¡œìš° - global_messages ì‚¬ìš©"""
        
        # global_messages ì‚¬ìš© (ì—†ìœ¼ë©´ messagesë¡œ í´ë°±)
        global_messages = state.get("global_messages", [])
        if not global_messages:
            global_messages = state.get("messages", [])
            state["global_messages"] = global_messages
        
        logger.info(f"[{self.name}] Global messages count: {len(global_messages)}")
        
        # í˜„ì¬ ì—ì´ì „íŠ¸ì˜ ì—­í• ì„ SystemMessageë¡œ ë§¨ ì•ì— ì¶”ê°€
        agent_role = self.get_agent_role_prompt()
        system_msg = SystemMessage(content=agent_role)
        
        # ë§¨ ì•ì— SystemMessage ì‚½ì…
        global_messages = [system_msg] + global_messages
        state["global_messages"] = global_messages
        
        logger.info(f"[{self.name}] âœ… Added agent role as SystemMessage at the beginning")
        
        # MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ
        available_tools = await self._list_mcp_tools()
        logger.info(f"[{self.name}] MCP tools available: {len(available_tools)}")
                
        # Bedrock toolConfigë¡œ ë³€í™˜
        bedrock_tool_config = self._convert_mcp_to_bedrock_toolspec(available_tools)
        if bedrock_tool_config:
            state["bedrock_tool_config"] = bedrock_tool_config
            logger.info(f"[{self.name}] âœ… Bedrock toolConfig created with {len(bedrock_tool_config['tools'])} tools")
        else:
            logger.warning(f"[{self.name}] âš ï¸ No Bedrock toolConfig created")
        
        # ReAct Loop
        while not StateBuilder.is_max_iterations_reached(state):
            state = StateBuilder.increment_iteration(state)
            current_iteration = state.get("iteration", 0)
            
            logger.info(f"\n{'='*60}")
            logger.info(f"[{self.name}] Iteration {current_iteration}/{self.max_iterations}")
            logger.info(f"{'='*60}")
            
            # global_messagesë¥¼ ì‚¬ìš©
            global_messages = state.get("global_messages", [])
            
            # Bedrock native tool calling: 1ë‹¨ê³„ë¡œ í†µí•©
            # _analyze_request ì œê±° â†’ _make_decisionì—ì„œ stopReasonìœ¼ë¡œ íŒë‹¨
            try:
                logger.info("ğŸ¤” Making Decision (Bedrock native tool calling)\n" + self._pretty_messages(global_messages))
                decision = await self._make_decision(state, global_messages, available_tools)
                
                logger.info(f"ğŸ¤” Decision: {decision.action.value}")
                logger.info(f"   Reasoning: {decision.reasoning}")
                
            except Exception as e:
                logger.error(f"[{self.name}] Decision making failed: {e}")

                state = StateBuilder.add_error(state, e, self.name)
                break
            
            # Step 3: ì•¡ì…˜ ì‹¤í–‰
            if decision.action == AgentAction.USE_TOOL:
                state = await self._execute_tool_action(state, decision)
                continue
            
            elif decision.action == AgentAction.DELEGATE:
                return await self._execute_delegate_action(state, decision)
                
            elif decision.action == AgentAction.RESPOND:
                return await self._execute_respond_action(state, global_messages, available_tools, decision)
        
        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬
        return await self._handle_max_iterations(state, global_messages)
    
    # =============================
    # ì•¡ì…˜ ì‹¤í–‰ ë©”ì„œë“œ
    # =============================
    
    async def _execute_tool_action(
        self,
        state: AgentState,
        decision: AgentDecision
    ) -> AgentState:
        """Tool ì‹¤í–‰ ì•¡ì…˜ ì²˜ë¦¬
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            decision: Agent ì˜ì‚¬ê²°ì • ê²°ê³¼
            
        Returns:
            AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        logger.info(f"ğŸ”§ Executing tool: {decision.tool_name}")
        logger.info(f"   Arguments: {decision.tool_arguments}")
        
        try:
            tool_result = await self._execute_mcp_tool(
                decision.tool_name,
                decision.tool_arguments
            )
            
            state = StateBuilder.add_tool_call(
                state,
                tool_name=decision.tool_name,
                arguments=decision.tool_arguments,
                result=tool_result
            )
            
            # Tool ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”
            try:
                import json
                if isinstance(tool_result, dict):
                    result_content = json.dumps(tool_result)
                else:
                    result_content = str(tool_result)
            except:
                result_content = str(tool_result)
            
            # Bedrock native tool callingì¸ì§€ í™•ì¸
            if decision.tool_use_id:
                # Bedrock native: ToolMessage (toolResult ë¸”ë¡)
                tool_message = ToolMessage(
                    content=result_content,
                    tool_call_id=decision.tool_use_id
                )
                logger.debug(f"[{self.name}] Using Bedrock toolResult format (toolUseId: {decision.tool_use_id})")
            else:
                # JSON fallback: ì¼ë°˜ AIMessage
                tool_message = AIMessage(
                    content=f"Tool: {decision.tool_name}\nResult: {result_content}"
                )
                logger.debug(f"[{self.name}] Using text format (no toolUseId)")
            
            state = self._add_message_to_state(state, tool_message)
            logger.info(f"âœ… Tool executed successfully")
            
        except Exception as e:
            logger.error(f"[{self.name}] Tool execution failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
            
            # ì—ëŸ¬ ì²˜ë¦¬ë„ ë™ì¼í•˜ê²Œ
            if decision.tool_use_id:
                error_message = ToolMessage(
                    content=f"Error: {str(e)}",
                    tool_call_id=decision.tool_use_id
                )
            else:
                error_message = AIMessage(
                    content=f"Tool: {decision.tool_name}\nError: {str(e)}"
                )
            state = self._add_message_to_state(state, error_message)
        
        return state
    
    async def _execute_delegate_action(
        self,
        state: AgentState,
        decision: AgentDecision
    ) -> AgentState:
        """Delegate ì•¡ì…˜ ì²˜ë¦¬
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            decision: Agent ì˜ì‚¬ê²°ì • ê²°ê³¼
            
        Returns:
            AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        logger.info(f"ğŸ”€ Delegating to agent: {decision.next_agent}")
        logger.info(f"   Reason: {decision.reasoning}")
        
        # delegation ë©”íƒ€ë°ì´í„° ì„¤ì •
        state["previous_agent"] = self.name
        state["next_agent"] = decision.next_agent
        state["delegation_reason"] = decision.reasoning
        state["status"] = ExecutionStatus.RUNNING
        state["timestamp"] = datetime.now()
        
        global_messages = state.get("global_messages", [])
        logger.info(f"[{self.name}] Delegation: next_agent={state.get('next_agent')}, status={state.get('status')}")
        logger.info(f"[{self.name}] âœ… Full conversation history preserved ({len(global_messages)} messages)")
        
        return state
    
    async def _execute_respond_action(
        self,
        state: AgentState,
        global_messages: List,
        available_tools: List[str],
        decision: AgentDecision
    ) -> AgentState:
        """Respond ì•¡ì…˜ ì²˜ë¦¬
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            global_messages: ì „ì—­ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            available_tools: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡
            decision: Agent ì˜ì‚¬ê²°ì • ê²°ê³¼
            
        Returns:
            AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        logger.info("âœ… Generating final response")
        
        try:
            # end_turnìœ¼ë¡œ ì‘ë‹µì´ ì „ë‹¬ë¨
            final_response = decision.response_text
            
            if not final_response:
                logger.error(f"[{self.name}] No response_text in decision")
                raise ValueError("response_text is required for RESPOND action")
            
            logger.info(f"[{self.name}] Using response from end_turn (no additional LLM call)")
    
            state["last_result"] = final_response
            
            # ìµœì¢… ì‘ë‹µë„ global_messagesì— ì¶”ê°€
            state = self._add_message_to_state(state, AIMessage(content=final_response))
            
            state = StateBuilder.finalize_state(state, ExecutionStatus.SUCCESS)
            logger.info(f"[{self.name}] Total messages: {len(state['global_messages'])}")
            logger.info(f"ğŸ’¬ Final response generated ({len(final_response)} chars)")
            
        except Exception as e:
            logger.error(f"[{self.name}] Final response generation failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
            state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
        
        return state
    
    async def _handle_max_iterations(
        self,
        state: AgentState,
        global_messages: List
    ) -> AgentState:
        """ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ ì²˜ë¦¬
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            global_messages: ì „ì—­ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        logger.warning(f"âš ï¸ Max iterations ({self.max_iterations}) reached")
        
        try:
            fallback_response = await self._generate_fallback_response(global_messages)
            state = self._add_message_to_state(state, AIMessage(content=fallback_response))
            state["last_result"] = fallback_response
        except Exception as e:
            logger.error(f"[{self.name}] Fallback response generation failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
        
        state = StateBuilder.finalize_state(state, ExecutionStatus.MAX_ITERATIONS)
        return state


    # =============================
    # Agent React Function ë‹¨ê³„ë³„ ë©”ì„œë“œ
    # =============================
    

    
    async def _make_decision(
        self,
        state: AgentState,
        messages: List,
        available_tools: List[str],
    ) -> AgentDecision:
        """Agent ì˜ì‚¬ê²°ì • (Bedrock Native Tool Calling ì „ìš©)
        
        toolChoice="auto"ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì´ í•„ìš”í•  ë•Œë§Œ Toolì„ ì„ íƒí•©ë‹ˆë‹¤.
        JSON íŒŒì‹±ì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ 100% ì•ˆì •ì ì…ë‹ˆë‹¤.
        
        ì‚¬ìš© ê°€ëŠ¥í•œ Tool:
        - MCP Tools: ì‹¤ì œ ë°ì´í„° ì¡°íšŒ
        - delegate_to_agent: ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„
        
        stopReason ì²˜ë¦¬:
        - tool_use: Tool ì‹¤í–‰
        - end_turn: ìµœì¢… ì‘ë‹µ ìƒì„±
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            messages: LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            available_tools: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡
            
        Returns:
            AgentDecision: Agent ì˜ì‚¬ê²°ì • ê²°ê³¼
            
        Raises:
            Exception: ì˜ì‚¬ê²°ì • ì‹¤íŒ¨ ì‹œ
        """
        available_agents = self._get_available_agents()
        
        system_prompt = DECISION_PROMPT.format(
            name=self.name,
            available_agents=available_agents,
            available_tools=available_tools
        )
        
        try:
            logger.info(f"[{self.name}] ğŸ¤” Making decision with Bedrock Native Tool Calling")
        
            messages.append(HumanMessage(content=system_prompt))
            state["global_messages"] = messages
            
            # Stateì—ì„œ bedrock_tool_config ê°€ì ¸ì˜¤ê¸°
            bedrock_tool_config = state.get("bedrock_tool_config")
            
            if not bedrock_tool_config:
                raise Exception("bedrock_tool_config not found in state")
            
            # LLM í˜¸ì¶œ - toolConfig ì „ë‹¬, toolChoice="auto"ë¡œ ìë™ ì„ íƒ
            formatted_messages = self._convert_messages_to_dict(messages)
            
            from core.llm.llm_manger import LLMHelper
            response = await asyncio.to_thread(
                LLMHelper.invoke_with_history,
                history=formatted_messages,
                tool_config=bedrock_tool_config,
                tool_choice={"auto": {}},  
                return_full_response=True,
                temperature=0.1,
                top_p=0.1
            )
            
            # stopReason í™•ì¸
            stop_reason = response.get("stopReason")
            logger.info(f"[{self.name}] stopReason: {stop_reason}")
            
            # end_turn: ìµœì¢… ì‘ë‹µ ì¤€ë¹„ ì™„ë£Œ
            if stop_reason == "end_turn":
                # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                message = response.get("output", {}).get("message", {})
                content_blocks = message.get("content", [])
                
                response_text = ""
                for block in content_blocks:
                    if "text" in block:
                        response_text = block["text"]
                        break
                
                logger.info(f"[{self.name}] âœ… LLM ready to provide final response (end_turn)")
                logger.info(f"[{self.name}] Response preview: {response_text[:100]}...")
                
                return AgentDecision(
                    action=AgentAction.RESPOND,
                    reasoning="LLM decided to respond directly without using tools",
                    response_text=response_text
                )
            
            # tool_useê°€ ì•„ë‹ˆë©´ ì—ëŸ¬
            if stop_reason != "tool_use":
                logger.error(f"[{self.name}] Unexpected stopReason: {stop_reason}")
                raise Exception(f"Unexpected stopReason: '{stop_reason}'")
            
            # Tool ì‚¬ìš© ì •ë³´ ì¶”ì¶œ
            message = response["output"]["message"]
            content = message.get("content", [])

            # reasoningContent ë¸”ë¡ í•„í„°ë§ (Extended Thinking ëª¨ë¸ìš©)
            # toolUse, text, image ë“±ë§Œ ìœ ì§€
            filtered_content = [
                block for block in content 
                if not isinstance(block, dict) or "reasoningContent" not in block
            ]
            
            # í•„í„°ë§ í›„ contentê°€ ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
            if not filtered_content:
                filtered_content = content

            # assistant ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            # Bedrock native tool callingì—ì„œëŠ” contentë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì•¼ í•¨
            # _prepare_bedrock_messagesì—ì„œ ì´ë¥¼ ì ì ˆíˆ ë³€í™˜í•¨
            messages.append(AIMessage(content=filtered_content))

            state["global_messages"] = messages
            
            # toolUse ë¸”ë¡ ì°¾ê¸° (í•„í„°ë§ëœ content ì‚¬ìš©)
            for block in filtered_content:
                if "toolUse" in block:
                    tool_use = block["toolUse"]
                    tool_name = tool_use["name"]
                    tool_input = tool_use.get("input", {})
                    tool_use_id = tool_use["toolUseId"]
                    
                    logger.info(f"[{self.name}] ğŸ”§ Tool selected: {tool_name}")
                    logger.info(f"[{self.name}] ğŸ“‹ Tool input: {tool_input}")
                    
                    # delegate_to_agent Tool ê°ì§€
                    if tool_name == "delegate_to_agent":
                        agent_name = tool_input.get("agent_name")
                        reason = tool_input.get("reason", "")
                        
                        logger.info(f"[{self.name}] ğŸ”€ Delegating to: {agent_name}")
                        
                        return AgentDecision(
                            action=AgentAction.DELEGATE,
                            reasoning=reason,
                            next_agent=agent_name
                        )
                    
                    # finish_conversation Toolì€ ì œê±°ë¨ (end_turnìœ¼ë¡œ ëŒ€ì²´)
                    
                    # ì¼ë°˜ MCP Tool
                    else:
                        return AgentDecision(
                            action=AgentAction.USE_TOOL,
                            reasoning="Bedrock native tool calling",
                            tool_name=tool_name,
                            tool_arguments=tool_input,
                            tool_use_id=tool_use_id
                        )
            
            # toolUse ë¸”ë¡ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° (ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨)
            logger.error(f"[{self.name}] No toolUse block found in response")
            raise Exception("No toolUse block found despite stopReason='tool_use'")
                
        except Exception as e:
            logger.error(f"[{self.name}] Decision making failed: {e}")
            raise
    
    async def _generate_fallback_response(self, messages: List) -> str:
        """ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ í´ë°± ì‘ë‹µ ìƒì„±
        
        Args:
            messages: LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            str: í´ë°± ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        return f"""ì²˜ë¦¬ ê³¼ì •ì´ ì˜ˆìƒë³´ë‹¤ ë³µì¡í•˜ì—¬ {self.max_iterations}íšŒ ë°˜ë³µ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.
ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."""

    # =============================
    # êµ¬ì²´ì ì¸ Agentê°€ êµ¬í˜„í•´ì•¼ í•  ë©”ì„œë“œ
    # =============================
    
    @abstractmethod
    def get_agent_role_prompt(self) -> str:
        """Agent ì—­í•  ì •ì˜ Prompt ë°˜í™˜
        
        ê° AgentëŠ” ì´ ë©”ì„œë“œë¥¼ êµ¬í˜„í•˜ì—¬ ìì‹ ì˜ ì—­í• ì„ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.
        
        Returns:
            str: Agentì˜ ì—­í• ì„ ì„¤ëª…í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸
        """
        pass

    # =============================
    # ê³µí†µ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _get_available_agents(self) -> str:
        """í˜„ì¬ Agentì—ì„œ ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡ ë°˜í™˜
        
        allowed_agents ì†ì„±ì´ ìˆìœ¼ë©´ í•´ë‹¹ ëª©ë¡ì„ ì‚¬ìš©í•˜ê³ ,
        ì—†ìœ¼ë©´ ë“±ë¡ëœ ëª¨ë“  Agentë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        ìê¸° ìì‹ ì€ í•­ìƒ ëª©ë¡ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.
        
        Returns:
            str: ìœ„ì„ ê°€ëŠ¥í•œ Agent ëª©ë¡ì„ í¬í•¨í•˜ëŠ” í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
        """
        if hasattr(self, "allowed_agents"):
            # allowed_agentsê°€ ìˆì–´ë„ ìê¸° ìì‹ ì€ ë¬´ì¡°ê±´ ì œì™¸í•´ì•¼ í•¨
            agents = [name for name in self.allowed_agents if name != self.name]
        else:
            # ê¸°ë³¸: ëª¨ë“  ë“±ë¡ëœ Agent (ìì‹  ì œì™¸)
            from agents.registry.agent_registry import AgentRegistry
            all_agents = AgentRegistry.list_agents()
            agents = [name for name in all_agents if name != self.name]
            
        logger.info(f"{agents} available for delegation from {self.name}")
        
        if not agents:
            return f"""ì—†ìŒ (ì´ ì—ì´ì „íŠ¸ê°€ ëª¨ë“  ì‘ì—…ì„ ì§ì ‘ ì²˜ë¦¬í•´ì•¼ í•¨)

**ë‹¹ì‹ ì˜ ì •ì²´ì„±: {self.name}**
**ìœ„ì„ ë¶ˆê°€: ìê¸° ìì‹ ({self.name})ì—ê²ŒëŠ” ì ˆëŒ€ ìœ„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**"""
        
        # í¬ë§·íŒ…
        agent_list = "\n".join([f"- {agent}" for agent in agents])
        
        return f"""
[ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡]
{agent_list}

**ë‹¹ì‹ ì˜ ì •ì²´ì„±: {self.name}**
**ì£¼ì˜:** ìœ„ ëª©ë¡ì— ì—†ëŠ” Agent(íŠ¹íˆ ìê¸° ìì‹ ì¸ {self.name})ì—ê²ŒëŠ” ì ˆëŒ€ ìœ„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
"""
    
    def _get_available_agents_list(self) -> List[str]:
        """í˜„ì¬ Agentì—ì„œ ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        
        Bedrock toolSpecì˜ enumì— ì‚¬ìš©í•˜ê¸° ìœ„í•œ í—¬í¼ ë©”ì„œë“œ
        
        Returns:
            List[str]: ìœ„ì„ ê°€ëŠ¥í•œ Agent ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        if hasattr(self, "allowed_agents"):
            agents = [name for name in self.allowed_agents if name != self.name]
        else:
            from agents.registry.agent_registry import AgentRegistry
            all_agents = AgentRegistry.list_agents()
            agents = [name for name in all_agents if name != self.name]
        
        return agents
    
    async def _list_mcp_tools(self) -> List[Dict[str, Any]]:
        """MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ ë° í•„í„°ë§
        
        allowed_tools ì†ì„±ì„ í™•ì¸í•˜ì—¬ í—ˆìš©ëœ ë„êµ¬ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
        - 'ALL': ëª¨ë“  ë„êµ¬ í—ˆìš©
        - []: ë„êµ¬ ì—†ìŒ
        - [ë„êµ¬ëª… ëª©ë¡]: í•´ë‹¹ ë„êµ¬ë§Œ í—ˆìš©
        
        Returns:
            List[Dict[str, Any]]: ë„êµ¬ ëª…ì„¸ ë¦¬ìŠ¤íŠ¸ (function call í˜•ì‹)
        """
        try:
            tools = await self.mcp.list_tools()
            tools_spec = []
            
            if hasattr(self, "allowed_tools"):
                if self.allowed_tools == 'ALL':
                    pass  # ì „ì²´ íˆ´ í—ˆìš©
                elif len(self.allowed_tools) == 0:
                    tools = []  # íˆ´ ì—†ìŒ
                else:
                    tools = [t for t in tools if t.name in self.allowed_tools]

            for tool in tools:
                schema = tool.inputSchema or {}
                props = schema.get("properties", {})
                if not props:
                    continue
                tools_spec.append({
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "parameters": {
                            "type": schema.get("type", "object"),
                            "properties": {
                                k: {
                                    "type": p.get("type", "string"),
                                    "description": p.get("description", "")
                                } for k, p in props.items()
                            },
                            "required": schema.get("required", [])
                        },
                    },
                })
            logger.debug(f"[{self.name}] Retrieved {len(tools_spec)} tools")
            return tools_spec
        except Exception as e:
            logger.error(f"[{self.name}] Failed to list MCP tools: {e}")
            return []
    
    def _convert_mcp_to_bedrock_toolspec(
        self,
        mcp_tools: List[Dict[str, Any]]
    ) -> Optional[Dict]:
        """
        MCP tool specì„ Bedrock toolConfig í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³ ,
        delegate_to_agentì™€ finish_conversation Tool ì¶”ê°€
        
        MCPëŠ” OpenAI function call í˜•ì‹:
        {
            "type": "function",
            "function": {
                "name": "get_user",
                "description": "...",
                "parameters": {
                    "type": "object",
                    "properties": {...},
                    "required": [...]
                }
            }
        }
        
        BedrockëŠ” toolSpec í˜•ì‹:
        {
            "tools": [
                {
                    "toolSpec": {
                        "name": "get_user",
                        "description": "...",
                        "inputSchema": {
                            "json": {...}  # MCP parameters ê·¸ëŒ€ë¡œ
                        }
                    }
                }
            ]
        }
        
        Args:
            mcp_tools: _list_mcp_tools()ì—ì„œ ë°˜í™˜ëœ tool ëª©ë¡
            
        Returns:
            Bedrock toolConfig ë”•ì…”ë„ˆë¦¬
        """
        bedrock_tools = []
        
        # 1. MCP Tools ë³€í™˜
        if mcp_tools:
            for tool in mcp_tools:
                func = tool.get("function", {})
                params = func.get("parameters", {})
                
                # descriptionì´ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆ ë˜ë¯€ë¡œ ê¸°ë³¸ê°’ ì œê³µ
                description = func.get("description", "").strip()
                if not description:
                    description = f"MCP tool: {func.get('name', 'unknown')}"
                
                bedrock_tools.append({
                    "toolSpec": {
                        "name": func.get("name"),
                        "description": description,
                        "inputSchema": {
                            "json": params
                        }
                    }
                })
        
        # 2. delegate_to_agent Tool ì¶”ê°€
        available_agents = self._get_available_agents_list()
        if available_agents:
            bedrock_tools.append({
                "toolSpec": {
                    "name": "delegate_to_agent",
                    "description": "ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—…ì„ ìœ„ì„í•©ë‹ˆë‹¤. í˜„ì¬ ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•  ìˆ˜ ì—†ê±°ë‚˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì „ë¬¸ì„±ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©í•©ë‹ˆë‹¤.",
                    "inputSchema": {
                        "json": {
                            "type": "object",
                            "properties": {
                                "agent_name": {
                                    "type": "string",
                                    "description": f"ìœ„ì„í•  ì—ì´ì „íŠ¸ ì´ë¦„. ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸: {', '.join(available_agents)}",
                                    "enum": available_agents
                                },
                                "reason": {
                                    "type": "string",
                                    "description": "ìœ„ì„ ì´ìœ  ë° ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸"
                                }
                            },
                            "required": ["agent_name", "reason"]
                        }
                    }
                }
            })
        
        logger.info(f"[{self.name}] âœ… Created Bedrock toolConfig: {len(bedrock_tools)} tools (MCP: {len(mcp_tools) if mcp_tools else 0}, delegate: {1 if available_agents else 0})")
        
        return {
            "tools": bedrock_tools
        }

    async def _execute_mcp_tool(
        self,
        tool_name: str,
        tool_args: Dict[str, Any]
    ) -> Any:
        """MCP ë„êµ¬ ì‹¤í–‰
        
        Args:
            tool_name: ì‹¤í–‰í•  ë„êµ¬ ì´ë¦„
            tool_args: ë„êµ¬ ì¸ì ë”•ì…”ë„ˆë¦¬
            
        Returns:
            Any: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
            
        Raises:
            Exception: ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ
        """
        try:
            result = await self.mcp.call_tool(tool_name, tool_args)
            logger.info(f"[{self.name}] Tool '{tool_name}' executed successfully")
            return result
        except Exception as e:
            logger.error(f"[{self.name}] Tool '{tool_name}' execution failed: {e}")
            raise
    
    def _remove_think_tag(self, text: str) -> str:
        """</think> íƒœê·¸ ì œê±° ë° JSON ì¶”ì¶œ
        
        LLM ì‘ë‹µì—ì„œ <think> íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ìˆœìˆ˜í•œ JSONë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            str: íƒœê·¸ê°€ ì œê±°ëœ ê¹¨ë—í•œ í…ìŠ¤íŠ¸
        """
        # 1. </think>ê°€ ìˆë‹¤ë©´, ê·¸ ë’¤ì˜ ë‚´ìš©ë§Œ ì·¨í•©ë‹ˆë‹¤.
        if "</think>" in text:
            text = text.rsplit("</think>", 1)[-1]
        
        # 2. í˜¹ì‹œë¼ë„ <think>ë§Œ ìˆê³  ë‹«ëŠ” íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì•ˆì „ì¥ì¹˜ë¡œ ì‹œì‘ íƒœê·¸ ì²˜ë¦¬
        elif "<think>" in text:
            text = text.rsplit("<think>", 1)[-1]

        # 3. ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        # 4. ìˆœìˆ˜í•œ JSON ê°ì²´ë§Œ ì¶”ì¶œ (ì²« '{' ë¶€í„° ë§ˆì§€ë§‰ '}' ê¹Œì§€)
        start_idx = text.find("{")
        end_idx = text.rfind("}")
        
        if start_idx != -1 and end_idx != -1:
            text = text[start_idx : end_idx + 1]
        
        return text


    # =============================
    # ê¸°íƒ€ ê³µí†µ ë©”ì„œë“œ
    # =============================
    
    def validate_input(self, state: AgentState) -> bool:
        """ì…ë ¥ ìƒíƒœ ê²€ì¦"""
        if "messages" not in state or not isinstance(state["messages"], list):
            logger.error(f"[{self.name}] Invalid messages field")
            return False
        
        is_valid, error_msg = StateValidator.validate_execution_state(state)
        if not is_valid:
            logger.error(f"[{self.name}] Invalid execution state: {error_msg}")
            return False
        
        return True

    def pre_execute(self, state: AgentState) -> AgentState:
        """ì‹¤í–‰ ì „ ì „ì²˜ë¦¬"""
        return state

    def _validate_config(self):
        """ì„¤ì • ê²€ì¦"""
        if not self.config.name:
            raise ValueError("Agent name is required")

    def _log_start(self, state: AgentState):
        """ì‹¤í–‰ ì‹œì‘ ë¡œê¹…"""
        logger.info(f"[{self.name}] Starting execution")
        logger.info(f"   Session ID: {state.get('session_id', 'unknown')}")
        logger.info(f"   Messages: {len(state.get('messages', []))}")

    def _log_end(self, state: AgentState):
        """ì‹¤í–‰ ì™„ë£Œ ë¡œê¹…"""
        logger.info(f"[{self.name}] Execution completed")
        logger.info(f"   Final Status: {state.get('status', 'unknown')}")
        logger.info(f"   Iterations: {state.get('iteration', 0)}")
        logger.info(f"   Tool Calls: {len(state.get('tool_calls', []))}")