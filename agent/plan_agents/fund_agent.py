import json
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from pathlib import Path 
from typing import TypedDict, Annotated, Dict, Any 
from langgraph.graph import StateGraph, END 

# í€ë“œ ì—ì´ì „íŠ¸

# LangGraph ìƒíƒœ(State) ì •ì˜
class FundAgentState(TypedDict):
    fund_data_path: str
    
    # ì´ ë…¸ë“œê°€ ì‹¤í–‰ëœ í›„ ìƒíƒœì— ì¶”ê°€í•  ë°ì´í„°
    # (Annotatedë¥¼ ì‚¬ìš©í•˜ë©´, ê¸°ì¡´ ê²°ê³¼ì— ìƒˆë¡œìš´ ê²°ê³¼ë¥¼ 'ì¶”ê°€'í•  ìˆ˜ ìˆìŒ)
    fund_analysis_result: dict


# ì „ì—­ êµ¬ì„± ìš”ì†Œ ì •ì˜

# qwen3:8b ëª¨ë¸ ë¡œë“œ
try:
    llm = ChatOllama(model="qwen3:8b") 
    print("--- 8. ë¡œì»¬ Ollama (qwen3:8b) ëª¨ë¸ ë¡œë“œ ì„±ê³µ ---")
except Exception as e:
    print(f"Ollama ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("Ollama ë°ìŠ¤í¬íƒ‘ ì•±ì´ ì‹¤í–‰ ì¤‘ì¸ì§€, 'ollama pull qwen3:8b'ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    exit() 

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ìˆ˜ì • ì—†ìŒ)
FUND_ANALYST_PROMPT = """
[Persona]
ë‹¹ì‹ ì€ ìµœê³ ì˜ í€ë“œ ìƒí’ˆ ë¶„ì„ê°€(FundAnalyst)ì…ë‹ˆë‹¤. íŠ¹íˆ ê¸ˆìœµ ì´ˆë³´ìì—ê²Œ ë³µì¡í•œ ìƒí’ˆì„ ë§¤ìš° ì‰½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

[Task]
- ì…ë ¥ë°›ì€ [Raw Fund Data]ë¥¼ ë¶„ì„í•˜ì—¬, ê° 'ë¦¬ìŠ¤í¬ ë ˆë²¨'ë³„ë¡œ 'ì˜ˆìƒ ìˆ˜ìµë¥ 'ì´ ê°€ì¥ ë†’ì€ ìƒí’ˆ 1ê°œì”©ì„ ì„ ë³„í•©ë‹ˆë‹¤.
- ì„ ë³„ëœ ê° ìƒí’ˆì˜ ì„¤ëª…('description')ì„ ì´ˆë³´ìê°€ ì¦‰ì‹œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê°„ê²°í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.

[Instructions]
1. ì…ë ¥ë°›ì€ [Raw Fund Data] ëª©ë¡ ì „ì²´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
2. í€ë“œ ëª©ë¡ì„ 'risk_level' (ì˜ˆ: 'ë†’ì€ ìœ„í—˜', 'ì¤‘ê°„ ìœ„í—˜', 'ë‚®ì€ ìœ„í—˜') ë³„ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.
3. ê° ë¦¬ìŠ¤í¬_ë ˆë²¨ ê·¸ë£¹ ë‚´ì—ì„œ 'expected_return'(ì˜ˆìƒ ìˆ˜ìµë¥ )ì´ ê°€ì¥ ë†’ì€ ìƒí’ˆì„ **ë‹¨ í•˜ë‚˜ë§Œ** ì„ ì •í•©ë‹ˆë‹¤.
4. (ì¤‘ìš”) ì„ ì •ëœ ê° ìƒí’ˆì˜ 'description'(ì„¤ëª… ì›ë¬¸)ì„ ë¶„ì„í•˜ì—¬, **ê¸ˆìœµ ì´ˆë³´ì**ê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹¨ì–´ë¡œ í•µì‹¬ ë‚´ìš©(ì–´ë””ì— íˆ¬ìí•˜ëŠ”ì§€, ëª©í‘œëŠ” ë¬´ì—‡ì¸ì§€)ì„ ìš”ì•½í•©ë‹ˆë‹¤. ì „ë¬¸ ìš©ì–´ ì‚¬ìš©ì„ ìµœì†Œí™”í•´ì•¼ í•©ë‹ˆë‹¤.
5. ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì§€ì •ëœ [Output Format]ì— ë§ì¶° ì •í™•í•˜ê²Œ ë°˜í™˜í•©ë‹ˆë‹¤.

[Raw Fund Data (Input)]
{input_data}

[Output Format (Return this)]
<analysis_result>
(JSON í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì—¬ê¸°ì— ì‚½ì…)
</analysis_result>

"""
prompt_template = ChatPromptTemplate.from_template(FUND_ANALYST_PROMPT)

# íŒŒì„œ
def parse_analysis_result(llm_output: str):
    """
    LLMì˜ ì¶œë ¥ì´ <analysis_result>, ```json (ë°±í‹±),
    '''json (ì‘ì€ë”°ì˜´í‘œ) ë“± ì–´ë–¤ í˜•ì‹ì´ë“  ì²˜ë¦¬í•˜ëŠ” íŒŒì„œ
    """
    try:
        if "```json" in llm_output:
            result_str = llm_output.split("```json")[1].split("```")[0].strip()
        elif "'''json" in llm_output:
            result_str = llm_output.split("'''json")[1].split("'''")[0].strip()
        elif "<analysis_result>" in llm_output:
            result_str = llm_output.split("<analysis_result>")[1].split("</analysis_result>")[0].strip()
        elif llm_output.strip().startswith('{') and llm_output.strip().endswith('}'):
             result_str = llm_output.strip()
        else:
             raise ValueError("LLMì˜ ì¶œë ¥ì—ì„œ ìœ íš¨í•œ JSON ë§ˆì»¤(```, ''', <>)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return json.loads(result_str)
    except Exception as e:
        print(f"--- íŒŒì‹± ì˜¤ë¥˜ ---")
        print(f"LLM ì›ë³¸ ì¶œë ¥ (íŒŒì‹± ì „): {llm_output}")
        print(f"ì˜¤ë¥˜ ë‚´ìš©: {e}")
        return {"error": "ë¶„ì„ ê²°ê³¼ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

# ì²´ì¸ êµ¬ì„±
chain = prompt_template | llm | StrOutputParser() | parse_analysis_result


# LangGraph ë…¸ë“œ í•¨ìˆ˜ ì •ì˜
def run_fund_analysis_node(state: FundAgentState):
    print("--- [ë…¸ë“œ ì‹œì‘] 'í€ë“œ ë¶„ì„ ë…¸ë“œ' ì‹¤í–‰ ---")
    
    # 1. Stateì—ì„œ íŒŒì¼ ê²½ë¡œ ì…ë ¥ ë°›ê¸°
    file_path = state['fund_data_path']

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            raw_fund_data = json.load(f)
        print(f"--- 9. {file_path} íŒŒì¼ ë¡œë“œ ì„±ê³µ ---")
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {"fund_analysis_result": {"error": f"File not found: {file_path}"}}
    except json.JSONDecodeError:
        print(f"ì˜¤ë¥˜: {file_path} íŒŒì¼ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return {"fund_analysis_result": {"error": f"JSON decode error in file: {file_path}"}}
    except Exception as e:
        print(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"fund_analysis_result": {"error": f"File loading error: {e}"}}

    # 3. LLM ì…ë ¥ ë°ì´í„° ê°€ê³µ
    print("--- í€ë“œ ë¶„ì„ ì—ì´ì „íŠ¸ ì‹¤í–‰ (ë¡œì»¬ PCë¡œ ì—°ì‚° ì¤‘...) ---")
    fund_data_str = json.dumps(raw_fund_data, indent=2, ensure_ascii=False)

    # 4. .invoke()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ ì‹¤í–‰
    analysis_result = chain.invoke({"input_data": fund_data_str})

    print("--- [ë…¸ë“œ ì¢…ë£Œ] 'í€ë“œ ë¶„ì„ ë…¸ë“œ' ì™„ë£Œ ---")
    
    # 5. State ì—…ë°ì´íŠ¸ (ë°˜í™˜)
    return {"fund_analysis_result": analysis_result}


# ê·¸ë˜í”„ ì •ì˜ ë° í˜¸ì¶œ
if __name__ == "__main__":
    
    # ê·¸ë˜í”„ ì •ì˜
    workflow = StateGraph(FundAgentState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("analyze_funds", run_fund_analysis_node)

    # ì—£ì§€ ì¶”ê°€
    workflow.set_entry_point("analyze_funds")
    workflow.add_edge("analyze_funds", END)

    # ê·¸ë˜í”„ ì»´íŒŒì¼
    app = workflow.compile()

    # (ì¤‘ìš”) ì´ˆê¸° ìƒíƒœ(Initial State) ì •ì˜
    # ìƒëŒ€ ê²½ë¡œ
    current_script_path = Path(__file__).resolve()
    project_root = current_script_path.parents[2] 
    file_path_to_run = project_root / 'fund_data.json'

    initial_state = {
        "fund_data_path": str(file_path_to_run), # ë…¸ë“œì— íŒŒì¼ ê²½ë¡œ ì£¼ì…
        "fund_analysis_result": {}
    }

    print("\n--- ğŸ (LangGraph) í€ë“œ ë¶„ì„ ê·¸ë˜í”„ ì‹¤í–‰ ì‹œì‘ ğŸ ---")
    
    # 4-6. ê·¸ë˜í”„ ì‹¤í–‰
    final_state = app.invoke(initial_state)

    # 4-7. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n--- ğŸ (LangGraph) ê·¸ë˜í”„ ì‹¤í–‰ ì™„ë£Œ ğŸ ---")
    print("ìµœì¢… ë¶„ì„ ê²°ê³¼ (JSON):")
    print(json.dumps(final_state['fund_analysis_result'], indent=2, ensure_ascii=False))