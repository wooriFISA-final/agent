from abc import ABC, abstractmethod
import asyncio
import json
import re
from datetime import datetime
from typing import Any, Dict, Optional, List
from enum import Enum

from agents.config.base_config import (
    BaseAgentConfig,
    AgentState,
    StateBuilder,
    StateValidator,
    ExecutionStatus
)

from agents.base.agent_base_prompts import DECISION_PROMPT
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage

from core.mcp.mcp_manager import MCPManager
from core.logging.logger import setup_logger
from core.llm.llm_manger import LLMHelper

logger = setup_logger()


# =============================
# Agent ê´€ë ¨ í´ë˜ìŠ¤
# =============================

class AgentAction(Enum):
    """Agentê°€ ì·¨í•  ìˆ˜ ìˆëŠ” í–‰ë™ íƒ€ì…"""
    USE_TOOL = "use_tool"
    RESPOND = "respond"
    DELEGATE = "delegate"


class AgentDecision:
    """Agentì˜ ì˜ì‚¬ê²°ì • ê²°ê³¼"""
    def __init__(
        self,
        action: AgentAction,
        reasoning: str,
        tool_name: Optional[str] = None,
        tool_arguments: Optional[Dict] = None,
        tool_use_id: Optional[str] = None,
        tool_calls: Optional[List[Dict]] = None,
        next_agent: Optional[str] = None,
        response_text: Optional[str] = None,
        requires_post_processing: bool = False
    ):
        self.action = action
        self.reasoning = reasoning
        self.tool_name = tool_name
        self.tool_arguments = tool_arguments or {}
        self.tool_use_id = tool_use_id
        self.tool_calls = tool_calls or []
        self.next_agent = next_agent
        self.response_text = response_text
        self.requires_post_processing = requires_post_processing


class AgentBase(ABC):
    """
    ë©€í‹°í„´ Tool í˜¸ì¶œì„ ì§€ì›í•˜ëŠ” Agent ë² ì´ìŠ¤ í´ë˜ìŠ¤
    
    í•µì‹¬ ì„¤ê³„:
    - LLMHelperë¥¼ í†µí•œ Bedrock Converse API ì§ì ‘ í˜¸ì¶œ
    - LangChain ë©”ì‹œì§€ëŠ” LangGraph í˜¸í™˜ì„ ìœ„í•´ ìœ ì§€
    - LLM í˜¸ì¶œ ì‹œì—ë§Œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©
    - Agentë³„ LLM ì„¤ì • ì§€ì›
    - DELEGATE ì•¡ì…˜ìœ¼ë¡œ ë‹¤ë¥¸ Agentì—ê²Œ ì‘ì—… ìœ„ì„ ê°€ëŠ¥
    """

    def __init__(self, config: BaseAgentConfig):
        self.name = config.name
        self.config = config
        self.mcp = MCPManager().get_instance()
        
        # âœ… agents.yaml ì„¤ì • ìš°ì„  ì ìš©
        from agents.config.agent_config_loader import AgentConfigLoader
        
        yaml_config = AgentConfigLoader.get_agent_config_from_current(self.name)
        
        if yaml_config:
            self.max_iterations = yaml_config.max_iterations
            self.config.max_retries = yaml_config.max_retries
            self.config.timeout = yaml_config.timeout
            self.config.tags = yaml_config.tags
            
            if yaml_config.llm_config:
                merged_llm = {**config.get_llm_config_dict(), **yaml_config.llm_config}
                self.llm_config = merged_llm
            else:
                self.llm_config = config.get_llm_config_dict()
            
            logger.info(f"[{self.name}] âœ… Applied agents.yaml config:")
            logger.info(f"   max_retries: {self.config.max_retries}")
            logger.info(f"   timeout: {self.config.timeout}")
            logger.info(f"   max_iterations: {self.max_iterations}")
            logger.info(f"   tags: {self.config.tags}")
        else:
            self.max_iterations = config.max_iterations
            self.llm_config = config.get_llm_config_dict()
            logger.info(f"[{self.name}] Using BaseAgentConfig defaults")
        
        logger.info(f"[{self.name}] Agent initialized")
        logger.info(f"[{self.name}] LLM config: {self.llm_config if self.llm_config else 'Using global settings'}")
        
        self._validate_config()

    # =============================
    # LLM í˜¸ì¶œ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _langchain_to_dict(self, message) -> Dict[str, Any]:
        """LangChain ë©”ì‹œì§€ë¥¼ Bedrock ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        if isinstance(message, HumanMessage):
            if isinstance(message.content, list):
                return {"role": "user", "content": message.content}
            else:
                return {"role": "user", "content": [{"text": message.content}]}
        
        elif isinstance(message, AIMessage):
            from core.llm.llm_manger import _sanitize_extended_thinking_tokens
            
            if isinstance(message.content, list):
                sanitized_content = []
                for block in message.content:
                    if isinstance(block, dict) and "text" in block:
                        sanitized_block = block.copy()
                        sanitized_block["text"] = _sanitize_extended_thinking_tokens(block["text"])
                        sanitized_content.append(sanitized_block)
                    else:
                        sanitized_content.append(block)
                return {"role": "assistant", "content": sanitized_content}
            else:
                sanitized_text = _sanitize_extended_thinking_tokens(message.content)
                return {"role": "assistant", "content": [{"text": sanitized_text}]}
        
        elif isinstance(message, SystemMessage):
            return {"role": "user", "content": [{"text": f"[System] {message.content}"}]}
        
        elif isinstance(message, ToolMessage):
            logger.warning(f"[{self.name}] ToolMessage deprecated, use HumanMessage with toolResult")
            return {"role": "user", "content": [{"text": message.content}]}
        
        else:
            msg_type = type(message).__name__
            msg_attrs = {k: v for k, v in message.__dict__.items() if not k.startswith('_')}
            logger.warning(f"[{self.name}] âš ï¸ Unknown message type: {msg_type}")
            logger.warning(f"[{self.name}]    Message attributes: {msg_attrs}")
            
            if hasattr(message, 'type'):
                logger.warning(f"[{self.name}]    Message.type: {message.type}")
            
            return {"role": "user", "content": [{"text": str(message)}]}
    
    def _convert_messages_to_dict(self, messages: List) -> List[Dict[str, str]]:
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ì¼ê´„ ë³€í™˜"""
        return [self._langchain_to_dict(msg) for msg in messages]
        
    # =============================
    # Message í¬ë§·íŒ… ë° LLM í˜¸ì¶œ (Debugìš©)
    # =============================
    def _pretty_messages(self, messages: List) -> str:
        """LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ë¬¸ìì—´ë¡œ ì˜ˆì˜ê²Œ ë³€í™˜"""
        converted = self._convert_messages_to_dict(messages)
        return json.dumps(converted, ensure_ascii=False, indent=2)

    def _prepare_llm_params(
        self,
        use_agent_config: bool = True,
        stream: Optional[bool] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """LLM í˜¸ì¶œ íŒŒë¼ë¯¸í„° ì¤€ë¹„"""
        if use_agent_config:
            llm_params = {**self.llm_config, **kwargs}
        else:
            llm_params = {**kwargs}
        
        if stream is not None:
            llm_params["stream"] = stream
            
        return llm_params
    
    def _call_llm(
        self,
        messages: List,
        stream: Optional[bool] = None,
        **kwargs
    ) -> str:
        """LLM í˜¸ì¶œ (ë™ê¸° ë°©ì‹)"""
        llm_params = self._prepare_llm_params(
            use_agent_config=True,
            stream=stream,
            **kwargs
        )
        
        logger.debug(f"[{self.name}] LLM Call Parameters: {llm_params}")
        
        formatted_messages = self._convert_messages_to_dict(messages)
        
        return LLMHelper.invoke_with_history(
            history=formatted_messages,
            **llm_params
        )

    # =============================
    # ìƒíƒœ ê´€ë¦¬ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _add_message_to_state(self, state: AgentState, message) -> AgentState:
        """ìƒíƒœì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ê³  global_messages ì—…ë°ì´íŠ¸"""
        global_messages = state.get("global_messages", [])
        global_messages.append(message)
        state["global_messages"] = global_messages
        return state

    # =============================
    # ë©€í‹°í„´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
    # =============================
    
    async def run(self, state: AgentState) -> AgentState:
        """Agent ì‹¤í–‰ ë©”ì¸ í”Œë¡œìš°"""
        self._log_start(state)

        if not self.validate_input(state):
            error = ValueError(f"Invalid input for {self.name}")
            state = StateBuilder.add_error(state, error, self.name)
            state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
            return state
        
        state["iteration"] = 0
        logger.info(f"[{self.name}] Iteration reset to 0 for this agent")

        state = self.pre_execute(state)

        for attempt in range(1, self.config.max_retries + 1):
            try:
                async with asyncio.timeout(self.config.timeout):
                    result = await self.execute_multi_turn(state)
                break
                
            except asyncio.TimeoutError:
                error_msg = f"Timeout after {self.config.timeout} seconds"
                logger.warning(f"[{self.name}] attempt {attempt} failed: {error_msg}")
                
                if attempt == self.config.max_retries:
                    error = TimeoutError(f"{self.name} execution timed out")
                    state = StateBuilder.add_error(state, error, self.name)
                    state = StateBuilder.finalize_state(state, ExecutionStatus.TIMEOUT)
                    return state
                
                await asyncio.sleep(1.5 * attempt)
                
            except Exception as e:
                logger.warning(f"[{self.name}] attempt {attempt} failed: {e}")
                
                if attempt == self.config.max_retries:
                    state = StateBuilder.add_error(state, e, self.name)
                    state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
                    return state
                
                await asyncio.sleep(1.5 * attempt)

        self._log_end(result)
        return result

    # =============================
    # ë©€í‹°í„´ ì‹¤í–‰ ë¡œì§ (ReAct Loop)
    # =============================
    
    async def execute_multi_turn(self, state: AgentState) -> AgentState:
        """ë©€í‹°í„´ ì‹¤í–‰ í”Œë¡œìš° - global_messages ì‚¬ìš©"""
        
        if state.get("status") == ExecutionStatus.RESPONDING:
            logger.info(f"[{self.name}] âš™ï¸ Re-entered for post-processing (status: RESPONDING)")
            state.pop("requires_post_processing", None)
            state["status"] = ExecutionStatus.RUNNING
            logger.info(f"[{self.name}] Status changed to RUNNING for post-processing")
        
        global_messages = state.get("global_messages", [])
        if not global_messages:
            global_messages = state.get("messages", [])
            state["global_messages"] = global_messages
        
        logger.info(f"[{self.name}] Global messages count: {len(global_messages)}")
        
        agent_role = self.get_agent_role_prompt()
        system_msg = SystemMessage(content=agent_role)
        
        global_messages = [system_msg] + global_messages
        state["global_messages"] = global_messages
        
        logger.info(f"[{self.name}] âœ… Added agent role as SystemMessage at the beginning")
        
        available_tools = await self._list_mcp_tools()
        logger.info(f"[{self.name}] MCP tools available: {len(available_tools)}")
                
        bedrock_tool_config = self._convert_mcp_to_bedrock_toolspec(available_tools)
        if bedrock_tool_config:
            state["bedrock_tool_config"] = bedrock_tool_config
            logger.info(f"[{self.name}] âœ… Bedrock toolConfig created with {len(bedrock_tool_config['tools'])} tools")
            tool_names = [t["toolSpec"]["name"] for t in bedrock_tool_config["tools"]]
        else:
            logger.warning(f"[{self.name}] âš ï¸ No Bedrock toolConfig created")
            tool_names = []
        
        # ReAct Loop
        while not StateBuilder.is_max_iterations_reached(state):
            state = StateBuilder.increment_iteration(state)
            current_iteration = state.get("iteration", 0)
            
            logger.info(f"\n{'='*60}")
            logger.info(f"[{self.name}] Iteration {current_iteration}/{self.max_iterations}")
            logger.info(f"{'='*60}")
            
            global_messages = state.get("global_messages", [])
            
            # âœ… ë©”ì‹œì§€ êµ¬ì¡° ê²€ì¦ ì¶”ê°€
            if not self._validate_message_structure(global_messages):
                logger.error(f"[{self.name}] âŒ Message structure validation failed")
                # ë©”ì‹œì§€ ì •ê·œí™” ì‹œë„
                global_messages = self._normalize_messages(global_messages)
                state["global_messages"] = global_messages
                logger.info(f"[{self.name}] âœ… Messages normalized")
            
            try:
                logger.info("ğŸ¤” Making Decision (Bedrock native tool calling)\n")
                
                decision = await self._make_decision(state, global_messages, tool_names)
                
                logger.info(f"ğŸ¤” Decision: {decision.action.value}")
                logger.info(f"   Reasoning: {decision.reasoning}")
                
            except Exception as e:
                logger.error(f"[{self.name}] Decision making failed: {e}")
                state = StateBuilder.add_error(state, e, self.name)
                break
            
            if decision.action == AgentAction.USE_TOOL:
                state = await self._execute_tool_action(state, decision)
                continue
            
            elif decision.action == AgentAction.DELEGATE:
                return await self._execute_delegate_action(state, decision)
                
            elif decision.action == AgentAction.RESPOND:
                return await self._execute_respond_action(state, global_messages, available_tools, decision)
        
        return await self._handle_max_iterations(state, global_messages)
    
    # =============================
    # ì•¡ì…˜ ì‹¤í–‰ ë©”ì„œë“œ
    # =============================
    
    async def _execute_tool_action(
        self,
        state: AgentState,
        decision: AgentDecision
    ) -> AgentState:
        """Tool ì‹¤í–‰ ì•¡ì…˜ ì²˜ë¦¬ - ì²« ë²ˆì§¸ë§Œ ì‹¤í–‰í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë©”ì‹œì§€ì—ì„œ ì œê±°"""
        
        tool_calls = decision.tool_calls if decision.tool_calls else [{
            "name": decision.tool_name,
            "arguments": decision.tool_arguments,
            "tool_use_id": decision.tool_use_id
        }]
        
        total_tools = len(tool_calls)
        logger.info(f"ğŸ”§ Total {total_tools} tool(s) requested")
        
        first_tool = tool_calls[0]
        logger.info(f"ğŸ”§ Executing tool 1/{total_tools}: {first_tool['name']}")
        logger.info(f"   Arguments: {first_tool['arguments']}")
        
        tool_results = []
        
        # ì²« ë²ˆì§¸ tool ì‹¤í–‰
        try:
            tool_result = await self._execute_mcp_tool(
                first_tool["name"],
                first_tool["arguments"]
            )
            
            state = StateBuilder.add_tool_call(
                state,
                tool_name=first_tool["name"],
                arguments=first_tool["arguments"],
                result=tool_result
            )
            
            import json
            if isinstance(tool_result, dict):
                result_content = json.dumps(tool_result, ensure_ascii=False)
            else:
                result_content = str(tool_result)
            
            tool_results.append({
                "toolResult": {
                    "toolUseId": first_tool["tool_use_id"],
                    "content": [{"text": result_content}]
                }
            })
            
            logger.info(f"âœ… Tool 1/{total_tools} executed successfully")
            
        except Exception as e:
            logger.error(f"[{self.name}] Tool execution failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
            
            tool_results.append({
                "toolResult": {
                    "toolUseId": first_tool["tool_use_id"],
                    "content": [{"text": f"Error: {str(e)}"}],
                    "status": "error"
                }
            })
        
        # âœ… ë‚˜ë¨¸ì§€ toolì€ assistant ë©”ì‹œì§€ì—ì„œ ì œê±° (ì¬êµ¬ì„±)
        if total_tools > 1:
            logger.warning(f"âš ï¸ Removing {total_tools - 1} unused tool(s) from message history")
            
            global_messages = state.get("global_messages", [])
            if global_messages and isinstance(global_messages[-1].content, list):
                last_msg = global_messages[-1]
                
                # ì²« ë²ˆì§¸ toolUseë§Œ ë‚¨ê¸°ê¸°
                new_content = []
                tool_count = 0
                for block in last_msg.content:
                    if isinstance(block, dict) and "toolUse" in block:
                        tool_count += 1
                        if tool_count == 1:
                            new_content.append(block)
                    else:
                        new_content.append(block)
                
                # ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                last_msg.content = new_content
                global_messages[-1] = last_msg
                state["global_messages"] = global_messages
                
                logger.info(f"   Kept first toolUse, removed {total_tools - 1} toolUse block(s)")
        
        # âœ… ì²« ë²ˆì§¸ toolì˜ ê²°ê³¼ë§Œ ì¶”ê°€
        tool_result_message = HumanMessage(content=tool_results)
        state = self._add_message_to_state(state, tool_result_message)
        
        logger.info(f"âœ… Tool execution completed: 1 executed, {total_tools - 1} removed")
        
        return state
    
    async def _execute_delegate_action(
        self,
        state: AgentState,
        decision: AgentDecision
    ) -> AgentState:
        """Delegate ì•¡ì…˜ ì²˜ë¦¬ - toolResult ì¶”ê°€"""
        logger.info(f"ğŸ”€ Delegating to agent: {decision.next_agent}")
        logger.info(f"   Reason: {decision.reasoning}")
        
        # âœ… delegate toolResult ì¶”ê°€ (Bedrock API ìš”êµ¬ì‚¬í•­)
        tool_result = {
            "toolResult": {
                "toolUseId": decision.tool_use_id,
                "content": [{
                    "text": json.dumps({
                        "status": "delegated",
                        "next_agent": decision.next_agent,
                        "reason": decision.reasoning
                    }, ensure_ascii=False)
                }]
            }
        }
        
        # global_messagesì— toolResult ì¶”ê°€
        tool_result_message = HumanMessage(content=[tool_result])
        state = self._add_message_to_state(state, tool_result_message)
        
        # delegation ë©”íƒ€ë°ì´í„° ì„¤ì •
        state["previous_agent"] = self.name
        state["next_agent"] = decision.next_agent
        state["delegation_reason"] = decision.reasoning
        state["status"] = ExecutionStatus.RUNNING
        state["timestamp"] = datetime.now()
        
        global_messages = state.get("global_messages", [])
        logger.info(f"[{self.name}] Delegation: next_agent={state.get('next_agent')}, status={state.get('status')}")
        logger.info(f"[{self.name}] âœ… Full conversation history preserved ({len(global_messages)} messages)")
        
        return state

    async def _execute_respond_action(
        self,
        state: AgentState,
        global_messages: List,
        available_tools: List[str],
        decision: AgentDecision
    ) -> AgentState:
        """Respond ì•¡ì…˜ ì²˜ë¦¬"""
        logger.info("âœ… Processing response action")
        
        try:
            if decision.requires_post_processing:
                # âœ… respond_intermediate toolResult ì¶”ê°€
                tool_result = {
                    "toolResult": {
                        "toolUseId": decision.tool_use_id,
                        "content": [{
                            "text": json.dumps({
                                "status": "intermediate",
                                "reason": decision.reasoning,
                                "message": "ì¤‘ê°„ ë‹¨ê³„ - ì¶”ê°€ ì‘ì—… í•„ìš”"
                            }, ensure_ascii=False)
                        }]
                    }
                }
                
                # global_messagesì— toolResult ì¶”ê°€
                tool_result_message = HumanMessage(content=[tool_result])
                state = self._add_message_to_state(state, tool_result_message)
                
                state["status"] = ExecutionStatus.RESPONDING
                state["requires_post_processing"] = True
                logger.info(f"[{self.name}] âš™ï¸ Intermediate stage - RESPONDING (toolResult added)")
                logger.info(f"[{self.name}] Router will re-enter this agent for post-processing")
                logger.info(f"[{self.name}] Reason: {decision.reasoning}")
            else:
                final_response = decision.response_text
                
                if not final_response:
                    logger.error(f"[{self.name}] No response_text in decision")
                    raise ValueError("response_text is required for final RESPOND action")
                
                logger.info(f"[{self.name}] Response ready ({len(final_response)} chars)")
                
                state["last_result"] = final_response
                
                state = self._add_message_to_state(state, AIMessage(content=final_response))
                
                usage = state.get("usage", {})
                total_tokens = usage.get("totalTokens", 0)
                
                if total_tokens > 50000:
                    logger.warning(f"âš ï¸ Token limit approaching: {total_tokens}/128000 - Compressing history...")
                    state = await self._compress_conversation_history(state)
                else:
                    logger.info(f"ğŸ“Š Token usage OK: {total_tokens}/128000")
                
                state = StateBuilder.finalize_state(state, ExecutionStatus.SUCCESS)
                logger.info(f"[{self.name}] âœ… Final response saved and finalized with SUCCESS")
            
            logger.info(f"[{self.name}] Total messages: {len(state.get('global_messages', []))}")
            logger.info(f"ğŸ’¬ Response action processed")
            
        except Exception as e:
            logger.error(f"[{self.name}] Response processing failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
            state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
        
        return state
    
    async def _handle_max_iterations(
        self,
        state: AgentState,
        global_messages: List
    ) -> AgentState:
        """ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ ì²˜ë¦¬"""
        logger.warning(f"âš ï¸ Max iterations ({self.max_iterations}) reached")
        
        try:
            fallback_response = await self._generate_fallback_response(global_messages)
            state = self._add_message_to_state(state, AIMessage(content=fallback_response))
            state["last_result"] = fallback_response
        except Exception as e:
            logger.error(f"[{self.name}] Fallback response generation failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
        
        state = StateBuilder.finalize_state(state, ExecutionStatus.MAX_ITERATIONS)
        return state

    # =============================
    # Agent React Function ë‹¨ê³„ë³„ ë©”ì„œë“œ
    # =============================
    async def _make_decision(
        self,
        state: AgentState,
        messages: List,
        available_tools: List[str],
    ) -> AgentDecision:
        available_agents = self._get_available_agents_list()
        user_id = state.get("user_id", "test_user_1")
        
        if available_tools:
            tools_formatted = "\n".join([f"     - {tool}" for tool in available_tools])
        else:
            tools_formatted = "     - (ì—†ìŒ)"
        
        system_prompt = DECISION_PROMPT.format(
            name=self.name,
            user_id=user_id,
            available_agents=available_agents,
            available_tools=tools_formatted
        )
        
        try:
            logger.info(f"[{self.name}] ğŸ¤” Making decision with Bedrock Native Tool Calling")
        
            messages.append(HumanMessage(content=system_prompt))
            state["global_messages"] = messages
            
            bedrock_tool_config = state.get("bedrock_tool_config")
            if not bedrock_tool_config:
                raise Exception("bedrock_tool_config not found in state")
            
            formatted_messages = self._convert_messages_to_dict(messages)
            
            from core.llm.llm_manger import LLMHelper
            response = await asyncio.to_thread(
                LLMHelper.invoke_with_history,
                history=formatted_messages,
                tool_config=bedrock_tool_config,
                tool_choice={"auto": {}},
                return_full_response=True,
                temperature=0.01,
                top_p=0.01
            )
            
            stop_reason = response.get("stopReason")
            logger.info(f"[{self.name}] stopReason: {stop_reason}")
            
            usage = response.get("usage", {})
            state["usage"] = usage
            logger.info(f"ğŸ“Š Token usage - Input: {usage.get('inputTokens', 0)}, Output: {usage.get('outputTokens', 0)}, Total: {usage.get('totalTokens', 0)}")
            
            # end_turn ì²˜ë¦¬
            if stop_reason == "end_turn":
                message = response.get("output", {}).get("message", {})
                content_blocks = message.get("content", [])
                
                response_text = ""
                for block in content_blocks:
                    if "text" in block:
                        response_text = block["text"]
                        break
                
                logger.info(f"[{self.name}] âœ… Final response via end_turn")
                
                messages.append(AIMessage(content=response_text))
                state["global_messages"] = messages
                
                return AgentDecision(
                    action=AgentAction.RESPOND,
                    reasoning="Final response without post-processing",
                    response_text=response_text,
                    requires_post_processing=False
                )
            
            if stop_reason != "tool_use":
                logger.error(f"[{self.name}] Unexpected stopReason: {stop_reason}")
                raise Exception(f"Unexpected stopReason: '{stop_reason}'")
            
            message = response["output"]["message"]
            content = message.get("content", [])

            # reasoningContent í•„í„°ë§
            filtered_content = [
                block for block in content 
                if not isinstance(block, dict) or "reasoningContent" not in block
            ]
            
            # âœ… ë¹ˆ ê²½ìš° ë¹ˆ í…ìŠ¤íŠ¸ ë¸”ë¡ ì¶”ê°€ (ì›ë³¸ ë³µì› ê¸ˆì§€)
            if not filtered_content:
                logger.warning(f"[{self.name}] âš ï¸ All content filtered out, adding empty text block")
                filtered_content = [{"text": ""}]

            # âœ… toolUse.name sanitize
            for block in filtered_content:
                if isinstance(block, dict) and "toolUse" in block:
                    tool_use = block["toolUse"]
                    tool_name_raw = tool_use.get("name", "")
                    
                    tool_name_clean = tool_name_raw.split('<')[0].split('|')[0].strip()
                    tool_name_clean = re.sub(r'[^a-zA-Z0-9_-]', '', tool_name_clean)
                    
                    if tool_name_clean != tool_name_raw:
                        logger.warning(f"[{self.name}] âš ï¸ Sanitized toolUse.name in message: '{tool_name_raw}' â†’ '{tool_name_clean}'")
                        tool_use["name"] = tool_name_clean

            messages.append(AIMessage(content=filtered_content))
            state["global_messages"] = messages
            
            # âœ… ëª¨ë“  toolUse ë¸”ë¡ ìˆ˜ì§‘
            tool_calls = []
            for block in filtered_content:
                if "toolUse" in block:
                    tool_use = block["toolUse"]
                    tool_name_raw = tool_use["name"]
                    tool_input = tool_use.get("input", {})
                    tool_use_id = tool_use["toolUseId"]
                    
                    tool_name = tool_name_raw.split('<')[0].split('|')[0].strip()
                    
                    if tool_name != tool_name_raw:
                        logger.warning(f"[{self.name}] âš ï¸ Tool name sanitized: '{tool_name_raw}' â†’ '{tool_name}'")
                    
                    tool_calls.append({
                        "name": tool_name,
                        "arguments": tool_input,
                        "tool_use_id": tool_use_id
                    })
            
            if not tool_calls:
                logger.error(f"[{self.name}] No toolUse block found")
                raise Exception("No toolUse block found despite stopReason='tool_use'")
            
            logger.info(f"[{self.name}] Found {len(tool_calls)} tool call(s)")
            
            first_tool = tool_calls[0]
            
            logger.info(f"[{self.name}] ğŸ”§ Primary tool: {first_tool['name']}")
            logger.info(f"[{self.name}] ğŸ“‹ Tool input: {first_tool['arguments']}")
            
            # respond_intermediate
            if first_tool["name"] == "respond_intermediate":
                reason = first_tool["arguments"].get("reason", "Additional work required")
                logger.info(f"[{self.name}] âš™ï¸ Intermediate stage")
                
                return AgentDecision(
                    action=AgentAction.RESPOND,
                    reasoning=reason,
                    response_text="",
                    requires_post_processing=True,
                    tool_use_id=first_tool["tool_use_id"],
                    tool_calls=tool_calls
                )
            
            # delegate
            elif first_tool["name"] == "delegate":
                agent_name = first_tool["arguments"].get("agent_name")
                reason = first_tool["arguments"].get("reason", "")
                
                logger.info(f"[{self.name}] ğŸ”€ Delegating to: {agent_name}")
                
                return AgentDecision(
                    action=AgentAction.DELEGATE,
                    reasoning=reason,
                    next_agent=agent_name,
                    tool_use_id=first_tool["tool_use_id"],
                    tool_calls=tool_calls
                )
            
            # ì¼ë°˜ MCP Tool
            else:
                return AgentDecision(
                    action=AgentAction.USE_TOOL,
                    reasoning="Bedrock native tool calling",
                    tool_name=first_tool["name"],
                    tool_arguments=first_tool["arguments"],
                    tool_use_id=first_tool["tool_use_id"],
                    tool_calls=tool_calls
                )
                
        except Exception as e:
            logger.error(f"[{self.name}] Decision making failed: {e}")
            raise
        
    async def _generate_fallback_response(self, messages: List) -> str:
        """ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ í´ë°± ì‘ë‹µ ìƒì„±"""
        return f"""ì²˜ë¦¬ ê³¼ì •ì´ ì˜ˆìƒë³´ë‹¤ ë³µì¡í•˜ì—¬ {self.max_iterations}íšŒ ë°˜ë³µ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.
ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."""

    async def _compress_conversation_history(self, state: AgentState) -> AgentState:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ìë™ ì••ì¶• - toolUse/toolResult ìŒ ë³´ì¡´"""
        messages = state.get("global_messages", [])
        
        if len(messages) <= 12:
            logger.info(f"[{self.name}] History short enough ({len(messages)} messages), skipping compression")
            return state
        
        logger.info(f"[{self.name}] ğŸ—œï¸ Compressing conversation history...")
        logger.info(f"   Before: {len(messages)} messages")
        
        try:
            compressed_messages = self._compress_history_safely(messages)
            state["global_messages"] = compressed_messages
            
            logger.info(f"   After: {len(compressed_messages)} messages")
            logger.info(f"[{self.name}] âœ… History compressed successfully")
            
        except Exception as e:
            logger.error(f"[{self.name}] âŒ History compression failed: {e}")
        
        return state
    
    def _compress_history_safely(self, messages: List) -> List:
        """íˆìŠ¤í† ë¦¬ ì••ì¶• - toolUse/toolResult ìŒ ë³´ì¡´"""
        if len(messages) <= 12:
            return messages
        
        compressed = []
        i = 0
        
        # ì²« ë©”ì‹œì§€ ë³´ì¡´
        compressed.append(messages[0])
        i = 1
        
        # ì¤‘ê°„ ë¶€ë¶„ ìš”ì•½ (ìŒì„ ìœ ì§€í•˜ë©´ì„œ)
        middle_end = len(messages) - 10
        pairs_to_summarize = []
        
        while i < middle_end:
            msg = messages[i]
            
            # assistant + user (toolUse/toolResult) ìŒ ê°ì§€
            if (isinstance(msg, AIMessage) and 
                i + 1 < len(messages) and
                isinstance(messages[i + 1], HumanMessage)):
                
                # toolUse í™•ì¸
                has_tool_use = any(
                    isinstance(block, dict) and "toolUse" in block
                    for block in (msg.content if isinstance(msg.content, list) else [])
                )
                
                if has_tool_use:
                    # ìŒìœ¼ë¡œ ìš”ì•½ ëŒ€ìƒì— ì¶”ê°€
                    pairs_to_summarize.append((msg, messages[i + 1]))
                    i += 2
                    continue
            
            pairs_to_summarize.append((msg,))
            i += 1
        
        # ìš”ì•½ ìƒì„±
        summary_text = self._summarize_message_pairs(pairs_to_summarize)
        compressed.append(SystemMessage(content=f"[ì´ì „ ëŒ€í™” ìš”ì•½]\n{summary_text}"))
        
        # ìµœê·¼ 10ê°œ ë³´ì¡´
        compressed.extend(messages[-10:])
        
        return compressed
    
    def _summarize_message_pairs(self, pairs: List) -> str:
        """ë©”ì‹œì§€ ìŒ ìš”ì•½"""
        if not pairs:
            return "ì´ì „ ëŒ€í™” ë‚´ìš© ì—†ìŒ"
        
        conversation_parts = []
        for pair in pairs:
            if len(pair) == 2:
                # toolUse/toolResult ìŒ
                ai_msg, user_msg = pair
                conversation_parts.append(f"Tool í˜¸ì¶œ: {self._extract_tool_names(ai_msg)}")
            else:
                # ë‹¨ì¼ ë©”ì‹œì§€
                msg = pair[0]
                msg_type = msg.__class__.__name__
                content = str(msg.content)[:200] if not isinstance(msg.content, list) else "[êµ¬ì¡°í™”ëœ ë©”ì‹œì§€]"
                conversation_parts.append(f"{msg_type}: {content}...")
        
        return "\n".join(conversation_parts[:20])  # ìµœëŒ€ 20ê°œë§Œ
    
    def _extract_tool_names(self, ai_message: AIMessage) -> str:
        """AIMessageì—ì„œ tool ì´ë¦„ ì¶”ì¶œ"""
        if not isinstance(ai_message.content, list):
            return "unknown"
        
        tool_names = []
        for block in ai_message.content:
            if isinstance(block, dict) and "toolUse" in block:
                tool_names.append(block["toolUse"].get("name", "unknown"))
        
        return ", ".join(tool_names) if tool_names else "unknown"
    
    async def _summarize_messages(self, messages: List) -> str:
        """ë©”ì‹œì§€ ëª©ë¡ì„ LLMìœ¼ë¡œ ìš”ì•½"""
        if not messages:
            return "ì´ì „ ëŒ€í™” ë‚´ìš© ì—†ìŒ"
        
        conversation_parts = []
        for msg in messages:
            msg_type = msg.__class__.__name__
            content = str(msg.content)
            
            if isinstance(msg.content, list):
                text_parts = []
                for block in msg.content:
                    if isinstance(block, dict):
                        if "text" in block:
                            text_parts.append(block["text"][:200])
                        elif "toolUse" in block:
                            tool_name = block["toolUse"].get("name", "unknown")
                            text_parts.append(f"[Tool: {tool_name}]")
                        elif "toolResult" in block:
                            text_parts.append("[Tool Result]")
                content = " ".join(text_parts)
            else:
                content = content[:200]
            
            conversation_parts.append(f"{msg_type}: {content}...")
        
        conversation_text = "\n".join(conversation_parts)
        
        prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ìì™€ AI ì—ì´ì „íŠ¸ ê°„ì˜ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤. í•µì‹¬ ì •ë³´ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

{conversation_text}

ìš”ì•½ ì‹œ ë°˜ë“œì‹œ í¬í•¨í•  ë‚´ìš©:
- ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì£¼ìš” ì •ë³´ë‚˜ ì‘ì—…, ì‚¬ìš©ìê°€ ì„ íƒí•œ ìƒí’ˆ ì •ë³´, ê¸ˆì•¡ ë“±
- ì—ì´ì „íŠ¸ê°€ ìˆ˜í–‰í•œ ì£¼ìš” ì‘ì—… (Tool í˜¸ì¶œ, ê³„ì‚° ë“±)
- ì¤‘ìš”í•œ ìˆ«ìë‚˜ ë°ì´í„°, ì‚¬ìš©ì ì •ë³´ (ê¸ˆì•¡, ë¹„ìœ¨, ìƒí’ˆëª… ë“±)
- í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©

300ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½:"""
        
        try:
            from core.llm.llm_manger import LLMHelper
            summary = await asyncio.to_thread(
                LLMHelper.invoke,
                prompt=prompt,
                max_tokens=800,
                temperature=0.3
            )
            
            return summary.strip()
            
        except Exception as e:
            logger.error(f"[{self.name}] âŒ Summarization failed: {e}")
            return f"ì´ì „ ëŒ€í™”: {len(messages)}ê°œ ë©”ì‹œì§€ (ì‚¬ìš©ì ìš”ì²­ ë° ì—ì´ì „íŠ¸ ì‘ë‹µ í¬í•¨)"

    def _validate_message_structure(self, messages: List) -> bool:
        """ë©”ì‹œì§€ êµ¬ì¡° ê²€ì¦ - toolUse/toolResult ìŒ í™•ì¸"""
        for i in range(len(messages) - 1):
            if not isinstance(messages[i], AIMessage):
                continue
            
            content = messages[i].content
            if not isinstance(content, list):
                continue
            
            # toolUse ê°œìˆ˜ í™•ì¸
            tool_uses = [
                block for block in content
                if isinstance(block, dict) and "toolUse" in block
            ]
            
            if not tool_uses:
                continue
            
            # ë‹¤ìŒ ë©”ì‹œì§€ê°€ userì¸ì§€ í™•ì¸
            if i + 1 >= len(messages) or not isinstance(messages[i + 1], HumanMessage):
                logger.error(f"âš ï¸ toolUse without following user message at index {i}")
                return False
            
            # toolResult ê°œìˆ˜ í™•ì¸
            next_content = messages[i + 1].content
            if not isinstance(next_content, list):
                logger.error(f"âš ï¸ Invalid user message content at index {i + 1}")
                return False
            
            tool_results = [
                block for block in next_content
                if isinstance(block, dict) and "toolResult" in block
            ]
            
            if len(tool_uses) != len(tool_results):
                logger.error(
                    f"âš ï¸ Mismatch at index {i}: "
                    f"{len(tool_uses)} toolUse vs {len(tool_results)} toolResult"
                )
                return False
        
        return True
    
    def _normalize_messages(self, messages: List) -> List:
        normalized = []
        i = 0
        
        while i < len(messages):
            msg = messages[i]
            
            # SystemMessageì™€ HumanMessage(ì¼ë°˜)ëŠ” ê·¸ëŒ€ë¡œ ì¶”ê°€
            if isinstance(msg, SystemMessage):
                normalized.append(msg)
                i += 1
                continue
            
            if isinstance(msg, HumanMessage):
                # toolResultê°€ ì—†ëŠ” ì¼ë°˜ HumanMessage
                if not isinstance(msg.content, list):
                    normalized.append(msg)
                    i += 1
                    continue
                
                # toolResult í™•ì¸
                has_tool_result = any(
                    isinstance(block, dict) and "toolResult" in block
                    for block in msg.content
                )
                
                if not has_tool_result:
                    normalized.append(msg)
                    i += 1
                    continue
                
                # toolResultê°€ ìˆëŠ”ë° ì´ì „ ë©”ì‹œì§€ê°€ ì—†ê±°ë‚˜ AIMessageê°€ ì•„ë‹˜
                if not normalized or not isinstance(normalized[-1], AIMessage):
                    logger.warning(f"âš ï¸ Orphaned toolResult at index {i} - removing")
                    i += 1
                    continue
                
                # ì´ì „ AIMessageì˜ toolUse í™•ì¸
                prev_ai = normalized[-1]
                if not isinstance(prev_ai.content, list):
                    # ì´ì „ AIMessageì— toolUseê°€ ì—†ìŒ - toolResult ì œê±°
                    logger.warning(f"âš ï¸ toolResult without toolUse at index {i} - removing")
                    i += 1
                    continue
                
                tool_uses = [
                    block for block in prev_ai.content
                    if isinstance(block, dict) and "toolUse" in block
                ]
                
                if not tool_uses:
                    # ì´ì „ AIMessageì— toolUseê°€ ì—†ìŒ - toolResult ì œê±°
                    logger.warning(f"âš ï¸ toolResult without toolUse at index {i} - removing")
                    i += 1
                    continue
                
                # toolResult ê°œìˆ˜ í™•ì¸ ë° ì¡°ì •
                tool_results = [
                    block for block in msg.content
                    if isinstance(block, dict) and "toolResult" in block
                ]
                
                if len(tool_uses) == len(tool_results):
                    # ì •ìƒ - ê·¸ëŒ€ë¡œ ì¶”ê°€
                    normalized.append(msg)
                else:
                    # ë¶ˆì¼ì¹˜ - ì¡°ì •
                    logger.warning(
                        f"âš ï¸ Adjusting toolResult count at index {i}: "
                        f"{len(tool_uses)} toolUse vs {len(tool_results)} toolResult"
                    )
                    
                    # toolUse ê°œìˆ˜ë§Œí¼ toolResult ìœ ì§€
                    adjusted_results = tool_results[:len(tool_uses)]
                    
                    # ë¶€ì¡±í•˜ë©´ ë¹ˆ ê²°ê³¼ ì¶”ê°€
                    while len(adjusted_results) < len(tool_uses):
                        adjusted_results.append({
                            "toolResult": {
                                "toolUseId": tool_uses[len(adjusted_results)]["toolUse"]["toolUseId"],
                                "content": [{"text": "Normalized: Missing result"}]
                            }
                        })
                    
                    normalized.append(HumanMessage(content=adjusted_results))
                
                i += 1
                continue
            
            # AIMessage with toolUse ì²˜ë¦¬
            if isinstance(msg, AIMessage) and isinstance(msg.content, list):
                tool_uses = [
                    block for block in msg.content
                    if isinstance(block, dict) and "toolUse" in block
                ]
                
                if tool_uses:
                    # ë‹¤ìŒ ë©”ì‹œì§€ í™•ì¸
                    if i + 1 < len(messages) and isinstance(messages[i + 1], HumanMessage):
                        next_content = messages[i + 1].content
                        
                        if isinstance(next_content, list):
                            tool_results = [
                                block for block in next_content
                                if isinstance(block, dict) and "toolResult" in block
                            ]
                            
                            # ìŒì´ ì¼ì¹˜í•˜ë©´ ê·¸ëŒ€ë¡œ ì¶”ê°€
                            if len(tool_uses) == len(tool_results):
                                normalized.append(msg)
                                normalized.append(messages[i + 1])
                                i += 2
                                continue
                            else:
                                # ë¶ˆì¼ì¹˜ - toolUse ê°œìˆ˜ë§Œí¼ toolResult ì¡°ì •
                                logger.warning(
                                    f"âš ï¸ Normalizing mismatch at index {i}: "
                                    f"{len(tool_uses)} toolUse vs {len(tool_results)} toolResult"
                                )
                                
                                # toolUse ê°œìˆ˜ë§Œí¼ toolResult ìœ ì§€
                                adjusted_results = tool_results[:len(tool_uses)]
                                
                                # ë¶€ì¡±í•˜ë©´ ë¹ˆ ê²°ê³¼ ì¶”ê°€
                                while len(adjusted_results) < len(tool_uses):
                                    adjusted_results.append({
                                        "toolResult": {
                                            "toolUseId": tool_uses[len(adjusted_results)]["toolUse"]["toolUseId"],
                                            "content": [{"text": "Normalized: Missing result"}]
                                        }
                                    })
                                
                                normalized.append(msg)
                                normalized.append(HumanMessage(content=adjusted_results))
                                i += 2
                                continue
                    else:
                        # ë‹¤ìŒ ë©”ì‹œì§€ê°€ ì—†ê±°ë‚˜ HumanMessageê°€ ì•„ë‹˜ - toolUse ì œê±°
                        logger.warning(f"âš ï¸ Removing orphaned toolUse at index {i}")
                        msg_copy = AIMessage(content=[
                            block for block in msg.content
                            if not (isinstance(block, dict) and "toolUse" in block)
                        ])
                        
                        if msg_copy.content:
                            normalized.append(msg_copy)
                        
                        i += 1
                        continue
            
            # ì¼ë°˜ AIMessage (toolUse ì—†ìŒ)ëŠ” ê·¸ëŒ€ë¡œ ì¶”ê°€
            normalized.append(msg)
            i += 1
        
        return normalized

    # =============================
    # êµ¬ì²´ì ì¸ Agentê°€ êµ¬í˜„í•´ì•¼ í•  ë©”ì„œë“œ
    # =============================
    
    @abstractmethod
    def get_agent_role_prompt(self) -> str:
        """Agent ì—­í•  ì •ì˜ Prompt ë°˜í™˜"""
        pass

    # =============================
    # ê³µí†µ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _get_available_agents(self) -> str:
        """í˜„ì¬ Agentì—ì„œ ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡ ë°˜í™˜"""
        if hasattr(self, "allowed_agents"):
            agents = [name for name in self.allowed_agents if name != self.name]
        else:
            from agents.registry.agent_registry import AgentRegistry
            all_agents = AgentRegistry.list_agents()
            agents = [name for name in all_agents if name != self.name]
            
        logger.info(f"{agents} available for delegation from {self.name}")
        
        if not agents:
            return f"""ì—†ìŒ (ì´ ì—ì´ì „íŠ¸ê°€ ëª¨ë“  ì‘ì—…ì„ ì§ì ‘ ì²˜ë¦¬í•´ì•¼ í•¨)

**ë‹¹ì‹ ì˜ ì •ì²´ì„±: {self.name}**
**ìœ„ì„ ë¶ˆê°€: ìê¸° ìì‹ ({self.name})ì—ê²ŒëŠ” ì ˆëŒ€ ìœ„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**"""
        
        agent_list = "\n".join([f"- {agent}" for agent in agents])
        
        return f"""
[ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡]
{agent_list}

**ë‹¹ì‹ ì˜ ì •ì²´ì„±: {self.name}**
**ì£¼ì˜:** ìœ„ ëª©ë¡ì— ì—†ëŠ” Agent(íŠ¹íˆ ìê¸° ìì‹ ì¸ {self.name})ì—ê²ŒëŠ” ì ˆëŒ€ ìœ„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
"""
    
    def _get_available_agents_list(self) -> List[str]:
        """í˜„ì¬ Agentì—ì„œ ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
        if hasattr(self, "allowed_agents"):
            agents = [name for name in self.allowed_agents if name != self.name]
        else:
            from agents.registry.agent_registry import AgentRegistry
            all_agents = AgentRegistry.list_agents()
            agents = [name for name in all_agents if name != self.name]
        
        return agents
    
    async def _list_mcp_tools(self) -> List[Dict[str, Any]]:
        """MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ ë° í•„í„°ë§"""
        try:
            tools = await self.mcp.list_tools()
            tools_spec = []
            
            if hasattr(self, "allowed_tools"):
                if self.allowed_tools == 'ALL':
                    pass
                elif len(self.allowed_tools) == 0:
                    tools = []
                else:
                    tools = [t for t in tools if t.name in self.allowed_tools]

            for tool in tools:
                schema = tool.inputSchema or {}
                props = schema.get("properties", {})
                if not props:
                    continue
                tools_spec.append({
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "parameters": {
                            "type": schema.get("type", "object"),
                            "properties": {
                                k: {
                                    "type": p.get("type", "string"),
                                    "description": p.get("description", "")
                                } for k, p in props.items()
                            },
                            "required": schema.get("required", [])
                        },
                    },
                })
            logger.debug(f"[{self.name}] Retrieved {len(tools_spec)} tools")
            return tools_spec
        except Exception as e:
            logger.error(f"[{self.name}] Failed to list MCP tools: {e}")
            return []
    
    def _convert_mcp_to_bedrock_toolspec(
        self,
        mcp_tools: List[Dict[str, Any]]
    ) -> Optional[Dict]:
        """MCP tool specì„ Bedrock toolConfig í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        bedrock_tools = []
        
        from core.llm.llm_manger import _sanitize_extended_thinking_tokens
        
        # 1. MCP Tools ë³€í™˜
        if mcp_tools:
            for tool in mcp_tools:
                func = tool.get("function", {})
                params = func.get("parameters", {})
                
                tool_name = _sanitize_extended_thinking_tokens(func.get("name", "")).strip()
                
                description = func.get("description", "").strip()
                description = _sanitize_extended_thinking_tokens(description)
                
                if not description:
                    description = f"MCP tool: {tool_name}"
                
                bedrock_tools.append({
                    "toolSpec": {
                        "name": tool_name,
                        "description": description,
                        "inputSchema": {
                            "json": params
                        }
                    }
                })
        
        # 2. respond_intermediate Tool ì¶”ê°€
        bedrock_tools.append({
            "toolSpec": {
                "name": "respond_intermediate",
                "description": """ì¤‘ê°„ ë‹¨ê³„ ì‹ í˜¸. ì‚¬ìš©ìì—ê²Œ ìµœì¢… ì‘ë‹µì„ ì œê³µí•˜ê¸° ì „ì— ì¶”ê°€ ì‘ì—…(DB ì €ì¥, ë°ì´í„° ì²˜ë¦¬ ë“±)ì´ ë” í•„ìš”í•œ ê²½ìš° ì‚¬ìš©í•©ë‹ˆë‹¤.

ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ â†’ DB ì €ì¥ í•„ìš” â†’ ì €ì¥ í›„ ìµœì¢… ì‘ë‹µ
- ë°ì´í„° ì¡°íšŒ ì™„ë£Œ â†’ ì¶”ê°€ ê³„ì‚° í•„ìš” â†’ ê³„ì‚° í›„ ìµœì¢… ì‘ë‹µ
- ì¤‘ê°„ ê²°ê³¼ í™•ì¸ â†’ ê²€ì¦ í•„ìš” â†’ ê²€ì¦ í›„ ìµœì¢… ì‘ë‹µ

**ì¤‘ìš”**: 
- ì´ Tool ì‚¬ìš© í›„ í•„ìš”í•œ MCP Toolì„ í˜¸ì¶œí•˜ì—¬ ì‘ì—…ì„ ì™„ë£Œí•˜ì„¸ìš”
- ëª¨ë“  ì‘ì—… ì™„ë£Œ í›„ ìµœì¢… ì‘ë‹µì€ ë³„ë„ë¡œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤ (end_turn)
- ì´ Toolì€ "ì•„ì§ ì‘ì—…ì´ ë” í•„ìš”í•¨"ì„ ì•Œë¦¬ëŠ” ì‹ í˜¸ì¼ ë¿, ì‚¬ìš©ìì—ê²Œ ì§ì ‘ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤""",
                "inputSchema": {
                    "json": {
                        "type": "object",
                        "properties": {
                            "reason": {
                                "type": "string",
                                "description": "ì¶”ê°€ ì‘ì—…ì´ í•„ìš”í•œ ì´ìœ  (ì˜ˆ: 'DBì— ìƒë‹´ ë‚´ìš© ì €ì¥ í•„ìš”', 'í¬íŠ¸í´ë¦¬ì˜¤ ê³„ì‚° í›„ ì‘ë‹µ ìƒì„± í•„ìš”')"
                            }
                        },
                        "required": ["reason"]
                    }
                }
            }
        })
        
        # 3. delegate Tool ì¶”ê°€
        available_agents = self._get_available_agents_list()
        if available_agents:
            bedrock_tools.append({
                "toolSpec": {
                    "name": "delegate",
                    "description": """
                    ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—…ì„ ìœ„ì„í•©ë‹ˆë‹¤. í˜„ì¬ ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•  ìˆ˜ ì—†ê±°ë‚˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì „ë¬¸ì„±ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©í•©ë‹ˆë‹¤.
                    ë°˜ë“œì‹œ, í˜„ì¬ ì—ì´ì „íŠ¸ê°€ ìœ„ì„ ê°€ëŠ¥í•œ agentë¥¼ delegateí•´ì•¼ í•©ë‹ˆë‹¤. 
[delegate agents]
1. plan_input_agent
   - ì—­í• : ê¸°ë³¸ ì •ë³´ 8ê°€ì§€ ìˆ˜ì§‘ ë° ê²€ì¦
     * ì´ˆê¸° ìë³¸, í¬ë§ ì§€ì—­, í¬ë§ ì£¼íƒ ê°€ê²©, í¬ë§ ì£¼íƒ ìœ í˜•, ì†Œë“ ëŒ€ë¹„ ì‚¬ìš© ë¹„ìœ¨
     * ì´ë¦„, ë‚˜ì´, íˆ¬ìì„±í–¥ (Toolë¡œ ì¡°íšŒ)
   - ìœ„ì„ ì‹œì :
     * ì‚¬ìš©ì ì…ë ¥ ì •ë³´ê°€ ë“¤ì–´ì˜¨ ê²½ìš°
     * 8ê°€ì§€ ì •ë³´ ì¤‘ í•˜ë‚˜ë¼ë„ ì—†ëŠ” ê²½ìš°
     * ê²€ì¦ ì‹¤íŒ¨í•œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
     * ì´ë¦„/ë‚˜ì´/íˆ¬ìì„±í–¥ ì •ë³´ ì—†ëŠ” ê²½ìš°

2. validation_agent
   - ì—­í• : ê¸°ë³¸ ì •ë³´ 6ê°€ì§€ ê²€ì¦
     * initial_prop, hope_location, hope_price, hope_housing_type, income_usage_ratio, ratio_str
   - ìœ„ì„ ì‹œì :
     * ì •ë³´ê°€ ëª¨ì˜€ìœ¼ë‚˜ ê²€ì¦ ë¯¸ì™„ë£Œ
     * ê²€ì¦ ì‹¤íŒ¨ í›„ ì¬ì…ë ¥ëœ ê²½ìš°
     * ì´ë¯¸ ê²€ì¦ì´ ë˜ì—ˆìœ¼ë‚˜ ìƒˆë¡œìš´ ì…ë ¥ì´ ë“¤ì–´ì™€ ê²€ì¦ì´ í•„ìš”í•œ ê²½ìš°
     * í‰ê·  ì‹œì„¸ ë¹„êµ ë° í¬íŠ¸í´ë¦¬ì˜¤ ì €ì¥ í•„ìš”ì‹œ

3. loan_agent
   - ì—­í• : ëŒ€ì¶œ í•œë„, DSR/LTV, ìƒí™˜ êµ¬ì¡° ê³„ì‚°
   - ìœ„ì„ ì‹œì :
     * plan_input_agent ì™„ë£Œ í›„
     * ê¸°ë³¸ ì •ë³´ 6ê°€ì§€ ê²€ì¦ ì™„ë£Œ
     * ëŒ€ì¶œ ê²°ê³¼ ì—†ëŠ” ê²½ìš°

4. saving_agent
   - ì—­í• : ì˜ˆÂ·ì ê¸ˆ ì €ì¶• ì „ëµ ì„¤ê³„
   - ìœ„ì„ ì‹œì :
     * ì‚¬ìš©ìê°€ ì˜ˆê¸ˆ/ì ê¸ˆ ì „ëµ ìš”ì²­
     * ëŒ€ì¶œ í›„ ìê¸°ìë³¸ ë¶€ì¡±
     * ì˜ˆê¸ˆ/ì ê¸ˆ ìƒí’ˆ ì…ë ¥/ì„ íƒ/ì¶”ì²œ ìš”ì²­

5. fund_agent
   - ì—­í• : í€ë“œ/íˆ¬ì ì „ëµ ì œì•ˆ
   - ìœ„ì„ ì‹œì :
     * ì¶”ê°€ íˆ¬ì ìˆ˜ìµ ì–¸ê¸‰
     * 'í€ë“œ', 'ETF', 'íˆ¬ì', 'ìˆ˜ìµë¥ ' í‚¤ì›Œë“œ ì‚¬ìš©

6. summary_agent
   - ì—­í• : ìµœì¢… ì£¼íƒ ìê¸ˆ ê³„íš ë¦¬í¬íŠ¸ ì‘ì„±
   - ìœ„ì„ ì‹œì :
     * ì£¼ìš” ë‹¨ê³„ ëŒ€ë¶€ë¶„ ì™„ë£Œ
     * 'ì „ì²´ ìš”ì•½', 'ìµœì¢… ê³„íš', 'ë¦¬í¬íŠ¸', 'ì •ë¦¬' ìš”ì²­
                    """,
                    "inputSchema": {
                        "json": {
                            "type": "object",
                            "properties": {
                                "agent_name": {
                                    "type": "string",
                                    "description": f"ìœ„ì„í•  ì—ì´ì „íŠ¸ ì´ë¦„. ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸: {', '.join(available_agents)}",
                                    "enum": available_agents
                                },
                                "reason": {
                                    "type": "string",
                                    "description": "ìœ„ì„ ì´ìœ  ë° ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸"
                                }
                            },
                            "required": ["agent_name", "reason"]
                        }
                    }
                }
            })
        
        logger.info(f"[{self.name}] âœ… Created Bedrock toolConfig: {len(bedrock_tools)} tools (MCP: {len(mcp_tools) if mcp_tools else 0}, respond_intermediate: 1, delegate: {1 if available_agents else 0})")
        
        return {
            "tools": bedrock_tools
        }

    async def _execute_mcp_tool(
        self,
        tool_name: str,
        tool_args: Dict[str, Any]
    ) -> Any:
        """MCP ë„êµ¬ ì‹¤í–‰"""
        try:
            result = await self.mcp.call_tool(tool_name, tool_args)
            logger.info(f"[{self.name}] Tool '{tool_name}' Result : {result}")
            logger.info(f"[{self.name}] Tool '{tool_name}' executed successfully")
            return result
        except Exception as e:
            logger.error(f"[{self.name}] Tool '{tool_name}' execution failed: {e}")
            raise
    
    def _remove_think_tag(self, text: str) -> str:
        """</think> íƒœê·¸ ì œê±° ë° JSON ì¶”ì¶œ"""
        if "</think>" in text:
            text = text.rsplit("</think>", 1)[-1]
        elif "<think>" in text:
            text = text.rsplit("<think>", 1)[-1]

        text = text.strip()
        
        start_idx = text.find("{")
        end_idx = text.rfind("}")
        
        if start_idx != -1 and end_idx != -1:
            text = text[start_idx : end_idx + 1]
        
        return text

    # =============================
    # ê¸°íƒ€ ê³µí†µ ë©”ì„œë“œ
    # =============================
    
    def validate_input(self, state: AgentState) -> bool:
        """ì…ë ¥ ìƒíƒœ ê²€ì¦"""
        if "messages" not in state or not isinstance(state["messages"], list):
            logger.error(f"[{self.name}] Invalid messages field")
            return False
        
        is_valid, error_msg = StateValidator.validate_execution_state(state)
        if not is_valid:
            logger.error(f"[{self.name}] Invalid execution state: {error_msg}")
            return False
        
        return True

    def pre_execute(self, state: AgentState) -> AgentState:
        """ì‹¤í–‰ ì „ ì „ì²˜ë¦¬"""
        return state

    def _validate_config(self):
        """ì„¤ì • ê²€ì¦"""
        if not self.config.name:
            raise ValueError("Agent name is required")

    def _log_start(self, state: AgentState):
        """ì‹¤í–‰ ì‹œì‘ ë¡œê¹…"""
        logger.info(f"[{self.name}] Starting execution")
        logger.info(f"   Session ID: {state.get('session_id', 'unknown')}")
        logger.info(f"   Messages: {len(state.get('messages', []))}")

    def _log_end(self, state: AgentState):
        """ì‹¤í–‰ ì™„ë£Œ ë¡œê¹…"""
        logger.info(f"[{self.name}] Execution completed")
        logger.info(f"   Final Status: {state.get('status', 'unknown')}")
        logger.info(f"   Iterations: {state.get('iteration', 0)}")
        logger.info(f"   Tool Calls: {len(state.get('tool_calls', []))}")