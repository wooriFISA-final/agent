import os
import re
import json
<<<<<<< HEAD
import logging
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

# ----------------------------------
# í™˜ê²½ ì„¤ì • ë° ë¡œê¹…
# ----------------------------------
load_dotenv()
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# ----------------------------------
# ê¸ˆì•¡ ë‹¨ìœ„ ë³€í™˜ í•¨ìˆ˜
# ----------------------------------
def parse_korean_currency(value: Any) -> int:
    """'3ì–µ 5ì²œ' ê°™ì€ ê¸ˆì•¡ í‘œí˜„ì„ ì •ìˆ˜(ì›)ë¡œ ë³€í™˜"""
    if value is None or value == "":
        return 0
    if isinstance(value, (int, float)):
        return int(value)
    value = str(value).replace(",", "").replace(" ", "")
    total = 0
    for pattern, multiplier in [
        (r"(\d+(?:\.\d+)?)ì–µ", 100_000_000),
        (r"(\d+(?:\.\d+)?)ì²œë§Œ", 10_000_000),
        (r"(\d+(?:\.\d+)?)ë°±ë§Œ", 1_000_000),
        (r"(\d+(?:\.\d+)?)ë§Œ", 10_000),
    ]:
        match = re.search(pattern, value)
        if match:
            total += float(match.group(1)) * multiplier
    if total == 0:
        try:
            total = int(float(re.sub(r"[^0-9]", "", value)))
        except ValueError:
            total = 0
    return int(total)

# ----------------------------------
# PlanInputAgent (í•œ ë…¸ë“œ = í•œ ì—ì´ì „íŠ¸)
# ----------------------------------
class PlanInputAgent:
    def __init__(self, model_name: str = "qwen3:8b"):
        self.llm = ChatOllama(model=model_name, temperature=0.3)
        self.system_prompt = SystemMessage(content="""
[íŽ˜ë¥´ì†Œë‚˜(Persona)]
ë‹¹ì‹ ì€ 'ìš°ë¦¬ì€í–‰ ì£¼íƒ ìžê¸ˆ ì„¤ê³„ ì»¨ì„¤í„´íŠ¸ AI'ìž…ë‹ˆë‹¤.
ê³ ê°ì˜ ëŒ€ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ê²°ì •í•˜ê³ ,
í˜„ìž¬ê¹Œì§€ í™•ë³´í•œ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.

---

[TASK]
1. ì•„ëž˜ 5ê°€ì§€ í•µì‹¬ ì •ë³´ë¥¼ ëª¨ë‘ ìˆ˜ì§‘í•´ì•¼ í•©ë‹ˆë‹¤:
   - initial_prop : ì´ˆê¸° ìžì‚°
   - hope_location : í¬ë§ ì§€ì—­
   - hope_price : í¬ë§ ì£¼íƒ ê°€ê²©
   - hope_housing_type : ì£¼íƒ ìœ í˜•
   - income_usage_ratio : ì›”ê¸‰ ì‚¬ìš© ë¹„ìœ¨
2. ì´ë¯¸ í™•ë³´ëœ ì •ë³´ëŠ” ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.  
3. í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ í•˜ì„¸ìš”.  
4. ëª¨ë“  ì •ë³´ë¥¼ í™•ë³´í•˜ë©´ â€œis_completeâ€: trueë¡œ ì„¤ì •í•˜ê³ , â€œnext_questionâ€ì€ ë¹ˆ ë¬¸ìžì—´ë¡œ ë‘ì„¸ìš”.
5. ìž…ë ¥ê°’ì— 'ì–µ', 'ì²œë§Œ', 'ë§Œ' ë“±ì˜ ë‹¨ìœ„ê°€ ì´ë¯¸ ìˆ«ìžë¡œ ë³€í™˜ë˜ì–´ ìžˆë‹¤ë©´ **ì¶”ê°€ ê³±ì…ˆì„ í•˜ì§€ ë§ˆì„¸ìš”**.
6. ì˜ˆ: ì‚¬ìš©ìžê°€ 3ì–µì´ë¼ê³  ìž…ë ¥í•œ ê²½ìš° â†’ 300000000ìœ¼ë¡œ ë³€í™˜
7. ì´ë¯¸ ìˆ«ìžë¡œ ë“¤ì–´ì˜¨ ê°’(300000000 ë“±)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.
8. 10ë°°, 100ë°°ë¥¼ ë” ê³±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

---

[ì¶œë ¥ í˜•ì‹(JSON)]
{
  "next_question": "í¬ë§í•˜ì‹œëŠ” ì£¼íƒì˜ ìœ„ì¹˜ëŠ” ì–´ë””ì¸ê°€ìš”?",
  "collected_info": {
    "initial_prop": "3000ë§Œì›",
    "hope_location": "ì„œìš¸ ë§ˆí¬êµ¬"
  },
  "is_complete": false
}

âš ï¸ ì ˆëŒ€ í•œêµ­ì–´ ì„¤ëª…ë¬¸, ì½”ë“œë¸”ë¡, ë°±í‹±, ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
""")

    # -------------------------------
    # ë‚´ë¶€ íŒŒì„œ
    # -------------------------------
    def _parse_value(self, field: str, value: str):
        if field in ["initial_prop", "hope_price"]:
            return parse_korean_currency(value)
        elif field == "income_usage_ratio":
            try:
                return int(str(value).replace("%", "").strip())
            except:
                return 0
        return str(value).strip()

    # -------------------------------
    # ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (LangGraph Node)
    # -------------------------------
    async def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """í•œ ë…¸ë“œë¡œì¨ ë™ìž‘"""
        user_id = state.get("user_id", 1)
        conversation = state.get("messages", [])
        collected_info = state.get("extracted_info", {}) or {}

        # LLM í˜¸ì¶œ
        messages = [self.system_prompt] + conversation
        response = self.llm.invoke(messages)
        raw_output = response.content.strip()
        logger.info(f"ðŸ“¨ LLM ì¶œë ¥(raw): {raw_output}")

        # JSON íŒŒì‹±
        match = re.search(r"\{[\s\S]*\}", raw_output)
        parsed = None
        if match:
            try:
                parsed = json.loads(match.group(0))
            except Exception as e:
                logger.error(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        if not parsed:
            return {
                "user_id": user_id,
                "extracted_info": collected_info,
                "input_completed": False,
                "messages": [AIMessage(content="ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?")]
            }

        # ì •ë³´ ë³‘í•©
        for k, v in parsed.get("collected_info", {}).items():
            if v and k not in collected_info:
                collected_info[k] = self._parse_value(k, v)

        is_complete = parsed.get("is_complete", False)
        next_q = parsed.get("next_question", "")

        if is_complete:
            logger.info(f"âœ… ìž…ë ¥ ì™„ë£Œ: {collected_info}")
            return {
                "user_id": user_id,
                "extracted_info": collected_info,
                "input_completed": True,
                "messages": [AIMessage(content="âœ… ëª¨ë“  ì •ë³´ê°€ ìž…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€ì¦ì„ ì‹œìž‘í•˜ê² ìŠµë‹ˆë‹¤.")]
            }

        return {
            "user_id": user_id,
            "extracted_info": collected_info,
            "input_completed": False,
            "messages": [AIMessage(content=next_q)]
        }
=======
from dotenv import load_dotenv

# ------------------------------------------------
# 1. (ìˆ˜ì •) í•„ìš”í•œ LangChain ë° Typing ëª¨ë“ˆ ìž„í¬íŠ¸
# ------------------------------------------------
import logging
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from sqlalchemy import create_engine, Column, Integer, String, BigInteger, Enum, ForeignKey, DateTime
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy.sql import func
from typing import TypedDict, Annotated, Dict, Any, List, Optional
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage
import operator

# ------------------------------------------------
# (2) DB ì„¤ì • ë° ëª¨ë¸ ì •ì˜ (ë‹˜ì˜ ì½”ë“œì™€ ë™ì¼)
# ------------------------------------------------
load_dotenv()
DB_USER = os.getenv("user")
DB_PASSWORD = os.getenv("password")
DB_HOST = os.getenv("host")
DB_NAME = os.getenv("database")

Base = declarative_base()
engine = create_engine(f"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}", echo=False)
Session = sessionmaker(bind=engine)
session = Session()

# (UserInfo, PlanInput í…Œì´ë¸” ëª¨ë¸ - ë‹˜ì˜ ì½”ë“œì™€ ë™ì¼)
class UserInfo(Base):
    __tablename__ = "user_info"
    user_id = Column(Integer, primary_key=True, autoincrement=True)
    name = Column(String(50), nullable=False) 
    age = Column(Integer)
    gender = Column(Enum('M', 'F'))
    region = Column(String(100))
    income = Column(BigInteger)
    monthly_salary = Column(BigInteger)
    job_type = Column(String(50))
    employment_years = Column(Integer)

class PlanInput(Base):
    __tablename__ = "plan_input"
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_id = Column(Integer, ForeignKey("user_info.user_id", ondelete="CASCADE"), nullable=False)
    target_house_price = Column(BigInteger)
    target_location = Column(String(100))
    housing_type = Column(String(50))
    available_assets = Column(BigInteger)
    income_usage_ratio = Column(Integer)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

Base.metadata.create_all(engine)

# ------------------------------------------------
# (3) (í•„ìˆ˜) LangGraph 'í†µí•©' ìƒíƒœ ì •ì˜
# (ì´ íŒŒì¼ì´ 'plan_graph.py'ì—ì„œ importë  ë•Œë¥¼ ëŒ€ë¹„í•´, 
#  'plan_graph.py'ì˜ AgentGraphStateì™€ ë™ì¼í•œ êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤)
# ------------------------------------------------
class AgentGraphState(TypedDict):
    """
    ê·¸ëž˜í”„ ì „ì²´ë¥¼ íë¥´ëŠ” ê³µìš© ë©”ëª¨ë¦¬
    (ì´ ë…¸ë“œëŠ” 'messages'ì™€ 'user_id'ë¥¼ ì½ê³ , 
     'input_completed', 'plan_input_data', 'plan_id', 'messages'ë¥¼ ì”ë‹ˆë‹¤)
    """
    # (Input)
    user_id: int
    messages: Annotated[List[BaseMessage], operator.add] 
    
    # (íŒŒì¼ ê²½ë¡œ)
    fund_data_path: Optional[str]
    savings_data_path: Optional[str]
    
    # (Flags)
    input_completed: bool
    validation_passed: bool
    
    # (Data)
    plan_input_data: Dict[str, Any]
    plan_id: Optional[int]
    user_mydata: Optional[Dict[str, Any]]
    loan_recommendations: Optional[Dict[str, Any]]
    savings_recommendations: Optional[Dict[str, Any]]
    fund_analysis_result: Optional[Dict[str, Any]]
    final_plan: Optional[Dict[str, Any]]
    error_message: Optional[str]


# ------------------------------------------------
# (4) ðŸŸ¢ (ìˆ˜ì •) InputAgentNode í´ëž˜ìŠ¤ ì •ì˜ ðŸŸ¢
# (PlanAgentNode -> InputAgentNodeë¡œ ì´ë¦„ ë³€ê²½)
# ------------------------------------------------
class InputAgentNode:
    """
    (ìˆ˜ì •) í„´ì œ(Turn-based) ëŒ€í™”ë¥¼ í†µí•´ ì‚¬ìš©ìžë¡œë¶€í„° ìž¬ë¬´ ê³„íš ìž…ë ¥ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    FastAPI ì„œë²„ì™€ ì—°ë™ë˜ë©°, 'while True' ë£¨í”„ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """

    def __init__(self, model="qwen3:8b"):
        
        self.required_info = {
            "target_house_price": "ëª©í‘œ ì£¼íƒ ê°€ê²© (ì› ë‹¨ìœ„, ìˆ«ìžë§Œ)",
            "target_location": "ì£¼íƒ ìœ„ì¹˜ (ì˜ˆ: ì„œìš¸ ì†¡íŒŒêµ¬, ë¶€ì‚°ê´‘ì—­ì‹œ)",
            "housing_type": "ì£¼ê±°ì§€ í˜•íƒœ (ì•„íŒŒíŠ¸, ì—°ë¦½/ë‹¤ì„¸ëŒ€, ë‹¨ë…ì£¼íƒ, ì˜¤í”¼ìŠ¤í…” ì¤‘ í•˜ë‚˜)",
            "available_assets": "í˜„ìž¬ ì‚¬ìš© ê°€ëŠ¥í•œ ìžì‚° (ì› ë‹¨ìœ„, ìˆ«ìžë§Œ)",
            "income_usage_ratio": "ì›”ê¸‰ì—ì„œ ì €ì¶•/íˆ¬ìžì— ì‚¬ìš©í•  ë¹„ìœ¨ (í¼ì„¼íŠ¸, ìˆ«ìžë§Œ)"
        }
        
        # --- (ìˆ˜ì •) LangChain 'chain'ìœ¼ë¡œ ë³€ê²½ (LangSmith ì¶”ì  ê°€ëŠ¥) ---
        try:
            llm = ChatOllama(model=model, temperature=0.0)
            system_prompt = f"""
            ë‹¹ì‹ ì€ ì‚¬ìš©ìžì˜ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìž¬ë¬´ ê³„íšì— í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” AIìž…ë‹ˆë‹¤.
            ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í•­ëª©ë“¤ì„ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤.
            
            [ì¶”ì¶œ í•­ëª©]
            {json.dumps(self.required_info, indent=2, ensure_ascii=False)}

            [ê·œì¹™]
            1. ëª¨ë“  í•­ëª©ì„ ë°˜ë“œì‹œ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ "ì •ë³´ ë¶€ì¡±"ì´ë¼ê³  ëª…í™•ížˆ í‘œì‹œí•˜ì„¸ìš”.
            2. 'housing_type'ì€ ë°˜ë“œì‹œ [ì•„íŒŒíŠ¸, ì—°ë¦½/ë‹¤ì„¸ëŒ€, ë‹¨ë…ì£¼íƒ, ì˜¤í”¼ìŠ¤í…”] ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
            3. ì‚¬ìš©ìžê°€ "10ì–µ"ì´ë¼ê³  ë§í•˜ë©´ "1000000000"ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
            4. 'income_usage_ratio'ëŠ” "50%"ë¼ê³  í•˜ë©´ "50"ìœ¼ë¡œ ìˆ«ìžë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
            5. ìµœì¢… ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ëª…ì€ ë¶™ì´ì§€ ë§ˆì„¸ìš”.
            """
            
            prompt_template = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", "ë‹¤ìŒì€ í˜„ìž¬ê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡ìž…ë‹ˆë‹¤:\n\n{conversation_history_str}\n\nìœ„ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ 5ê°€ì§€ í•­ëª©ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.")
            ])
            
            # (LangChain ì²´ì¸ ì •ì˜)
            self.llm_chain = prompt_template | llm | StrOutputParser() | self._parse_llm_json

        except Exception as e:
            print(f"LLM ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.llm_chain = None
    
    # --- (ì¶”ê°€) LangChain ì²´ì¸ìš© íŒŒì„œ ---
    def _parse_llm_json(self, llm_output: str):
        try:
            json_match = re.search(r"\{.*\}", llm_output, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                extracted_data = json.loads(json_str)
                return extracted_data, None 
            else:
                raise json.JSONDecodeError("No JSON object found", llm_output, 0)
        except json.JSONDecodeError as e:
            print(f"[LLM íŒŒì‹± ì˜¤ë¥˜] LLM ì‘ë‹µ: {llm_output}")
            return None, f"LLMì´ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}"

    # --- (ìˆ˜ì •) ë‹˜ì˜ í•¨ìˆ˜ë“¤ì„ í´ëž˜ìŠ¤ ë‚´ë¶€ ë©”ì„œë“œë¡œ ë³€ê²½ ---
    def _normalize_location(self, location: str):
        # (ë‹˜ì˜ normalize_location ì½”ë“œ)
        location = location.strip()
        if location.startswith("ì„œìš¸"):
            return location
        match = re.match(r"^(\S+ì‹œ|\S+íŠ¹ë³„ìžì¹˜ì‹œ)", location)
        if match:
            normalized = match.group(1)
            print(f"ìž…ë ¥í•˜ì‹  ì§€ì—­ '{location}'ì€ '{normalized}' í‰ê·  ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
            return normalized
        return location

    def _save_to_db(self, data: dict, user_id: int):
        # (ë‹˜ì˜ save_to_db ì½”ë“œ)
        print(f"\n[DB ì €ìž¥ ì‹œë„] user_id: {user_id}")
        try:
            processed_data = {
                "target_house_price": int(data["target_house_price"]),
                "target_location": data["target_location"],
                "housing_type": data["housing_type"],
                "available_assets": int(data["available_assets"]),
                "income_usage_ratio": int(data["income_usage_ratio"]),
                "user_id": user_id
            }
            record = PlanInput(**processed_data)
            session.add(record)
            session.commit()
            print(f"[DB ì €ìž¥ ì™„ë£Œ] plan_id: {record.id}")
            return record.id 
        except Exception as e:
            session.rollback()
            print(f"[DB ì €ìž¥ ì˜¤ë¥˜] ë¡¤ë°± ìˆ˜í–‰. ì˜¤ë¥˜: {e}")
            return None
            
    def _summarize(self, responses):
        # (ë‹˜ì˜ summarize ì½”ë“œ)
        pass

    # ------------------------------------------------
    # (í•µì‹¬ ìˆ˜ì •) ðŸŸ¢ LangGraph ë…¸ë“œ ì‹¤í–‰ í•¨ìˆ˜ ðŸŸ¢
    # (run_as_node -> run, 'while True' ë£¨í”„ ì œê±°)
    # ------------------------------------------------
    def run(self, state: AgentGraphState) -> Dict[str, Any]:
        """
        (ìˆ˜ì •) ì´ í•¨ìˆ˜ê°€ LangGraphì— 'ë…¸ë“œ'ë¡œ ë“±ë¡ë  ì‹¤ì œ ì‹¤í–‰ í•¨ìˆ˜ìž…ë‹ˆë‹¤.
        'while True' ë£¨í”„ ì—†ì´ 'ë‹¨ í•œ ë²ˆ' ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        print("\n--- [ë…¸ë“œ 0] 'ìž…ë ¥ ìˆ˜ì§‘ ë…¸ë“œ' ì‹¤í–‰ ---")
        
        if not self.llm_chain:
            return {
                "input_completed": False, 
                "messages": [AIMessage(content="ì˜¤ë¥˜: LLM ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìžì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")]
            }

        # 1. Stateì—ì„œ í˜„ìž¬ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
        messages_list = state["messages"]
        user_id = state["user_id"]

        # 2. ëŒ€í™” ê¸°ë¡ì„ LLMì— ì „ë‹¬í•  ë¬¸ìžì—´ë¡œ ë³€í™˜
        history_str = "\n".join([f"{msg.type}: {msg.content}" for msg in messages_list])
        
        # 3. LLM ì²´ì¸ 'ë‹¨ í•œ ë²ˆ' í˜¸ì¶œ (ì •ë³´ ì¶”ì¶œ)
        extracted_data, error = self.llm_chain.invoke({"conversation_history_str": history_str})
        
        if error:
            print(f"[LLM íŒŒì‹± ì˜¤ë¥˜] {error}")
            return {
                "input_completed": False,
                "messages": [AIMessage(content=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. {error}. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?")]
            }

        # 4. ì •ë³´ê°€ ë¶€ì¡±í•œì§€ í™•ì¸
        missing_info = []
        for key, desc in self.required_info.items():
            if not extracted_data.get(key) or extracted_data.get(key) == "ì •ë³´ ë¶€ì¡±":
                missing_info.append(desc)
        
        # 5. ë¶„ê¸° ì²˜ë¦¬ (ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ vs ì¶”ê°€ ì§ˆë¬¸)
        if not missing_info:
            # 5-A: ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ
            print("[ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ. DB ì €ìž¥ ë° ë‹¤ìŒ ë…¸ë“œë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.]")
            
            # (ìœ„ì¹˜ ì •ê·œí™” ì ìš©)
            extracted_data["target_location"] = self._normalize_location(extracted_data["target_location"])
            
            # (DB ì €ìž¥)
            plan_id = self._save_to_db(extracted_data, user_id)
            
            if plan_id:
                return {
                    "plan_input_data": extracted_data, # â¬…ï¸ ë‹¤ìŒ ë…¸ë“œë“¤ì´ ì‚¬ìš©í•  ë°ì´í„°
                    "plan_id": plan_id,
                    "input_completed": True, # â¬…ï¸ ë‹¤ìŒ ë…¸ë“œë¡œ ê°€ë¼ëŠ” ì‹ í˜¸
                    "messages": [AIMessage(content=f"ëª¨ë“  ì •ë³´(Plan ID: {plan_id})ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€ì¦(Validation)ì„ ì‹œìž‘í•©ë‹ˆë‹¤.")]
                }
            else:
                return {
                    "input_completed": False, # â¬…ï¸ ê·¸ëž˜í”„ ì¢…ë£Œ ì‹ í˜¸
                    "messages": [AIMessage(content="ì •ë³´ ìˆ˜ì§‘ì— ì„±ê³µí–ˆìœ¼ë‚˜, DB ì €ìž¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")]
                }
        else:
            # 5-B: ì •ë³´ ë¶€ì¡± (ì¶”ê°€ ì§ˆë¬¸)
            missing_str = ", ".join(missing_info)
            ai_question = f"ë§ì”€ ê°ì‚¬í•©ë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ {missing_str} ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?"
            print(f"[ì •ë³´ ë¶€ì¡±] AI ì¶”ê°€ ì§ˆë¬¸: {ai_question}")
            
            return {
                "input_completed": False, # â¬…ï¸ ê·¸ëž˜í”„ ì¢…ë£Œ ì‹ í˜¸ (ëŒ€ê¸°)
                "messages": [AIMessage(content=ai_question)]
            }

# ------------------------------------------------
# (5) (í…ŒìŠ¤íŠ¸) VS Codeì—ì„œ ì´ íŒŒì¼ë§Œ ë‹¨ë…ìœ¼ë¡œ ì‹¤í–‰
# (python agent/plan_agents/input_agent.py)
# ------------------------------------------------
if __name__ == "__main__":
    
    # (ë¡œê¹… ì„¤ì •)
    logging.basicConfig(level=logging.INFO)
    
    # 1. ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤í™”
    input_node = InputAgentNode(model="qwen3:8b")

    # 2. (ê°€ìƒ) í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²« ë²ˆì§¸ ìš”ì²­ì´ ë“¤ì–´ì˜´
    print("--- 1ì°¨ í˜¸ì¶œ (ì •ë³´ ë¶€ì¡±) ---")
    initial_messages = [HumanMessage(content="ì„œìš¸ì— 10ì–µì§œë¦¬ ì•„íŒŒíŠ¸ ì‚¬ê³  ì‹¶ì–´ìš”")]
    initial_state_input = {
        "user_id": 1, # (í…ŒìŠ¤íŠ¸ìš© user_id)
        "messages": initial_messages
    }
    
    # 3. ë…¸ë“œ ì‹¤í–‰
    # (AgentGraphStateì˜ ëª¨ë“  í‚¤ê°€ í•„ìš”í•˜ì§€ë§Œ, í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ dictë¡œ ìž„ì‹œ ì „ë‹¬)
    state_after_1st_call = input_node.run(initial_state_input)
    
    # 4. AIì˜ ì¶”ê°€ ì§ˆë¬¸ ì¶œë ¥
    print("\n[AI ì‘ë‹µ (í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬)]")
    # (messagesëŠ” BaseMessage ê°ì²´ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ .contentë¡œ ì ‘ê·¼)
    print(state_after_1st_call["messages"][-1].content)
    
    # 5. (ê°€ìƒ) ì‚¬ìš©ìžê°€ AIì˜ ì§ˆë¬¸ì— ë‹µë³€í•¨
    # (ì‹¤ì œë¡œëŠ” state_after_1st_call["messages"]ë¥¼ ëˆ„ì í•´ì•¼ í•¨)
    messages_2 = [
        HumanMessage(content="ì„œìš¸ì— 10ì–µì§œë¦¬ ì•„íŒŒíŠ¸ ì‚¬ê³  ì‹¶ì–´ìš”"),
        AIMessage(content=state_after_1st_call["messages"][-1].content),
        HumanMessage(content="í˜„ìž¬ ìžì‚°ì€ 2ì–µì´ê³ , ì›”ê¸‰ì˜ 50%ë¥¼ ì“¸ ìˆ˜ ìžˆì–´ìš”.")
    ]
    state_input_2 = {
        "user_id": 1,
        "messages": messages_2
    }
    
    # 6. (ê°€ìƒ) í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë‘ ë²ˆì§¸ ìš”ì²­ì´ ë“¤ì–´ì˜´
    print("\n\n--- 2ì°¨ í˜¸ì¶œ (ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ) ---")
    state_after_2nd_call = input_node.run(state_input_2)
    
    # 7. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n[AI ì‘ë‹µ (í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬)]")
    print(state_after_2nd_call["messages"][-1].content)
    
    print("\n[ìµœì¢… ìˆ˜ì§‘ëœ ë°ì´í„°]")
    print(json.dumps(state_after_2nd_call.get("plan_input_data"), indent=2, ensure_ascii=False))
>>>>>>> c35374b0f210d38053de68412e5413857b8674da
