import json
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from pathlib import Path 
import operator
from typing import TypedDict, Annotated, Dict, Any 
from langgraph.graph import StateGraph, END 


# LangGraph ìƒíƒœ ì •ì˜
# (í´ë˜ìŠ¤ ë°–ì— ì •ì˜í•˜ì—¬ ê·¸ë˜í”„ ì „ì²´ì—ì„œ ê³µìœ )
class FundAgentState(TypedDict):
    fund_data_path: str
    fund_analysis_result: dict


# 'ì „ì—­' í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
FUND_ANALYST_PROMPT = """
[Persona]
ë‹¹ì‹ ì€ ìµœê³ ì˜ í€ë“œ ìƒí’ˆ ë¶„ì„ê°€(FundAnalyst)ì…ë‹ˆë‹¤. íŠ¹íˆ ê¸ˆìœµ ì´ˆë³´ìì—ê²Œ ë³µì¡í•œ ìƒí’ˆì„ ë§¤ìš° ì‰½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

[Task]
- ì…ë ¥ë°›ì€ [Raw Fund Data]ë¥¼ ë¶„ì„í•˜ì—¬, ê° 'ë¦¬ìŠ¤í¬ ë ˆë²¨'ë³„ë¡œ 'ì˜ˆìƒ ìˆ˜ìµë¥ 'ì´ ê°€ì¥ ë†’ì€ ìƒí’ˆ 1ê°œì”©ì„ ì„ ë³„í•©ë‹ˆë‹¤.
- ì„ ë³„ëœ ê° ìƒí’ˆì˜ ì„¤ëª…('description')ì„ ì´ˆë³´ìê°€ ì¦‰ì‹œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê°„ê²°í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.

[Instructions]
1. ì…ë ¥ë°›ì€ [Raw Fund Data] ëª©ë¡ ì „ì²´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
2. í€ë“œ ëª©ë¡ì„ 'risk_level' (ì˜ˆ: 'ë†’ì€ ìœ„í—˜', 'ì¤‘ê°„ ìœ„í—˜', 'ë‚®ì€ ìœ„í—˜') ë³„ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.
3. ê° ë¦¬ìŠ¤í¬_ë ˆë²¨ ê·¸ë£¹ ë‚´ì—ì„œ 'expected_return'(ì˜ˆìƒ ìˆ˜ìµë¥ )ì´ ê°€ì¥ ë†’ì€ ìƒí’ˆì„ **ë‹¨ í•˜ë‚˜ë§Œ** ì„ ì •í•©ë‹ˆë‹¤.
4. (ì¤‘ìš”) ì„ ì •ëœ ê° ìƒí’ˆì˜ 'description'(ì„¤ëª… ì›ë¬¸)ì„ ë¶„ì„í•˜ì—¬, **ê¸ˆìœµ ì´ˆë³´ì**ê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹¨ì–´ë¡œ í•µì‹¬ ë‚´ìš©(ì–´ë””ì— íˆ¬ìí•˜ëŠ”ì§€, ëª©í‘œëŠ” ë¬´ì—‡ì¸ì§€)ì„ ìš”ì•½í•©ë‹ˆë‹¤.
5. ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì§€ì •ëœ [Output Format]ì— ë§ì¶° ì •í™•í•˜ê²Œ ë°˜í™˜í•©ë‹ˆë‹¤.

[Raw Fund Data (Input)]
{input_data}

[Output Format (Return this)]
<analysis_result>
{{
  "recommendations": [
    {{
      "risk_level": "ë†’ì€ ìœ„í—˜",
      "product_name": "ì˜ˆì‹œ í€ë“œ A",
      "expected_return": "12.5%",
      "summary_for_beginner": "AIì™€ ë°˜ë„ì²´ì²˜ëŸ¼ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ëŠ” ê¸°ìˆ  ê¸°ì—…ì— ì§‘ì¤‘ íˆ¬ìí•©ë‹ˆë‹¤."
    }}
  ]
}}
</analysis_result>
"""

# LangGraph ë…¸ë“œ í´ë˜ìŠ¤ ì •ì˜
class FundAgentNode:

    def __init__(self):
        """
        í´ë˜ìŠ¤ê°€ ìƒì„±ë  ë•Œ LLM, í”„ë¡¬í”„íŠ¸, ì²´ì¸ì„ í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        print("--- FundAgentNode ì´ˆê¸°í™” ---")
        try:
            # LLM ì •ì˜
            self.llm = ChatOllama(model="qwen3:8b") 
            print("--- 8. ë¡œì»¬ Ollama (qwen3:8b) ëª¨ë¸ ë¡œë“œ ì„±ê³µ ---")
        except Exception as e:
            print(f"Ollama ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("Ollama ë°ìŠ¤í¬íƒ‘ ì•±ì´ ì‹¤í–‰ ì¤‘ì¸ì§€, 'ollama pull qwen3:8b'ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            exit() 

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        self.prompt_template = ChatPromptTemplate.from_template(FUND_ANALYST_PROMPT)

        # ì²´ì¸ ìƒì„±
        self.chain = self.prompt_template | self.llm | StrOutputParser() | self._parse_analysis_result
        
        print("--- LLM ì²´ì¸ êµ¬ì„± ì™„ë£Œ ---")

    # 'íŒŒì„œ'ë¥¼ í´ë˜ìŠ¤ ë‚´ë¶€ ë©”ì„œë“œë¡œ ì •ì˜
    def _parse_analysis_result(self, llm_output: str):
        """
        LLMì˜ ì¶œë ¥ì´ <analysis_result>, ```json (ë°±í‹±),
        '''json (ì‘ì€ë”°ì˜´í‘œ) ë“± ì–´ë–¤ í˜•ì‹ì´ë“  ì²˜ë¦¬í•˜ëŠ” íŒŒì„œ
        """
        try:
            if "```json" in llm_output:
                result_str = llm_output.split("```json")[1].split("```")[0].strip()
            elif "'''json" in llm_output:
                result_str = llm_output.split("'''json")[1].split("'''")[0].strip()
            elif "<analysis_result>" in llm_output:
                result_str = llm_output.split("<analysis_result>")[1].split("</analysis_result>")[0].strip()
            elif llm_output.strip().startswith('{') and llm_output.strip().endswith('}'):
                 result_str = llm_output.strip()
            else:
                 raise ValueError("LLMì˜ ì¶œë ¥ì—ì„œ ìœ íš¨í•œ JSON ë§ˆì»¤(```, ''', <>)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return json.loads(result_str)
        except Exception as e:
            print(f"--- íŒŒì‹± ì˜¤ë¥˜ ---")
            print(f"LLM ì›ë³¸ ì¶œë ¥ (íŒŒì‹± ì „): {llm_output}")
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {e}")
            return {"error": "ë¶„ì„ ê²°ê³¼ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

    # LangGraph ë…¸ë“œ ì‹¤í–‰ í•¨ìˆ˜
    def run(self, state: FundAgentState):
        """
        ì´ í•¨ìˆ˜ê°€ LangGraphì— 'ë…¸ë“œ'ë¡œ ë“±ë¡ë  ì‹¤ì œ ì‹¤í–‰ í•¨ìˆ˜ì…ë‹ˆë‹¤.
        """
        print("--- [ë…¸ë“œ ì‹œì‘] 'í€ë“œ ë¶„ì„ ë…¸ë“œ' ì‹¤í–‰ ---")
        
        # Stateì—ì„œ íŒŒì¼ ê²½ë¡œ ì…ë ¥ ë°›ê¸° ì¶”í›„ DBëŒì–´ì˜¤ëŠ” ê±¸ë¡œ ìˆ˜ì •
        file_path = state['fund_data_path']

        # íŒŒì¼ ë¡œë“œ
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                raw_fund_data = json.load(f)
            print(f"--- 9. {file_path} íŒŒì¼ ë¡œë“œ ì„±ê³µ ---")
        except FileNotFoundError:
            print(f"ì˜¤ë¥˜: {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {"fund_analysis_result": {"error": f"File not found: {file_path}"}}
        except json.JSONDecodeError:
            print(f"ì˜¤ë¥˜: {file_path} íŒŒì¼ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return {"fund_analysis_result": {"error": f"JSON decode error in file: {file_path}"}}
        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"fund_analysis_result": {"error": f"File loading error: {e}"}}

        # LLM ì…ë ¥ ë°ì´í„° ê°€ê³µ
        print("--- í€ë“œ ë¶„ì„ ì—ì´ì „íŠ¸ ì‹¤í–‰ (ë¡œì»¬ PCë¡œ ì—°ì‚° ì¤‘...) ---")
        fund_data_str = json.dumps(raw_fund_data, indent=2, ensure_ascii=False)

        # .invoke()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ ì‹¤í–‰ (í´ë˜ìŠ¤ ë‚´ë¶€ ì²´ì¸ í˜¸ì¶œ)
        analysis_result = self.chain.invoke({"input_data": fund_data_str})

        print("--- [ë…¸ë“œ ì¢…ë£Œ] 'í€ë“œ ë¶„ì„ ë…¸ë“œ' ì™„ë£Œ ---")
        
        # State ì—…ë°ì´íŠ¸ (ë°˜í™˜)
        return {"fund_analysis_result": analysis_result}


# 4ë‹¨ê³„: (ì‹¤í–‰) ê·¸ë˜í”„ ì •ì˜ ë° í˜¸ì¶œ (VS Code ë¡œì»¬ ì‹¤í–‰ìš©)

if __name__ == "__main__":
    
    # í´ë˜ìŠ¤ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”
    fund_agent_node = FundAgentNode()

    # ê·¸ë˜í”„ ì •ì˜
    workflow = StateGraph(FundAgentState)

    # ë…¸ë“œ ì¶”ê°€ (í´ë˜ìŠ¤ì˜ run ë©”ì„œë“œë¥¼ ë“±ë¡)
    workflow.add_node("analyze_funds", fund_agent_node.run)

    # ì—£ì§€ ì¶”ê°€
    workflow.set_entry_point("analyze_funds")
    workflow.add_edge("analyze_funds", END)

    # ê·¸ë˜í”„ ì»´íŒŒì¼
    app = workflow.compile()

    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    current_script_path = Path(__file__).resolve()
    project_root = current_script_path.parents[2] 
    file_path_to_run = project_root / 'fund_data.json'

    # ê·¸ë˜í”„ì˜ 'ì´ˆê¸° ìƒíƒœ' ì •ì˜
    initial_state = {
        "fund_data_path": str(file_path_to_run), 
        "fund_analysis_result": {}
    }

    print("\n--- ğŸ (LangGraph) í€ë“œ ë¶„ì„ ê·¸ë˜í”„ ì‹¤í–‰ ì‹œì‘ ğŸ ---")
    
    # 4-8. ê·¸ë˜í”„ ì‹¤í–‰
    final_state = app.invoke(initial_state)

    # 4-9. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n--- ğŸ (LangGraph) ê·¸ë˜í”„ ì‹¤í–‰ ì™„ë£Œ ğŸ ---")
    print("ìµœì¢… ë¶„ì„ ê²°ê³¼ (JSON):")
    print(json.dumps(final_state['fund_analysis_result'], indent=2, ensure_ascii=False))