from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_core.messages import HumanMessage, AIMessage
from contextlib import asynccontextmanager
import asyncio

from agents.registry.agent_registry import AgentRegistry
from core.logging.logger import setup_logger
from graph.builder.graph_builder import GraphBuilder
from graph.schemas.state import LLMStateSchema
from core.mcp.mcp_manager import MCPManager

logger = setup_logger()

# =============================
# Lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
# =============================
graph = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    global graph

    logger.info("ğŸš€ Starting Multi-Agent System...")

    # 1) MCP ë‹¨ì¼ ì„¸ì…˜ ì´ˆê¸°í™”
    mcp = MCPManager()
    mcp.initialize("http://localhost:8888/mcp/")

    for attempt in range(5):
        try:
            await mcp.connect()
            logger.info("ğŸ”— MCP connected!")
            break
        except Exception:
            await asyncio.sleep(2)

    # 2) Agent ìë™ ë“±ë¡
    AgentRegistry.auto_discover("agents.implementations")

    # 3) ê·¸ë˜í”„ ìƒì„±
    builder = GraphBuilder(LLMStateSchema)
    builder.add_agent_node("user_reg", "user_registration")\
        .set_entry_point("user_reg")\
        .set_finish_point("user_reg")
    graph = builder.build()

    yield

    # ì¢…ë£Œ
    await mcp.close()
    logger.info("ğŸ§¹ MCP closed.")


app = FastAPI(title="Multi-Agent Planner", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)


# =============================
# FastAPI ì•± ìƒì„±
# =============================
app = FastAPI(title="Multi-Agent Planner", lifespan=lifespan)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =============================
# API ëª¨ë¸
# =============================
class ChatRequest(BaseModel):
    message: str
    session_id: str = "default-session"


class ChatResponse(BaseModel):
    response: str


# =============================
# API ì—”ë“œí¬ì¸íŠ¸
# =============================
@app.get("/")
async def root():
    """í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "ok",
        "message": "AI Agent API is running ğŸš€",
        "agents": AgentRegistry.list_agents()
    }


@app.get("/health")
async def health_check():
    """MCP ì—°ê²° ìƒíƒœ í™•ì¸"""
    try:
        mcp = MCPManager()
        await mcp.ensure_connected()
        tools = await mcp.list_tools()
        return {
            "status": "healthy",
            "mcp_connected": True,
            "available_tools": len(tools)
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "mcp_connected": False,
            "error": str(e)
        }


@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """
    ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸
    
    Front â†’ Agent Graph â†’ Response
    """
    global graph

    if not graph:
        logger.error("âŒ Agent graph not initialized")
        return ChatResponse(response="âŒ Agent graph is not initialized properly.")

    try:
        logger.info(f"ğŸ“© User message: {request.message}")
        logger.info(f"ğŸ”‘ Session ID: {request.session_id}")

        # ê·¸ë˜í”„ ì„¤ì •
        config = {"configurable": {"thread_id": request.session_id}}

        # ë©”ì‹œì§€ ìƒì„± ë° ê·¸ë˜í”„ ì‹¤í–‰
        messages = [HumanMessage(content=request.message)]
        result = await graph.ainvoke({"messages": messages}, config=config)

        # ì‘ë‹µ ì¶”ì¶œ
        final_response = result.get("messages")

        logger.info(f"ìµœì¢… ì‘ë‹µ ê²°ê³¼ í¬ë§·: {final_response}")
        if not final_response:
            logger.warning("âš ï¸ No response generated")
            return ChatResponse(response="ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        logger.info(f"âœ… Response generated: {final_response[:100] if isinstance(final_response, str) else 'List'}...")
        
        # AI ë©”ì‹œì§€ ì¶”ì¶œ
        ai_messages = [m for m in final_response if isinstance(m, AIMessage)]
        if not ai_messages:
            return ChatResponse(response="AI ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return ChatResponse(response=ai_messages[-1].content)

    except Exception as e:
        logger.error(f"âŒ Chat processing failed: {e}", exc_info=True)
        
        # MCP ì—°ê²° ì˜¤ë¥˜ì¸ ê²½ìš° ëª…í™•í•œ ë©”ì‹œì§€ ë°˜í™˜
        if "mcp" in str(e).lower() or "connection" in str(e).lower():
            return ChatResponse(response="MCP ì„œë²„ì™€ì˜ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        
        return ChatResponse(response=f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


# =============================
# ê°œë°œ ì„œë²„ ì‹¤í–‰
# =============================
if __name__ == "__main__":
    import uvicorn

    logger.info("ğŸš€ Starting API Server on http://localhost:8080")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8080,
        reload=True,
        log_level="info"
    )