from abc import ABC, abstractmethod
import asyncio
import json
import re
from datetime import datetime
from typing import Any, Dict, Optional, List
from enum import Enum

from agent.config.base_config import (
    BaseAgentConfig,
    AgentState,
    StateBuilder,
    StateValidator,
    ExecutionStatus
)

from agent.base.agent_base_prompts import ANALYSIS_PROMPT, DECISION_PROMPT, FINAL_PROMPT

# âœ… LangGraph í˜¸í™˜ì„ ìœ„í•´ LangChain ë©”ì‹œì§€ëŠ” ìœ ì§€
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage

from core.mcp.mcp_manager import MCPManager
from core.logging.logger import setup_logger
from core.llm.llm_manger import LLMHelper

logger = setup_logger()


# =============================
# Agent ê´€ë ¨ í´ë˜ìŠ¤
# =============================

class AgentAction(Enum):
    """Agentê°€ ì·¨í•  ìˆ˜ ìˆëŠ” í–‰ë™ íƒ€ì…"""
    USE_TOOL = "use_tool"
    RESPOND = "respond"
    DELEGATE = "delegate"  # âœ… ìƒˆë¡œ ì¶”ê°€: ë‹¤ë¥¸ Agentë¡œ ìœ„ì„


class AgentDecision:
    """Agentì˜ ì˜ì‚¬ê²°ì • ê²°ê³¼"""
    def __init__(
        self,
        action: AgentAction,
        reasoning: str,
        tool_name: Optional[str] = None,
        tool_arguments: Optional[Dict] = None,
        next_agent: Optional[str] = None  # âœ… ìƒˆë¡œ ì¶”ê°€: ìœ„ì„í•  Agent ì´ë¦„
    ):
        self.action = action
        self.reasoning = reasoning
        self.tool_name = tool_name
        self.tool_arguments = tool_arguments or {}
        self.next_agent = next_agent


class AgentBase(ABC):
    """
    ë©€í‹°í„´ Tool í˜¸ì¶œì„ ì§€ì›í•˜ëŠ” Agent ë² ì´ìŠ¤ í´ë˜ìŠ¤
    
    í•µì‹¬ ì„¤ê³„:
    - LLMHelperë¥¼ í†µí•œ Ollama Chat API ì§ì ‘ í˜¸ì¶œ
    - LangChain ë©”ì‹œì§€ëŠ” LangGraph í˜¸í™˜ì„ ìœ„í•´ ìœ ì§€
    - LLM í˜¸ì¶œ ì‹œì—ë§Œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©
    - Agentë³„ LLM ì„¤ì • ì§€ì›
    - DELEGATE ì•¡ì…˜ìœ¼ë¡œ ë‹¤ë¥¸ Agentì—ê²Œ ì‘ì—… ìœ„ì„ ê°€ëŠ¥
    """

    def __init__(self, config: BaseAgentConfig):
        self.name = config.name
        self.config = config
        self.mcp = MCPManager().get_instance()
        
        # âœ… agents.yaml ì„¤ì • ìš°ì„  ì ìš©
        from agent.config.agent_config_loader import AgentConfigLoader
        
        yaml_config = AgentConfigLoader.get_agent_config(self.name)
        
        if yaml_config:
            # agents.yaml ì„¤ì •ì´ ìˆìœ¼ë©´ ìš°ì„  ì ìš©
            self.max_iterations = yaml_config.max_iterations
            self.config.max_retries = yaml_config.max_retries
            self.config.timeout = yaml_config.timeout
            self.config.tags = yaml_config.tags
            
            # LLM ì„¤ì • ë³‘í•© (agents.yaml > BaseAgentConfig > ì „ì—­ ì„¤ì •)
            if yaml_config.llm_config:
                # agents.yamlì˜ llm_configë¥¼ ìš°ì„  ì ìš©
                merged_llm = {**config.get_llm_config_dict(), **yaml_config.llm_config}
                self.llm_config = merged_llm
            else:
                self.llm_config = config.get_llm_config_dict()
            
            logger.info(f"[{self.name}] âœ… Applied agents.yaml config:")
            logger.info(f"   max_retries: {self.config.max_retries}")
            logger.info(f"   timeout: {self.config.timeout}")
            logger.info(f"   max_iterations: {self.max_iterations}")
            logger.info(f"   tags: {self.config.tags}")
        else:
            # agents.yaml ì„¤ì •ì´ ì—†ìœ¼ë©´ BaseAgentConfig ì‚¬ìš©
            self.max_iterations = config.max_iterations
            self.llm_config = config.get_llm_config_dict()
            logger.warning(f"[{self.name}] âš ï¸  No agents.yaml config found, using BaseAgentConfig defaults")
        
        logger.info(f"[{self.name}] Agent initialized")
        logger.info(f"[{self.name}] LLM config: {self.llm_config if self.llm_config else 'Using global settings'}")
        
        self._validate_config()

    # =============================
    # LLM í˜¸ì¶œ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _langchain_to_dict(self, message) -> Dict[str, str]:
        """LangChain ë©”ì‹œì§€ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        if isinstance(message, HumanMessage):
            return {"role": "user", "content": message.content}
        elif isinstance(message, AIMessage):
            return {"role": "assistant", "content": message.content}
        elif isinstance(message, SystemMessage):
            return {"role": "system", "content": message.content}
        elif isinstance(message, ToolMessage):
            return {"role": "tool", "content": message.content}
        else:
            return {"role": "user", "content": str(message)}    
        
    # =============================
    # Message í¬ë§·íŒ… ë° LLM í˜¸ì¶œ (Debugìš©)
    # =============================
    def _pretty_messages(self, messages: List) -> str:
        """LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ë¬¸ìì—´ë¡œ ì˜ˆì˜ê²Œ ë³€í™˜"""
        converted = []
        for msg in messages:
            converted.append(self._langchain_to_dict(msg))
        return json.dumps(converted, ensure_ascii=False, indent=2)

    def _call_llm(
        self,
        messages: List,
        system_prompt: Optional[str] = None,
        stream: Optional[bool] = None,
        format: Optional[str] = None,
        **kwargs
    ) -> str:
        """
        LLM í˜¸ì¶œ (ë™ê¸° ë°©ì‹)
        
        ìš°ì„ ìˆœìœ„:
        1. ë©”ì„œë“œ í˜¸ì¶œ ì‹œ ì „ë‹¬ëœ kwargs
        2. Agentë³„ llm_config
        3. ì „ì—­ ì„¤ì • (LLMHelper ê¸°ë³¸ê°’)
        """
        # Agent ì„¤ì •ê³¼ kwargs ë³‘í•© (kwargsê°€ ìš°ì„ )
        llm_params = {**self.llm_config, **kwargs}
        
        # stream, format ëª…ì‹œì  ì²˜ë¦¬
        if stream is not None:
            llm_params["stream"] = stream
        if format is not None:
            llm_params["format"] = format
        
        logger.debug(f"[{self.name}] LLM Call Parameters: {llm_params}")
        
        # LangChain ë©”ì‹œì§€ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        formatted_messages = [self._langchain_to_dict(msg) for msg in messages]
        
        # system_promptê°€ ìˆìœ¼ë©´ ë§¨ ì•ì— ì¶”ê°€
        if system_prompt:
            formatted_messages.insert(0, {"role": "system", "content": system_prompt})
        
        # ë§ˆì§€ë§‰ user ë©”ì‹œì§€ë¥¼ promptë¡œ, ë‚˜ë¨¸ì§€ë¥¼ historyë¡œ
        if not formatted_messages:
            return ""
        
        last_msg = formatted_messages[-1]
        history = formatted_messages[:-1] if len(formatted_messages) > 1 else []
        
        if last_msg["role"] == "user":
            return LLMHelper.invoke_with_history(
                prompt=last_msg["content"],
                history=history,
                system_prompt=None,  # ì´ë¯¸ historyì— í¬í•¨ë¨
                **llm_params
            )
        else:
            # ë§ˆì§€ë§‰ì´ userê°€ ì•„ë‹ˆë©´ ì „ì²´ë¥¼ historyë¡œ
            return LLMHelper.invoke_with_history(
                prompt="",
                history=formatted_messages,
                system_prompt=None,
                **llm_params
            )
    
    def _call_llm_with_fixed_params(
        self,
        messages: List,
        system_prompt: Optional[str] = None,
        stream: bool = False,
        format: str = "",
        **fixed_kwargs
    ) -> str:
        """
        LLM í˜¸ì¶œ (ê³ ì • íŒŒë¼ë¯¸í„°)
        
        â­ í•µì‹¬: Agent llm_configë¥¼ ë¬´ì‹œí•˜ê³  ê³ ì •ê°’ë§Œ ì‚¬ìš©
        
        ì´ ë©”ì„œë“œëŠ” ë¶„ì„/ì˜ì‚¬ê²°ì • ê°™ì´ ì •í™•ì„±ì´ ì¤‘ìš”í•œ ì‘ì—…ì— ì‚¬ìš©
        Agentë³„ ì„¤ì •ì„ ë¬´ì‹œí•˜ê³  ê¸°ë³¸ê°’ë§Œ ë”°ë¦„
        
        ìš°ì„ ìˆœìœ„:
        1. ì´ ë©”ì„œë“œì˜ íŒŒë¼ë¯¸í„° (stream, format ê³ ì •)
        2. fixed_kwargs (ê¸°ë³¸ê°’)
        3. ì „ì—­ ì„¤ì • (LLMHelper ê¸°ë³¸ê°’)
        
        Args:
            messages: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            stream: ìŠ¤íŠ¸ë¦¬ë° (ê¸°ë³¸: False=ì „ì²´ ì‘ë‹µ)
            format: í¬ë§· (ê¸°ë³¸: ""=í…ìŠ¤íŠ¸, "json"=JSON ê°•ì œ)
            **fixed_kwargs: ê³ ì • íŒŒë¼ë¯¸í„° (temperature ë“±)
        """
        # â­ Agent llm_configë¥¼ ë¬´ì‹œí•˜ê³  fixed_kwargsë§Œ ì‚¬ìš©
        llm_params = {**fixed_kwargs}  # Agent ì„¤ì • ë¬´ì‹œ!
        
        # stream, formatì€ ì´ ë©”ì„œë“œì˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        llm_params["stream"] = stream
        llm_params["format"] = format
        
        logger.debug(f"[{self.name}] LLM Call (FIXED PARAMS): {llm_params}")
        logger.info(f"[{self.name}] Using fixed parameters (ignoring Agent config)")
        
        # LangChain ë©”ì‹œì§€ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        formatted_messages = [self._langchain_to_dict(msg) for msg in messages]
        
        if system_prompt:
            formatted_messages.insert(0, {"role": "system", "content": system_prompt})
        
        if not formatted_messages:
            return ""
        
        last_msg = formatted_messages[-1]
        history = formatted_messages[:-1] if len(formatted_messages) > 1 else []
        
        if last_msg["role"] == "user":
            return LLMHelper.invoke_with_history(
                prompt=last_msg["content"],
                history=history,
                system_prompt=None,
                **llm_params
            )
        else:
            return LLMHelper.invoke_with_history(
                prompt="",
                history=formatted_messages,
                system_prompt=None,
                **llm_params
            )

    # =============================
    # ë©€í‹°í„´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
    # =============================
    
    async def run(self, state: AgentState) -> AgentState:
        """Agent ì‹¤í–‰ ë©”ì¸ í”Œë¡œìš°"""
        self._log_start(state)

        if not self.validate_input(state):
            error = ValueError(f"Invalid input for {self.name}")
            state = StateBuilder.add_error(state, error, self.name)
            state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
            return state
        
        # âœ… Agent ì§„ì… ì‹œ iteration ì´ˆê¸°í™”
        state["iteration"] = 0
        logger.info(f"[{self.name}] Iteration reset to 0 for this agent")

        state = self.pre_execute(state)

        for attempt in range(1, self.config.max_retries + 1):
            try:
                async with asyncio.timeout(self.config.timeout):
                    result = await self.execute_multi_turn(state)
                break
                
            except asyncio.TimeoutError:
                error_msg = f"Timeout after {self.config.timeout} seconds"
                logger.warning(f"[{self.name}] attempt {attempt} failed: {error_msg}")
                
                if attempt == self.config.max_retries:
                    error = TimeoutError(f"{self.name} execution timed out")
                    state = StateBuilder.add_error(state, error, self.name)
                    state = StateBuilder.finalize_state(state, ExecutionStatus.TIMEOUT)
                    return state
                
                await asyncio.sleep(1.5 * attempt)
                
            except Exception as e:
                logger.warning(f"[{self.name}] attempt {attempt} failed: {e}")
                
                if attempt == self.config.max_retries:
                    state = StateBuilder.add_error(state, e, self.name)
                    state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
                    return state
                
                await asyncio.sleep(1.5 * attempt)

        self._log_end(result)
        return result

    # =============================
    # ë©€í‹°í„´ ì‹¤í–‰ ë¡œì§ (ReAct Loop)
    # =============================
    
    async def execute_multi_turn(self, state: AgentState) -> AgentState:
        """ë©€í‹°í„´ ì‹¤í–‰ í”Œë¡œìš°"""
        messages = state.get("messages", [])
        
        logger.info(f"[{self.name}] Messages count: {len(messages)}")
        
        # âœ… ë§¤ë²ˆ Agent ì§„ì… ì‹œ ì—­í•  ì •ì˜ ì¶”ê°€ (ì „ì²´ íˆìŠ¤í† ë¦¬ ìœ ì§€)
        agent_role = self.get_agent_role_prompt()
        system_msg = SystemMessage(content=agent_role)
        
        # ë§¨ ì•ì— ì¶”ê°€
        state["messages"] = [system_msg] + messages
        messages = state["messages"]
        
        logger.info(f"[{self.name}] âœ… Added agent role as system message")
        
        # MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ
        available_tools = await self._list_mcp_tools()
        logger.info(f"[{self.name}] MCP tools available: {len(available_tools)}")

        if not available_tools:
            error_msg = "No MCP tools available"
            logger.error(f"[{self.name}] {error_msg}")
            state = StateBuilder.add_warning(state, error_msg)
            state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
            return state
        
        logger.info(f"[{self.name}] Available tools: {available_tools}")
        
        # ReAct Loop
        while not StateBuilder.is_max_iterations_reached(state):
            state = StateBuilder.increment_iteration(state)
            current_iteration = state.get("iteration", 0)
            
            logger.info(f"\n{'='*60}")
            logger.info(f"[{self.name}] Iteration {current_iteration}/{self.max_iterations}")
            logger.info(f"{'='*60}")
            # Step 1: ìš”êµ¬ì‚¬í•­ ë¶„ì„
            try:
                logger.info("ğŸ“‹ Analyzing Input Message\n" + self._pretty_messages(messages))
                analyzed_request = await self._analyze_request(messages, available_tools)
                analyzed_request = self._remove_think_tag(analyzed_request)
                
                logger.info(f"ğŸ“‹ Analyzed Request: {analyzed_request}")
            except Exception as e:
                logger.error(f"[{self.name}] Request analysis failed: {e}")
                state = StateBuilder.add_error(state, e, self.name)
                break
            
            # Step 2: Agent ì˜ì‚¬ê²°ì •
            try:
                logger.info("ğŸ“‹ MakeDecision Input Message\n" + self._pretty_messages(messages))
                decision = await self._make_decision(messages, available_tools)
                
                logger.info(f"ğŸ¤” Decision: {decision.action.value}")
                logger.info(f"   Reasoning: {decision.reasoning}")
            except Exception as e:
                logger.error(f"[{self.name}] Decision making failed: {e}")
                state = StateBuilder.add_error(state, e, self.name)
                break
            
            # Step 2: ì•¡ì…˜ ì‹¤í–‰
            if decision.action == AgentAction.USE_TOOL:
                logger.info(f"ğŸ”§ Executing tool: {decision.tool_name}")
                logger.info(f"   Arguments: {decision.tool_arguments}")
                
                try:
                    tool_result = await self._execute_mcp_tool(
                        decision.tool_name,
                        decision.tool_arguments
                    )
                    
                    state = StateBuilder.add_tool_call(
                        state,
                        tool_name=decision.tool_name,
                        arguments=decision.tool_arguments,
                        result=tool_result
                    )
                    
                    tool_message = ToolMessage(
                        content=f"Tool: {decision.tool_name}\nResult: {tool_result}",
                        tool_call_id=decision.tool_name
                    )
                    messages.append(tool_message)
                    state["messages"] = messages
                    
                    logger.info(f"âœ… Tool executed successfully")
                    
                except Exception as e:
                    logger.error(f"[{self.name}] Tool execution failed: {e}")
                    state = StateBuilder.add_error(state, e, self.name)
                    
                    error_message = ToolMessage(
                        content=f"Tool: {decision.tool_name}\nError: {str(e)}",
                        tool_call_id=decision.tool_name
                    )
                    messages.append(error_message)
                    state["messages"] = messages
                
                continue
            
            elif decision.action == AgentAction.DELEGATE:
                logger.info(f"ğŸ”€ Delegating to agent: {decision.next_agent}")
                logger.info(f"   Reason: {decision.reasoning}")
                
                # âœ… ë©”ì‹œì§€ ì´ˆê¸°í™”í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€!
                delegation_msg = AIMessage(
                    content=f"[ë‚´ë¶€ ìœ„ì„] {decision.next_agent}ì—ê²Œ ì‘ì—…ì„ ìœ„ì„í•©ë‹ˆë‹¤.\nì´ìœ : {decision.reasoning}"
                )
                messages.append(delegation_msg)
                state["messages"] = messages
                
                # âœ… delegation ë©”íƒ€ë°ì´í„° ì„¤ì •
                state["previous_agent"] = self.name
                state["next_agent"] = decision.next_agent
                state["delegation_reason"] = decision.reasoning
                state["status"] = ExecutionStatus.RUNNING
                state["timestamp"] = datetime.now()
                
                logger.info(f"[{self.name}] Delegation: next_agent={state.get('next_agent')}, status={state.get('status')}")
                logger.info(f"[{self.name}] âœ… Full conversation history preserved ({len(messages)} messages)")
                return state
                
            elif decision.action == AgentAction.RESPOND:
                logger.info("âœ… Generating final response")
                
                try:
                    final_response = await self._generate_final_response(messages, available_tools)
                    
                    messages.append(AIMessage(content=final_response))
                    state["messages"] = messages
                    state["last_result"] = final_response
                    
                    state = StateBuilder.finalize_state(state, ExecutionStatus.SUCCESS)
                    logger.info(f"[{self.name}] Total messages: {len(state['messages'])}")
                    logger.info(f"ğŸ’¬ Final response generated ({len(final_response)} chars)")
                    return state
                    
                except Exception as e:
                    logger.error(f"[{self.name}] Final response generation failed: {e}")
                    state = StateBuilder.add_error(state, e, self.name)
                    state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
                    return state
        
        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬
        logger.warning(f"âš ï¸ Max iterations ({self.max_iterations}) reached")
        
        try:
            fallback_response = await self._generate_fallback_response(messages)
            messages.append(AIMessage(content=fallback_response))
            state["messages"] = messages
            state["last_result"] = fallback_response
        except Exception as e:
            logger.error(f"[{self.name}] Fallback response generation failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
        
        state = StateBuilder.finalize_state(state, ExecutionStatus.MAX_ITERATIONS)
        return state

    # =============================
    # Agent React Function ë‹¨ê³„ë³„ ë©”ì„œë“œ
    # =============================
    
    async def _analyze_request(
        self,
        messages: List,
        available_tools: List[str]
    ) -> str:
        """
        ìš”êµ¬ì‚¬í•­ ë¶„ì„ (ê¸°ë³¸ê°’ ê³ ì •)
        
        â­ Agent ì„¤ì • ë¬´ì‹œ, í•­ìƒ ê¸°ë³¸ê°’ ì‚¬ìš©
        - temperature: 0.1 (ë§¤ìš° ì¼ê´€ì )
        - format: "" (í…ìŠ¤íŠ¸)
        - stream: False (ì „ì²´ ì‘ë‹µ)
        """
        agent_role = self.get_agent_role_prompt()
        
        system_prompt = f"""{agent_role}

---
[í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì—ì´ì „íŠ¸ ID]
**{self.name}** (ë‹¹ì‹ ì…ë‹ˆë‹¤)

[í˜„ì¬ ë‹¨ê³„: ìš”êµ¬ì‚¬í•­ ë¶„ì„]

ë‹¹ì‹ ì˜ í˜„ì¬ ì—ì´ì „íŠ¸ì˜ ì—­í• ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ íŒŒì•…í•˜ì„¸ìš”:

1. ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê²ƒì´ ë¬´ì—‡ì¸ê°€?
2. ì´ì „ ëŒ€í™” ë§¥ë½ì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€?
3. í˜„ì¬ í•´ê²°í•´ì•¼ í•  êµ¬ì²´ì ì¸ ì‘ì—…ì€ ë¬´ì—‡ì¸ê°€?
                                      
ì¶œë ¥ í˜•ì‹ (JSON):
{{
  "user_intent": "ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê²ƒì— ëŒ€í•œ ëª…í™•í•œ ì„¤ëª…",
  "context_summary": "ì´ì „ ëŒ€í™”ì—ì„œ ì´ë¯¸ ìˆ˜í–‰ëœ ì‘ì—… ìš”ì•½",
  "next_task": "ì§€ê¸ˆ ìˆ˜í–‰í•´ì•¼ í•  êµ¬ì²´ì ì¸ ì‘ì—…"
}}

**ì¤‘ìš”:** 
- ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. Markdown ë°±í‹±(```)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. 
- ì ˆëŒ€ JSON ì´ì™¸ì— ì–´ë– í•œ ì •ë³´, í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- JSON ì¶œë ¥ì€ 1ê°œì˜ ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.
"""
        
        try:
            logger.info(f"[{self.name}] ğŸ“‹ Analyzing request with FIXED parameters")
            
            # âœ… ê³ ì •ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©
            response = await asyncio.to_thread(
                self._call_llm_with_fixed_params,
                messages,
                system_prompt,
                False,      # stream=False (ì „ì²´ ì‘ë‹µ)
                "json",         # format="" (í…ìŠ¤íŠ¸, JSON ì•„ë‹˜!)
                temperature=0.1  # ê¸°ë³¸ê°’ ê³ ì •
            )
            
            content = self._remove_think_tag(response)
            logger.info(f"[{self.name}] âœ… Request analysis completed")
            
            parsed = json.loads(content)
            return json.dumps(parsed, ensure_ascii=False)
        except Exception as e:
            logger.error(f"[{self.name}] Request analysis failed: {e}")
            raise
    
    async def _make_decision(
        self,
        messages: List,
        available_tools: List[str],
        analyzed_request: str = ""
    ) -> "AgentDecision":
        """
        Agent ì˜ì‚¬ê²°ì • (ê¸°ë³¸ê°’ ê³ ì •)
        
        â­ Agent ì„¤ì • ë¬´ì‹œ, í•­ìƒ ê¸°ë³¸ê°’ ì‚¬ìš©
        - temperature: 0.1 (ë§¤ìš° ì¼ê´€ì )
        - format: "json" (JSON ê°•ì œ)
        - stream: False (ì „ì²´ ì‘ë‹µ)
        """
        available_agents = self._get_available_agents()
        
        system_prompt = DECISION_PROMPT.format(
            name=self.name,
            available_agents=available_agents,
            available_tools=available_tools
        )
        
        try:
            logger.info(f"[{self.name}] ğŸ¤” Making decision with FIXED parameters")
            
            # âœ… ê³ ì •ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©
            response = await asyncio.to_thread(
                self._call_llm_with_fixed_params,
                messages,
                system_prompt,
                False,       # stream=False (ì „ì²´ ì‘ë‹µ)
                "json",      # format="json" (JSON ê°•ì œ)
                temperature=0.1  # ê¸°ë³¸ê°’ ê³ ì •
            )
            
            content = self._remove_think_tag(response)
            logger.info(f"[{self.name}] âœ… Decision made successfully")
            logger.info(f"ğŸ“‹ Decision Request: {content}")
            
            decision_json = json.loads(content)
            
            action_str = decision_json.get("action")
            reasoning = decision_json.get("reasoning", "")
            
            if action_str == "use_tool":
                return AgentDecision(
                    action=AgentAction.USE_TOOL,
                    reasoning=reasoning,
                    tool_name=decision_json.get("tool_name"),
                    tool_arguments=decision_json.get("tool_arguments", {})
                )
            elif action_str == "delegate":
                return AgentDecision(
                    action=AgentAction.DELEGATE,
                    reasoning=reasoning,
                    next_agent=decision_json.get("next_agent")
                )
            else:
                return AgentDecision(
                    action=AgentAction.RESPOND,
                    reasoning=reasoning
                )
                
        except Exception as e:
            logger.error(f"[{self.name}] Decision making failed: {e}")
            raise
    
    async def _generate_final_response(
        self,
        messages: List,
        tool_names: List[str]
    ) -> str:
        """
        ìµœì¢… ë‹µë³€ ìƒì„± (Agent ì„¤ì • ë”°ë¦„)
        
        â­ Agentì˜ llm_config ì‚¬ìš©
        - ì°½ì˜ì„± ì¡°ì • ê°€ëŠ¥
        - í¬ë§· ì„¤ì • ê°€ëŠ¥
        - Agentë³„ë¡œ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ê°€ëŠ¥
        
        ê° Agentì—ì„œ llm_configë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì •í•˜ë©´
        ì´ ë©”ì„œë“œê°€ ê·¸ì— ë”°ë¼ ë‹µë³€ì„ ìƒì„±í•¨
        """
        agent_role = self.get_agent_role_prompt()
        
        system_prompt = f"""{agent_role}

---

**[í˜„ì¬ ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìƒì„±]**

ë‹¹ì‹ ì˜ ì—­í• ì„ ë°”íƒ•ìœ¼ë¡œ, ì§€ê¸ˆê¹Œì§€ ìˆ˜í–‰í•œ ì‘ì—…ì˜ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”.

**ì¶œë ¥:** ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì‘ë‹µ
"""
        
        try:
            logger.info(f"[{self.name}] ğŸ’¬ Generating final response with Agent config")
            logger.info(f"[{self.name}] Using Agent's LLM settings: {self.llm_config}")
            
            # âœ… Agent ì„¤ì •ì„ ë”°ë¦„ (_call_llm ì‚¬ìš©)
            response = await asyncio.to_thread(
                self._call_llm,
                messages,
                system_prompt,
                None,   # stream: Agent ì„¤ì • ë”°ë¦„
                ""      # format: í…ìŠ¤íŠ¸ ì‘ë‹µ
            )
            
            logger.info(f"[{self.name}] âœ… Final response generated")
            return self._remove_think_tag(response)
        except Exception as e:
            logger.error(f"[{self.name}] Final response generation failed: {e}")
            raise
    
    async def _generate_fallback_response(self, messages: List) -> str:
        """ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ í´ë°± ì‘ë‹µ"""
        return f"""ì²˜ë¦¬ ê³¼ì •ì´ ì˜ˆìƒë³´ë‹¤ ë³µì¡í•˜ì—¬ {self.max_iterations}íšŒ ë°˜ë³µ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.
ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."""

    # =============================
    # êµ¬ì²´ì ì¸ Agentê°€ êµ¬í˜„í•´ì•¼ í•  ë©”ì„œë“œ
    # =============================
    
    @abstractmethod
    def get_agent_role_prompt(self) -> str:
        """Agent ì—­í•  ì •ì˜ Prompt"""
        pass

    # =============================
    # ê³µí†µ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _get_available_agents(self) -> str:
        """
        í˜„ì¬ Agentì—ì„œ ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡
        """
        if hasattr(self, "allowed_agents"):
            # allowed_agentsê°€ ìˆì–´ë„ ìê¸° ìì‹ ì€ ë¬´ì¡°ê±´ ì œì™¸í•´ì•¼ í•¨
            agents = [name for name in self.allowed_agents if name != self.name]
        else:
            # ê¸°ë³¸: ëª¨ë“  ë“±ë¡ëœ Agent (ìì‹  ì œì™¸)
            from agent.registry.agent_registry import AgentRegistry
            all_agents = AgentRegistry.list_agents()
            agents = [name for name in all_agents if name != self.name]
            
        logger.info(f"{agents} available for delegation from {self.name}")
        
        if not agents:
            return "ì—†ìŒ (ì´ ì—ì´ì „íŠ¸ê°€ ëª¨ë“  ì‘ì—…ì„ ì§ì ‘ ì²˜ë¦¬í•´ì•¼ í•¨)"
        
        # í¬ë§·íŒ…
        agent_list = "\n".join([f"- {agent}" for agent in agents])
        
        return f"""
[ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡]
{agent_list}

**ì£¼ì˜:** ìœ„ ëª©ë¡ì— ì—†ëŠ” Agent(íŠ¹íˆ ìê¸° ìì‹ )ì—ê²ŒëŠ” ì ˆëŒ€ ìœ„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
"""
    
    async def _list_mcp_tools(self) -> List[Dict[str, Any]]:
        """MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ"""
        try:
            tools = await self.mcp.list_tools()
            tools_spec = []
            
            if hasattr(self, "allowed_tools"):
                if self.allowed_tools == 'ALL':
                    pass  # ì „ì²´ íˆ´ í—ˆìš©
                elif len(self.allowed_tools) == 0:
                    tools = []  # íˆ´ ì—†ìŒ
                else:
                    tools = [t for t in tools if t.name in self.allowed_tools]

            for tool in tools:
                schema = tool.inputSchema or {}
                props = schema.get("properties", {})
                if not props:
                    continue
                tools_spec.append({
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "parameters": {
                            "type": schema.get("type", "object"),
                            "properties": {
                                k: {
                                    "type": p.get("type", "string"),
                                    "description": p.get("description", "")
                                } for k, p in props.items()
                            },
                            "required": schema.get("required", [])
                        },
                    },
                })
            logger.debug(f"[{self.name}] Retrieved {len(tools_spec)} tools")
            return tools_spec
        except Exception as e:
            logger.error(f"[{self.name}] Failed to list MCP tools: {e}")
            return []

    async def _execute_mcp_tool(
        self,
        tool_name: str,
        tool_args: Dict[str, Any]
    ) -> Any:
        """MCP ë„êµ¬ ì‹¤í–‰"""
        try:
            result = await self.mcp.call_tool(tool_name, tool_args)
            logger.info(f"[{self.name}] Tool '{tool_name}' executed successfully")
            return result
        except Exception as e:
            logger.error(f"[{self.name}] Tool '{tool_name}' execution failed: {e}")
            raise
    
    def _remove_think_tag(self, text: str) -> str:
        """
        </think> ì¢…ë£Œ íƒœê·¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê·¸ ë’¤ì˜ í…ìŠ¤íŠ¸(ì§„ì§œ ê²°ê³¼)ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        ê·¸ í›„ JSON í˜•ì‹('{ ... }')ë§Œ ì •í™•íˆ ë°œë¼ëƒ…ë‹ˆë‹¤.
        """
        # 1. </think>ê°€ ìˆë‹¤ë©´, ê·¸ ë’¤ì˜ ë‚´ìš©ë§Œ ì·¨í•©ë‹ˆë‹¤.
        #    (ì•ì— ìˆëŠ” <think> ë¸”ë¡ì´ë‚˜ ì¤‘ë³µëœ JSONì€ ëª¨ë‘ ë¬´ì‹œë¨)
        if "</think>" in text:
            text = text.rsplit("</think>", 1)[-1]
        
        # 2. í˜¹ì‹œë¼ë„ <think>ë§Œ ìˆê³  ë‹«ëŠ” íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì•ˆì „ì¥ì¹˜ë¡œ ì‹œì‘ íƒœê·¸ ì²˜ë¦¬
        elif "<think>" in text:
            text = text.rsplit("<think>", 1)[-1]

        # 3. ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        # 4. ìˆœìˆ˜í•œ JSON ê°ì²´ë§Œ ì¶”ì¶œ (ì²« '{' ë¶€í„° ë§ˆì§€ë§‰ '}' ê¹Œì§€)
        #    ì´ë ‡ê²Œ í•˜ë©´ "Here is the JSON:" ê°™ì€ êµ°ë”ë”ê¸° í…ìŠ¤íŠ¸ê°€ ë¶™ì–´ë„ ì œê±°ë©ë‹ˆë‹¤.
        start_idx = text.find("{")
        end_idx = text.rfind("}")
        
        if start_idx != -1 and end_idx != -1:
            text = text[start_idx : end_idx + 1]
        
        return text


    # =============================
    # ê¸°íƒ€ ê³µí†µ ë©”ì„œë“œ
    # =============================
    
    def validate_input(self, state: AgentState) -> bool:
        """ì…ë ¥ ìƒíƒœ ê²€ì¦"""
        if "messages" not in state or not isinstance(state["messages"], list):
            logger.error(f"[{self.name}] Invalid messages field")
            return False
        
        is_valid, error_msg = StateValidator.validate_execution_state(state)
        if not is_valid:
            logger.error(f"[{self.name}] Invalid execution state: {error_msg}")
            return False
        
        return True

    def pre_execute(self, state: AgentState) -> AgentState:
        """ì‹¤í–‰ ì „ ì „ì²˜ë¦¬"""
        return state

    def _validate_config(self):
        """ì„¤ì • ê²€ì¦"""
        if not self.config.name:
            raise ValueError("Agent name is required")

    def _log_start(self, state: AgentState):
        """ì‹¤í–‰ ì‹œì‘ ë¡œê¹…"""
        logger.info(f"[{self.name}] Starting execution")
        logger.info(f"   Session ID: {state.get('session_id', 'unknown')}")
        logger.info(f"   Messages: {len(state.get('messages', []))}")

    def _log_end(self, state: AgentState):
        """ì‹¤í–‰ ì™„ë£Œ ë¡œê¹…"""
        logger.info(f"[{self.name}] Execution completed")
        logger.info(f"   Final Status: {state.get('status', 'unknown')}")
        logger.info(f"   Iterations: {state.get('iteration', 0)}")
        logger.info(f"   Tool Calls: {len(state.get('tool_calls', []))}")