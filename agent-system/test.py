"""
LLM Workflow Example
Ollamaë¥¼ ì‚¬ìš©í•œ ì™„ì „í•œ ì›Œí¬í”Œë¡œìš°
"""
import asyncio
from typing import TypedDict, Optional
from graph.builder.graph_builder import GraphBuilder
from agents.registry.agent_registry import AgentRegistry
from core.logging.logger import setup_logger
from core.llm.llm_manger import LLMManager
from langchain_core.messages import HumanMessage
import logging


class LLMStateSchema(TypedDict, total=False):
    """LLM ì›Œí¬í”Œë¡œìš°ìš© ìƒíƒœ ìŠ¤í‚¤ë§ˆ"""
    query: str
    research_result: Optional[str]
    analysis_result: Optional[str]
    final_report: Optional[str]


async def test_ollama_connection():
    """Ollama ì—°ê²° í…ŒìŠ¤íŠ¸"""
    logger = logging.getLogger(__name__)
    
    logger.info("=" * 60)
    logger.info("ğŸ”Œ Testing Ollama Connection...")
    logger.info("=" * 60)
    
    try:
        # LLM ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” (providerë¥¼ ollamaë¡œ ëª…ì‹œ)
        LLMManager.reset()  # ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        llm = LLMManager.get_llm(provider="ollama", model="qwen3:8b")
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        response = await llm.ainvoke([HumanMessage(content="Hello")])
        
        logger.info(f"âœ… Ollama is ready! Response: {response.content[:50]}...")
        return True
            
    except Exception as e:
        logger.error(f"âŒ Connection test error: {e}")
        logger.info("""
ğŸ’¡ Troubleshooting:
1. Install Ollama: https://ollama.ai
2. Start Ollama: ollama serve
3. Pull a model: ollama pull llama3.2
4. Check if running: curl http://localhost:11434
""")
        return False


async def run_llm_workflow():
    """LLM ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    logger = logging.getLogger(__name__)
    
    logger.info("=" * 60)
    logger.info("ğŸš€ LLM Research Workflow Starting...")
    logger.info("=" * 60)
    
    # Agent ìë™ ë°œê²¬
    AgentRegistry.auto_discover("agents.implementations")
    
    registered_agents = AgentRegistry.list_agents()
    logger.info(f"âœ… Registered agents: {registered_agents}")
    
    # í•„ìˆ˜ Agent í™•ì¸
    required_agents = ["intent_classifier"]
    missing = [a for a in required_agents if a not in registered_agents]
    
    if missing:
        logger.warning(f"âš ï¸ Missing required agents: {missing}")
        logger.info("ğŸ’¡ Using available agents only. Some agents may not be available.")
        logger.info("ğŸ’¡ To create missing agents, implement them in agents/implementations/")
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ Agentë¡œ ê·¸ë˜í”„ ë¹Œë“œ
    builder = GraphBuilder(LLMStateSchema)
    
    # LLM Agentìš© ì„¤ì • (íƒ€ì„ì•„ì›ƒì„ 120ì´ˆë¡œ ëŠ˜ë¦¼)
    llm_agent_config = {
        "timeout": 120,  # LLM í˜¸ì¶œì€ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ íƒ€ì„ì•„ì›ƒì„ ëŠ˜ë¦¼
        "max_retries": 2  # ì¬ì‹œë„ íšŸìˆ˜ëŠ” ì¤„ì„
    }
    
    # intent_classifier ìˆìœ¼ë©´ ì¶”ê°€
    entry_point = None
    finish_point = None
    
    if "intent_classifier" in registered_agents:
        builder.add_agent_node("intent", "intent_classifier", config=llm_agent_config)
        entry_point = "intent"
        finish_point = "intent"
    else:
        logger.error("âŒ intent_classifier agent not found!")
        return None
    
    # ê·¸ë˜í”„ ì„¤ì •
    if entry_point and finish_point:
        builder.set_entry_point(entry_point)
        builder.set_finish_point(finish_point)
    else:
        logger.error("âŒ Cannot build graph: entry_point or finish_point is not set")
        return None
    
    # ê·¸ë˜í”„ ì»´íŒŒì¼
    graph = builder.build()
    
    logger.info("=" * 60)
    logger.info("ğŸ“Š Graph Structure:")
    logger.info(f"   Entry: {entry_point}")
    logger.info(f"   Finish: {finish_point}")
    logger.info("=" * 60)
    
    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state = {
        "query": "ê³„íšì„ ìˆ˜ì •í•˜ê³  ì‹¶ì–´"
    }
    
    logger.info(f"ğŸ” Starting workflow with query: '{initial_state['query']}'")
    logger.info("=" * 60)
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    try:
        result = await graph.ainvoke(initial_state)
        
        logger.info("=" * 60)
        logger.info("âœ… Workflow completed successfully!")
        logger.info("=" * 60)
        logger.info("ğŸ“ Results:")
        
        if "intent_result" in result:
            logger.info(f"   intent: {result['intent_result'][:100]}...")

        logger.info("=" * 60)
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ Workflow execution failed: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë¡œê¹… ì„¤ì •
    logger = setup_logger()
    
    logger.info("=" * 60)
    logger.info("ğŸš€ LLM Workflow Main")
    logger.info("=" * 60)
    
    # Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
    connection_ok = await test_ollama_connection()
    
    if not connection_ok:
        logger.error("âŒ Cannot proceed without Ollama connection")
        logger.info("ğŸ’¡ Please start Ollama and try again")
        return
    
    logger.info("")
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = await run_llm_workflow()
    
    if result:
        logger.info("âœ… All done!")
    else:
        logger.error("âŒ Workflow failed")


if __name__ == "__main__":
    asyncio.run(main())