from abc import ABC, abstractmethod
import asyncio
import json
import re
from datetime import datetime
from typing import Any, Dict, Optional, List
from enum import Enum

from agents.config.base_config import (
    BaseAgentConfig,
    AgentState,
    StateBuilder,
    StateValidator,
    ExecutionStatus
)

from agents.base.agent_base_prompts import DECISION_PROMPT
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage

from core.mcp.mcp_manager import MCPManager
from core.logging.logger import setup_logger
from core.llm.llm_manger import LLMHelper

logger = setup_logger()


# =============================
# Agent ê´€ë ¨ í´ë˜ìŠ¤
# =============================

class AgentAction(Enum):
    """Agentê°€ ì·¨í•  ìˆ˜ ìˆëŠ” í–‰ë™ íƒ€ì…"""
    USE_TOOL = "use_tool"
    RESPOND = "respond"
    DELEGATE = "delegate"  # âœ… ìƒˆë¡œ ì¶”ê°€: ë‹¤ë¥¸ Agentë¡œ ìœ„ì„


class AgentDecision:
    """Agentì˜ ì˜ì‚¬ê²°ì • ê²°ê³¼"""
    def __init__(
        self,
        action: AgentAction,
        reasoning: str,
        tool_name: Optional[str] = None,
        tool_arguments: Optional[Dict] = None,
        tool_use_id: Optional[str] = None,
        tool_calls: Optional[List[Dict]] = None,  # âœ… ì¶”ê°€
        next_agent: Optional[str] = None,
        response_text: Optional[str] = None,
        requires_post_processing: bool = False
    ):
        self.action = action
        self.reasoning = reasoning
        self.tool_name = tool_name
        self.tool_arguments = tool_arguments or {}
        self.tool_use_id = tool_use_id
        self.tool_calls = tool_calls or []  # âœ… ì¶”ê°€
        self.next_agent = next_agent
        self.response_text = response_text
        self.requires_post_processing = requires_post_processing


class AgentBase(ABC):
    """
    ë©€í‹°í„´ Tool í˜¸ì¶œì„ ì§€ì›í•˜ëŠ” Agent ë² ì´ìŠ¤ í´ë˜ìŠ¤
    
    í•µì‹¬ ì„¤ê³„:
    - LLMHelperë¥¼ í†µí•œ Ollama Chat API ì§ì ‘ í˜¸ì¶œ
    - LangChain ë©”ì‹œì§€ëŠ” LangGraph í˜¸í™˜ì„ ìœ„í•´ ìœ ì§€
    - LLM í˜¸ì¶œ ì‹œì—ë§Œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©
    - Agentë³„ LLM ì„¤ì • ì§€ì›
    - DELEGATE ì•¡ì…˜ìœ¼ë¡œ ë‹¤ë¥¸ Agentì—ê²Œ ì‘ì—… ìœ„ì„ ê°€ëŠ¥
    """

    def __init__(self, config: BaseAgentConfig):
        self.name = config.name
        self.config = config
        self.mcp = MCPManager().get_instance()
        
        # âœ… agents.yaml ì„¤ì • ìš°ì„  ì ìš©
        from agents.config.agent_config_loader import AgentConfigLoader
        
        yaml_config = AgentConfigLoader.get_agent_config_from_current(self.name)
        
        if yaml_config:
            # agents.yaml ì„¤ì •ì´ ìˆìœ¼ë©´ ìš°ì„  ì ìš©
            self.max_iterations = yaml_config.max_iterations
            self.config.max_retries = yaml_config.max_retries
            self.config.timeout = yaml_config.timeout
            self.config.tags = yaml_config.tags
            
            # LLM ì„¤ì • ë³‘í•© (agents.yaml > BaseAgentConfig > ì „ì—­ ì„¤ì •)
            if yaml_config.llm_config:
                # agents.yamlì˜ llm_configë¥¼ ìš°ì„  ì ìš©
                merged_llm = {**config.get_llm_config_dict(), **yaml_config.llm_config}
                self.llm_config = merged_llm
            else:
                self.llm_config = config.get_llm_config_dict()
            
            logger.info(f"[{self.name}] âœ… Applied agents.yaml config:")
            logger.info(f"   max_retries: {self.config.max_retries}")
            logger.info(f"   timeout: {self.config.timeout}")
            logger.info(f"   max_iterations: {self.max_iterations}")
            logger.info(f"   tags: {self.config.tags}")
        else:
            # agents.yaml ì„¤ì •ì´ ì—†ìœ¼ë©´ BaseAgentConfig ì‚¬ìš©
            self.max_iterations = config.max_iterations
            self.llm_config = config.get_llm_config_dict()
            logger.info(f"[{self.name}] Using BaseAgentConfig defaults")
        
        logger.info(f"[{self.name}] Agent initialized")
        logger.info(f"[{self.name}] LLM config: {self.llm_config if self.llm_config else 'Using global settings'}")
        
        self._validate_config()

    # =============================
    # LLM í˜¸ì¶œ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _langchain_to_dict(self, message) -> Dict[str, Any]:
        """LangChain ë©”ì‹œì§€ë¥¼ Bedrock ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        if isinstance(message, HumanMessage):
            # contentê°€ ë¦¬ìŠ¤íŠ¸ë©´ ê·¸ëŒ€ë¡œ, ë¬¸ìì—´ì´ë©´ text ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ê¸°
            if isinstance(message.content, list):
                return {"role": "user", "content": message.content}
            else:
                return {"role": "user", "content": [{"text": message.content}]}
        
        elif isinstance(message, AIMessage):
            # âœ… AIMessageì˜ contentì—ì„œ ì œì–´ í† í° ì œê±° (ë°©ì–´ì  ì¡°ì¹˜)
            # LLM Managerì—ì„œ ì´ë¯¸ ì œê±°í•˜ì§€ë§Œ, ì´ì¤‘ ë°©ì–´
            from core.llm.llm_manger import _sanitize_extended_thinking_tokens
            
            # contentê°€ ë¦¬ìŠ¤íŠ¸ë©´ ê° í…ìŠ¤íŠ¸ ë¸”ë¡ ì •ì œ
            if isinstance(message.content, list):
                sanitized_content = []
                for block in message.content:
                    if isinstance(block, dict) and "text" in block:
                        sanitized_block = block.copy()
                        sanitized_block["text"] = _sanitize_extended_thinking_tokens(block["text"])
                        sanitized_content.append(sanitized_block)
                    else:
                        sanitized_content.append(block)
                return {"role": "assistant", "content": sanitized_content}
            else:
                # ë¬¸ìì—´ì´ë©´ ì •ì œ í›„ text ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ê¸°
                sanitized_text = _sanitize_extended_thinking_tokens(message.content)
                return {"role": "assistant", "content": [{"text": sanitized_text}]}
        
        elif isinstance(message, SystemMessage):
            # BedrockëŠ” systemì„ ë³„ë„ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ userë¡œ ë³€í™˜í•˜ê±°ë‚˜ ì œê±°
            return {"role": "user", "content": [{"text": f"[System] {message.content}"}]}
        
        elif isinstance(message, ToolMessage):
            # ToolMessageëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (HumanMessage with toolResult ì‚¬ìš©)
            logger.warning(f"[{self.name}] ToolMessage deprecated, use HumanMessage with toolResult")
            return {"role": "user", "content": [{"text": message.content}]}
        
        else:
            return {"role": "user", "content": [{"text": str(message)}]}
    
    def _convert_messages_to_dict(self, messages: List) -> List[Dict[str, str]]:
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ì¼ê´„ ë³€í™˜
        
        Args:
            messages: LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[Dict[str, str]]: ë³€í™˜ëœ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        return [self._langchain_to_dict(msg) for msg in messages]
        
    # =============================
    # Message í¬ë§·íŒ… ë° LLM í˜¸ì¶œ (Debugìš©)
    # =============================
    def _pretty_messages(self, messages: List) -> str:
        """LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ë¬¸ìì—´ë¡œ ì˜ˆì˜ê²Œ ë³€í™˜
        
        Args:
            messages: LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            str: JSON í˜•íƒœì˜ ë¬¸ìì—´
        """
        converted = self._convert_messages_to_dict(messages)
        return json.dumps(converted, ensure_ascii=False, indent=2)

    def _prepare_llm_params(
        self,
        use_agent_config: bool = True,
        stream: Optional[bool] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """LLM í˜¸ì¶œ íŒŒë¼ë¯¸í„° ì¤€ë¹„
        
        Args:
            use_agent_config: Agent ì„¤ì • ì‚¬ìš© ì—¬ë¶€
            stream: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
            format: ì‘ë‹µ í¬ë§·
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
            
        Returns:
            Dict[str, Any]: ì¤€ë¹„ëœ LLM íŒŒë¼ë¯¸í„°
        """
        # Agent ì„¤ì • ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ê¸°ë³¸ê°’ ì„¤ì •
        if use_agent_config:
            llm_params = {**self.llm_config, **kwargs}
        else:
            llm_params = {**kwargs}
        
        # stream ëª…ì‹œì  ì²˜ë¦¬
        if stream is not None:
            llm_params["stream"] = stream
            
        return llm_params
    
    def _call_llm(
        self,
        messages: List,
        stream: Optional[bool] = None,
        **kwargs
    ) -> str:
        """LLM í˜¸ì¶œ (ë™ê¸° ë°©ì‹)
        
        ìš°ì„ ìˆœìœ„:
        1. ë©”ì„œë“œ í˜¸ì¶œ ì‹œ ì „ë‹¬ëœ kwargs
        2. Agentë³„ llm_config
        3. ì „ì—­ ì„¤ì • (LLMHelper ê¸°ë³¸ê°’)
        
        Args:
            messages: LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            stream: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
            **kwargs: ì¶”ê°€ LLM íŒŒë¼ë¯¸í„°
            
        Returns:
            str: LLM ì‘ë‹µ
        """
        llm_params = self._prepare_llm_params(
            use_agent_config=True,
            stream=stream,
            **kwargs
        )
        
        logger.debug(f"[{self.name}] LLM Call Parameters: {llm_params}")
        
        # LangChain ë©”ì‹œì§€ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        formatted_messages = self._convert_messages_to_dict(messages)
        
        return LLMHelper.invoke_with_history(
            history=formatted_messages,
            **llm_params
        )
        


    # =============================
    # ìƒíƒœ ê´€ë¦¬ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _add_message_to_state(self, state: AgentState, message) -> AgentState:
        """ìƒíƒœì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ê³  global_messages ì—…ë°ì´íŠ¸
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            message: ì¶”ê°€í•  LangChain ë©”ì‹œì§€
            
        Returns:
            AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        global_messages = state.get("global_messages", [])
        global_messages.append(message)
        state["global_messages"] = global_messages
        return state

    # =============================
    # ë©€í‹°í„´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
    # =============================
    
    async def run(self, state: AgentState) -> AgentState:
        """Agent ì‹¤í–‰ ë©”ì¸ í”Œë¡œìš°"""
        self._log_start(state)

        if not self.validate_input(state):
            error = ValueError(f"Invalid input for {self.name}")
            state = StateBuilder.add_error(state, error, self.name)
            state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
            return state
        
        # Agent ì§„ì… ì‹œ iteration ì´ˆê¸°í™”
        state["iteration"] = 0
        logger.info(f"[{self.name}] Iteration reset to 0 for this agent")

        state = self.pre_execute(state)

        for attempt in range(1, self.config.max_retries + 1):
            try:
                async with asyncio.timeout(self.config.timeout):
                    result = await self.execute_multi_turn(state)
                break
                
            except asyncio.TimeoutError:
                error_msg = f"Timeout after {self.config.timeout} seconds"
                logger.warning(f"[{self.name}] attempt {attempt} failed: {error_msg}")
                
                if attempt == self.config.max_retries:
                    error = TimeoutError(f"{self.name} execution timed out")
                    state = StateBuilder.add_error(state, error, self.name)
                    state = StateBuilder.finalize_state(state, ExecutionStatus.TIMEOUT)
                    return state
                
                await asyncio.sleep(1.5 * attempt)
                
            except Exception as e:
                logger.warning(f"[{self.name}] attempt {attempt} failed: {e}")
                
                if attempt == self.config.max_retries:
                    state = StateBuilder.add_error(state, e, self.name)
                    state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
                    return state
                
                await asyncio.sleep(1.5 * attempt)

        self._log_end(result)
        return result

    # =============================
    # ë©€í‹°í„´ ì‹¤í–‰ ë¡œì§ (ReAct Loop)
    # =============================
    
    async def execute_multi_turn(self, state: AgentState) -> AgentState:
        """ë©€í‹°í„´ ì‹¤í–‰ í”Œë¡œìš° - global_messages ì‚¬ìš©"""
        
        # RESPONDING ìƒíƒœë¡œ ì¬ì§„ì…í•œ ê²½ìš° ì²˜ë¦¬
        if state.get("status") == ExecutionStatus.RESPONDING:
            logger.info(f"[{self.name}] âš™ï¸ Re-entered for post-processing (status: RESPONDING)")
            
            # requires_post_processing í”Œë˜ê·¸ ì œê±°
            state.pop("requires_post_processing", None)
            
            # ìƒíƒœë¥¼ SUCCESSë¡œ ë³€ê²½í•˜ì—¬ ì¢…ë£Œ ì¤€ë¹„
            # ì£¼ì˜: ì—¬ê¸°ì„œëŠ” ìƒíƒœë§Œ RUNNINGìœ¼ë¡œ ë³€ê²½í•˜ê³ , ì‹¤ì œ Tool í˜¸ì¶œì€ LLMì—ê²Œ ë§¡ê¹€
            state["status"] = ExecutionStatus.RUNNING
            logger.info(f"[{self.name}] Status changed to RUNNING for post-processing")
            
            # í›„ì²˜ë¦¬ Toolì„ í˜¸ì¶œí•˜ë„ë¡ LLMì—ê²Œ ì§€ì‹œ
            # AgentëŠ” ì´ì œ í•„ìš”í•œ MCP Tool(ì˜ˆ: save_to_db)ì„ í˜¸ì¶œí•˜ê³ ,
            # ì™„ë£Œ í›„ respond_finalë¡œ ì¢…ë£Œí•´ì•¼ í•¨
        
        # global_messages ì‚¬ìš© (ì—†ìœ¼ë©´ messagesë¡œ í´ë°±)
        global_messages = state.get("global_messages", [])
        if not global_messages:
            global_messages = state.get("messages", [])
            state["global_messages"] = global_messages
        
        logger.info(f"[{self.name}] Global messages count: {len(global_messages)}")
        
        # í˜„ì¬ ì—ì´ì „íŠ¸ì˜ ì—­í• ì„ SystemMessageë¡œ ë§¨ ì•ì— ì¶”ê°€
        agent_role = self.get_agent_role_prompt()
        system_msg = SystemMessage(content=agent_role)
        
        # ë§¨ ì•ì— SystemMessage ì‚½ì…
        global_messages = [system_msg] + global_messages
        state["global_messages"] = global_messages
        
        logger.info(f"[{self.name}] âœ… Added agent role as SystemMessage at the beginning")
        
        # MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ
        available_tools = await self._list_mcp_tools()
        logger.info(f"[{self.name}] MCP tools available: {len(available_tools)}")
                
        # Bedrock toolConfigë¡œ ë³€í™˜
        bedrock_tool_config = self._convert_mcp_to_bedrock_toolspec(available_tools)
        if bedrock_tool_config:
            state["bedrock_tool_config"] = bedrock_tool_config
            logger.info(f"[{self.name}] âœ… Bedrock toolConfig created with {len(bedrock_tool_config['tools'])} tools")
            # ğŸ› ï¸ ëª¨ë“  tool ì´ë¦„ì„ ì¶”ì¶œ (MCP + respond_intermediate + delegate)
            tool_names = [t["toolSpec"]["name"] for t in bedrock_tool_config["tools"]]
        else:
            logger.warning(f"[{self.name}] âš ï¸ No Bedrock toolConfig created")
            tool_names = []

        
        # ReAct Loop
        while not StateBuilder.is_max_iterations_reached(state):
            state = StateBuilder.increment_iteration(state)
            current_iteration = state.get("iteration", 0)
            
            logger.info(f"\n{'='*60}")
            logger.info(f"[{self.name}] Iteration {current_iteration}/{self.max_iterations}")
            logger.info(f"{'='*60}")
            
            # global_messagesë¥¼ ì‚¬ìš©
            global_messages = state.get("global_messages", [])
            
            # Bedrock native tool calling: 1ë‹¨ê³„ë¡œ í†µí•©
            # _analyze_request ì œê±° â†’ _make_decisionì—ì„œ stopReasonìœ¼ë¡œ íŒë‹¨
            try:
                # logger.info("ğŸ¤” Making Decision (Bedrock native tool calling)\n" + self._pretty_messages(global_messages))
                logger.info("ğŸ¤” Making Decision (Bedrock native tool calling)\n")
                
                # âœ… ê¸°ì¡´ì— ì¶”ì¶œí•œ tool_names (MCP + delegate + respond_intermediate) ì‚¬ìš©
                decision = await self._make_decision(state, global_messages, tool_names)
                
                logger.info(f"ğŸ¤” Decision: {decision.action.value}")
                logger.info(f"   Reasoning: {decision.reasoning}")
                
            except Exception as e:
                logger.error(f"[{self.name}] Decision making failed: {e}")

                state = StateBuilder.add_error(state, e, self.name)
                break
            
            # Step 3: ì•¡ì…˜ ì‹¤í–‰
            if decision.action == AgentAction.USE_TOOL:
                state = await self._execute_tool_action(state, decision)
                continue
            
            elif decision.action == AgentAction.DELEGATE:
                return await self._execute_delegate_action(state, decision)
                
            elif decision.action == AgentAction.RESPOND:
                return await self._execute_respond_action(state, global_messages, available_tools, decision)
        
        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬
        return await self._handle_max_iterations(state, global_messages)
    
    # =============================
    # ì•¡ì…˜ ì‹¤í–‰ ë©”ì„œë“œ
    # =============================
    
    async def _execute_tool_action(
        self,
        state: AgentState,
        decision: AgentDecision
    ) -> AgentState:
        """Tool ì‹¤í–‰ ì•¡ì…˜ ì²˜ë¦¬ - ì—¬ëŸ¬ toolì´ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ë§Œ ì‹¤í–‰"""
        
        # âœ… ì—¬ëŸ¬ toolì´ ìˆìœ¼ë©´ ëª¨ë‘ ê°€ì ¸ì˜¤ê¸°
        tool_calls = decision.tool_calls if decision.tool_calls else [{
            "name": decision.tool_name,
            "arguments": decision.tool_arguments,
            "tool_use_id": decision.tool_use_id
        }]
        
        total_tools = len(tool_calls)
        logger.info(f"ğŸ”§ Total {total_tools} tool(s) requested")
        
        # âœ… ì²« ë²ˆì§¸ toolë§Œ ì‹¤í–‰
        first_tool = tool_calls[0]
        logger.info(f"ğŸ”§ Executing tool 1/{total_tools}: {first_tool['name']}")
        logger.info(f"   Arguments: {first_tool['arguments']}")
        
        tool_results = []
        
        # ì²« ë²ˆì§¸ tool ì‹¤í–‰
        try:
            tool_result = await self._execute_mcp_tool(
                first_tool["name"],
                first_tool["arguments"]
            )
            
            state = StateBuilder.add_tool_call(
                state,
                tool_name=first_tool["name"],
                arguments=first_tool["arguments"],
                result=tool_result
            )
            
            # JSON ì§ë ¬í™”
            import json
            if isinstance(tool_result, dict):
                result_content = json.dumps(tool_result, ensure_ascii=False)
            else:
                result_content = str(tool_result)
            
            # âœ… ì²« ë²ˆì§¸ toolì˜ ì‹¤ì œ ê²°ê³¼ ì¶”ê°€
            tool_results.append({
                "toolResult": {
                    "toolUseId": first_tool["tool_use_id"],
                    "content": [{"text": result_content}]
                }
            })
            
            logger.info(f"âœ… Tool 1/{total_tools} executed successfully")
            
        except Exception as e:
            logger.error(f"[{self.name}] Tool execution failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
            
            # âœ… ì—ëŸ¬ ì‘ë‹µ
            tool_results.append({
                "toolResult": {
                    "toolUseId": first_tool["tool_use_id"],
                    "content": [{"text": f"Error: {str(e)}"}],
                    "status": "error"
                }
            })
        
        # âœ… ë‚˜ë¨¸ì§€ toolë“¤ì— ëŒ€í•´ "ì•„ì§ ì‹¤í–‰ ì•ˆ í•¨" ì‘ë‹µ ìƒì„±
        if total_tools > 1:
            logger.info(f"â³ Deferring remaining {total_tools - 1} tool(s) to next iteration")
            
            for i, tool in enumerate(tool_calls[1:], start=2):
                logger.info(f"   Tool {i}/{total_tools}: {tool['name']} (deferred)")
                
                tool_results.append({
                    "toolResult": {
                        "toolUseId": tool["tool_use_id"],
                        "content": [{
                            "text": json.dumps({
                                "status": "deferred",
                                "message": f"ì´ ë„êµ¬ëŠ” ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ì „ ë„êµ¬({first_tool['name']})ì˜ ê²°ê³¼ë¥¼ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”.",
                                "tool_name": tool["name"],
                                "pending_arguments": tool["arguments"]
                            }, ensure_ascii=False)
                        }]
                    }
                })
        
        # âœ… ëª¨ë“  toolResultë¥¼ í•˜ë‚˜ì˜ User ë©”ì‹œì§€ë¡œ ì¶”ê°€
        tool_result_message = HumanMessage(content=tool_results)
        state = self._add_message_to_state(state, tool_result_message)
        
        logger.info(f"âœ… Tool execution completed: 1 executed, {total_tools - 1} deferred")
        
        return state
    
    async def _execute_delegate_action(
        self,
        state: AgentState,
        decision: AgentDecision
    ) -> AgentState:
        """Delegate ì•¡ì…˜ ì²˜ë¦¬
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            decision: Agent ì˜ì‚¬ê²°ì • ê²°ê³¼
            
        Returns:
            AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        logger.info(f"ğŸ”€ Delegating to agent: {decision.next_agent}")
        logger.info(f"   Reason: {decision.reasoning}")
        
        # delegation ë©”íƒ€ë°ì´í„° ì„¤ì •
        state["previous_agent"] = self.name
        state["next_agent"] = decision.next_agent
        state["delegation_reason"] = decision.reasoning
        state["status"] = ExecutionStatus.RUNNING
        state["timestamp"] = datetime.now()
        
        global_messages = state.get("global_messages", [])
        logger.info(f"[{self.name}] Delegation: next_agent={state.get('next_agent')}, status={state.get('status')}")
        logger.info(f"[{self.name}] âœ… Full conversation history preserved ({len(global_messages)} messages)")
        
        return state
    
    async def _execute_respond_action(
        self,
        state: AgentState,
        global_messages: List,
        available_tools: List[str],
        decision: AgentDecision
    ) -> AgentState:
        """Respond ì•¡ì…˜ ì²˜ë¦¬
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            global_messages: ì „ì—­ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            available_tools: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡
            decision: Agent ì˜ì‚¬ê²°ì • ê²°ê³¼
            
        Returns:
            AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        logger.info("âœ… Processing response action")
        
        try:
            # í›„ì²˜ë¦¬ í•„ìš” ì—¬ë¶€ì— ë”°ë¼ ìƒíƒœ ë¶„ê¸°
            if decision.requires_post_processing:
                # ì¤‘ê°„ ë‹¨ê³„: ì‘ë‹µ ì €ì¥í•˜ì§€ ì•Šê³  RESPONDING ìƒíƒœë¡œ ì„¤ì •
                # (ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ì§€ ì•ŠìŒ)
                state["status"] = ExecutionStatus.RESPONDING
                state["requires_post_processing"] = True
                logger.info(f"[{self.name}] âš™ï¸ Intermediate stage - RESPONDING (no response saved)")
                logger.info(f"[{self.name}] Router will re-enter this agent for post-processing")
                logger.info(f"[{self.name}] Reason: {decision.reasoning}")
            else:
                # ìµœì¢… ì‘ë‹µ: end_turnì„ í†µí•œ ì‘ë‹µ
                final_response = decision.response_text
                
                if not final_response:
                    logger.error(f"[{self.name}] No response_text in decision")
                    raise ValueError("response_text is required for final RESPOND action")
                
                logger.info(f"[{self.name}] Response ready ({len(final_response)} chars)")
                
                state["last_result"] = final_response
                
                # ì‘ë‹µì„ global_messagesì— ì¶”ê°€
                state = self._add_message_to_state(state, AIMessage(content=final_response))
                
                # ìµœì¢… ì‘ë‹µ: SUCCESSë¡œ ì¢…ë£Œ
                state = StateBuilder.finalize_state(state, ExecutionStatus.SUCCESS)
                logger.info(f"[{self.name}] âœ… Final response saved and finalized with SUCCESS")
            
            logger.info(f"[{self.name}] Total messages: {len(state.get('global_messages', []))}")
            logger.info(f"ğŸ’¬ Response action processed")
            
        except Exception as e:
            logger.error(f"[{self.name}] Response processing failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
            state = StateBuilder.finalize_state(state, ExecutionStatus.FAILED)
        
        return state
    
    async def _handle_max_iterations(
        self,
        state: AgentState,
        global_messages: List
    ) -> AgentState:
        """ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ ì²˜ë¦¬
        
        Args:
            state: í˜„ì¬ ìƒíƒœ
            global_messages: ì „ì—­ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        logger.warning(f"âš ï¸ Max iterations ({self.max_iterations}) reached")
        
        try:
            fallback_response = await self._generate_fallback_response(global_messages)
            state = self._add_message_to_state(state, AIMessage(content=fallback_response))
            state["last_result"] = fallback_response
        except Exception as e:
            logger.error(f"[{self.name}] Fallback response generation failed: {e}")
            state = StateBuilder.add_error(state, e, self.name)
        
        state = StateBuilder.finalize_state(state, ExecutionStatus.MAX_ITERATIONS)
        return state


    # =============================
    # Agent React Function ë‹¨ê³„ë³„ ë©”ì„œë“œ
    # =============================
    async def _make_decision(
        self,
        state: AgentState,
        messages: List,
        available_tools: List[str],
    ) -> AgentDecision:
        available_agents = self._get_available_agents()
        user_id = state.get("user_id", "test_user_1")
        
        # âœ… Tool ì´ë¦„ì„ bullet listë¡œ í¬ë§·íŒ…
        if available_tools:
            tools_formatted = "\n".join([f"     - {tool}" for tool in available_tools])
        else:
            tools_formatted = "     - (ì—†ìŒ)"
        
        system_prompt = DECISION_PROMPT.format(
            name=self.name,
            user_id=user_id,
            available_agents=available_agents,
            available_tools=tools_formatted
        )
        
        try:
            logger.info(f"[{self.name}] ğŸ¤” Making decision with Bedrock Native Tool Calling")
        
            messages.append(HumanMessage(content=system_prompt))
            state["global_messages"] = messages
            
            bedrock_tool_config = state.get("bedrock_tool_config")
            if not bedrock_tool_config:
                raise Exception("bedrock_tool_config not found in state")
            
            formatted_messages = self._convert_messages_to_dict(messages)
            
            from core.llm.llm_manger import LLMHelper
            response = await asyncio.to_thread(
                LLMHelper.invoke_with_history,
                history=formatted_messages,
                tool_config=bedrock_tool_config,
                tool_choice={"auto": {}},
                return_full_response=True,
                temperature=0.1,
                top_p=0.1
            )
            
            stop_reason = response.get("stopReason")
            logger.info(f"[{self.name}] stopReason: {stop_reason}")
            
            # end_turn ì²˜ë¦¬
            if stop_reason == "end_turn":
                message = response.get("output", {}).get("message", {})
                content_blocks = message.get("content", [])
                
                response_text = ""
                for block in content_blocks:
                    if "text" in block:
                        response_text = block["text"]
                        break
                
                logger.info(f"[{self.name}] âœ… Final response via end_turn")
                
                # âœ… Assistant ì‘ë‹µ ì¶”ê°€
                messages.append(AIMessage(content=response_text))
                state["global_messages"] = messages
                
                return AgentDecision(
                    action=AgentAction.RESPOND,
                    reasoning="Final response without post-processing",
                    response_text=response_text,
                    requires_post_processing=False
                )
            
            if stop_reason != "tool_use":
                logger.error(f"[{self.name}] Unexpected stopReason: {stop_reason}")
                raise Exception(f"Unexpected stopReason: '{stop_reason}'")
            
            # âœ… Assistant ë©”ì‹œì§€ ì „ì²´ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            message = response["output"]["message"]
            content = message.get("content", [])

            # reasoningContent í•„í„°ë§
            filtered_content = [
                block for block in content 
                if not isinstance(block, dict) or "reasoningContent" not in block
            ]
            
            if not filtered_content:
                filtered_content = content

            # âœ… toolUse.nameì„ sanitize (Bedrock ì •ê·œì‹: [a-zA-Z0-9_-]+)
            for block in filtered_content:
                if isinstance(block, dict) and "toolUse" in block:
                    tool_use = block["toolUse"]
                    tool_name_raw = tool_use.get("name", "")
                    
                    # ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°
                    tool_name_clean = tool_name_raw.split('<')[0].split('|')[0].strip()
                    # ì¶”ê°€ ì •ê·œì‹ ê²€ì¦: í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¬¸ì ì œê±°
                    tool_name_clean = re.sub(r'[^a-zA-Z0-9_-]', '', tool_name_clean)
                    
                    if tool_name_clean != tool_name_raw:
                        logger.warning(f"[{self.name}] âš ï¸ Sanitized toolUse.name in message: '{tool_name_raw}' â†’ '{tool_name_clean}'")
                        tool_use["name"] = tool_name_clean

            # âœ… í•„í„°ë§ëœ contentë¡œ AIMessage ìƒì„±í•˜ì—¬ ì¶”ê°€
            messages.append(AIMessage(content=filtered_content))
            state["global_messages"] = messages
            
            # âœ… ëª¨ë“  toolUse ë¸”ë¡ ìˆ˜ì§‘
            tool_calls = []
            for block in filtered_content:
                if "toolUse" in block:
                    tool_use = block["toolUse"]
                    tool_name_raw = tool_use["name"]
                    tool_input = tool_use.get("input", {})
                    tool_use_id = tool_use["toolUseId"]
                    
                    tool_name = tool_name_raw.split('<')[0].split('|')[0].strip()
                    
                    if tool_name != tool_name_raw:
                        logger.warning(f"[{self.name}] âš ï¸ Tool name sanitized: '{tool_name_raw}' â†’ '{tool_name}'")
                    
                    tool_calls.append({
                        "name": tool_name,
                        "arguments": tool_input,
                        "tool_use_id": tool_use_id
                    })
            
            if not tool_calls:
                logger.error(f"[{self.name}] No toolUse block found")
                raise Exception("No toolUse block found despite stopReason='tool_use'")
            
            logger.info(f"[{self.name}] Found {len(tool_calls)} tool call(s)")
            
            # âœ… ì²« ë²ˆì§¸ toolë¡œ ê¸°ë³¸ ì •ë³´ ì„¤ì •
            first_tool = tool_calls[0]
            
            logger.info(f"[{self.name}] ğŸ”§ Primary tool: {first_tool['name']}")
            logger.info(f"[{self.name}] ğŸ“‹ Tool input: {first_tool['arguments']}")
            
            # respond_intermediate
            if first_tool["name"] == "respond_intermediate":
                reason = first_tool["arguments"].get("reason", "Additional work required")
                logger.info(f"[{self.name}] âš™ï¸ Intermediate stage")
                
                return AgentDecision(
                    action=AgentAction.RESPOND,
                    reasoning=reason,
                    response_text="",
                    requires_post_processing=True,
                    tool_use_id=first_tool["tool_use_id"],
                    tool_calls=tool_calls  # âœ… ëª¨ë“  tool ì „ë‹¬
                )
            
            # delegate
            elif first_tool["name"] == "delegate":
                agent_name = first_tool["arguments"].get("agent_name")
                reason = first_tool["arguments"].get("reason", "")
                
                logger.info(f"[{self.name}] ğŸ”€ Delegating to: {agent_name}")
                
                return AgentDecision(
                    action=AgentAction.DELEGATE,
                    reasoning=reason,
                    next_agent=agent_name,
                    tool_use_id=first_tool["tool_use_id"],
                    tool_calls=tool_calls  # âœ… ëª¨ë“  tool ì „ë‹¬
                )
            
            # ì¼ë°˜ MCP Tool
            else:
                return AgentDecision(
                    action=AgentAction.USE_TOOL,
                    reasoning="Bedrock native tool calling",
                    tool_name=first_tool["name"],
                    tool_arguments=first_tool["arguments"],
                    tool_use_id=first_tool["tool_use_id"],
                    tool_calls=tool_calls  # âœ… ëª¨ë“  tool ì „ë‹¬
                )
                
        except Exception as e:
            logger.error(f"[{self.name}] Decision making failed: {e}")
            raise
        
    async def _generate_fallback_response(self, messages: List) -> str:
        """ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ í´ë°± ì‘ë‹µ ìƒì„±
        
        Args:
            messages: LangChain ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            str: í´ë°± ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        return f"""ì²˜ë¦¬ ê³¼ì •ì´ ì˜ˆìƒë³´ë‹¤ ë³µì¡í•˜ì—¬ {self.max_iterations}íšŒ ë°˜ë³µ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.
ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."""

    # =============================
    # êµ¬ì²´ì ì¸ Agentê°€ êµ¬í˜„í•´ì•¼ í•  ë©”ì„œë“œ
    # =============================
    
    @abstractmethod
    def get_agent_role_prompt(self) -> str:
        """Agent ì—­í•  ì •ì˜ Prompt ë°˜í™˜
        
        ê° AgentëŠ” ì´ ë©”ì„œë“œë¥¼ êµ¬í˜„í•˜ì—¬ ìì‹ ì˜ ì—­í• ì„ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.
        
        Returns:
            str: Agentì˜ ì—­í• ì„ ì„¤ëª…í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸
        """
        pass

    # =============================
    # ê³µí†µ í—¬í¼ ë©”ì„œë“œ
    # =============================
    
    def _get_available_agents(self) -> str:
        """í˜„ì¬ Agentì—ì„œ ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡ ë°˜í™˜
        
        allowed_agents ì†ì„±ì´ ìˆìœ¼ë©´ í•´ë‹¹ ëª©ë¡ì„ ì‚¬ìš©í•˜ê³ ,
        ì—†ìœ¼ë©´ ë“±ë¡ëœ ëª¨ë“  Agentë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        ìê¸° ìì‹ ì€ í•­ìƒ ëª©ë¡ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.
        
        Returns:
            str: ìœ„ì„ ê°€ëŠ¥í•œ Agent ëª©ë¡ì„ í¬í•¨í•˜ëŠ” í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
        """
        if hasattr(self, "allowed_agents"):
            # allowed_agentsê°€ ìˆì–´ë„ ìê¸° ìì‹ ì€ ë¬´ì¡°ê±´ ì œì™¸í•´ì•¼ í•¨
            agents = [name for name in self.allowed_agents if name != self.name]
        else:
            # ê¸°ë³¸: ëª¨ë“  ë“±ë¡ëœ Agent (ìì‹  ì œì™¸)
            from agents.registry.agent_registry import AgentRegistry
            all_agents = AgentRegistry.list_agents()
            agents = [name for name in all_agents if name != self.name]
            
        logger.info(f"{agents} available for delegation from {self.name}")
        
        if not agents:
            return f"""ì—†ìŒ (ì´ ì—ì´ì „íŠ¸ê°€ ëª¨ë“  ì‘ì—…ì„ ì§ì ‘ ì²˜ë¦¬í•´ì•¼ í•¨)

**ë‹¹ì‹ ì˜ ì •ì²´ì„±: {self.name}**
**ìœ„ì„ ë¶ˆê°€: ìê¸° ìì‹ ({self.name})ì—ê²ŒëŠ” ì ˆëŒ€ ìœ„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**"""
        
        # í¬ë§·íŒ…
        agent_list = "\n".join([f"- {agent}" for agent in agents])
        
        return f"""
[ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡]
{agent_list}

**ë‹¹ì‹ ì˜ ì •ì²´ì„±: {self.name}**
**ì£¼ì˜:** ìœ„ ëª©ë¡ì— ì—†ëŠ” Agent(íŠ¹íˆ ìê¸° ìì‹ ì¸ {self.name})ì—ê²ŒëŠ” ì ˆëŒ€ ìœ„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
"""
    
    def _get_available_agents_list(self) -> List[str]:
        """í˜„ì¬ Agentì—ì„œ ìœ„ì„ ê°€ëŠ¥í•œ ë‹¤ë¥¸ Agent ëª©ë¡ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        
        Bedrock toolSpecì˜ enumì— ì‚¬ìš©í•˜ê¸° ìœ„í•œ í—¬í¼ ë©”ì„œë“œ
        
        Returns:
            List[str]: ìœ„ì„ ê°€ëŠ¥í•œ Agent ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        if hasattr(self, "allowed_agents"):
            agents = [name for name in self.allowed_agents if name != self.name]
        else:
            from agents.registry.agent_registry import AgentRegistry
            all_agents = AgentRegistry.list_agents()
            agents = [name for name in all_agents if name != self.name]
        
        return agents
    
    async def _list_mcp_tools(self) -> List[Dict[str, Any]]:
        """MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ ë° í•„í„°ë§
        
        allowed_tools ì†ì„±ì„ í™•ì¸í•˜ì—¬ í—ˆìš©ëœ ë„êµ¬ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
        - 'ALL': ëª¨ë“  ë„êµ¬ í—ˆìš©
        - []: ë„êµ¬ ì—†ìŒ
        - [ë„êµ¬ëª… ëª©ë¡]: í•´ë‹¹ ë„êµ¬ë§Œ í—ˆìš©
        
        Returns:
            List[Dict[str, Any]]: ë„êµ¬ ëª…ì„¸ ë¦¬ìŠ¤íŠ¸ (function call í˜•ì‹)
        """
        try:
            tools = await self.mcp.list_tools()
            tools_spec = []
            
            if hasattr(self, "allowed_tools"):
                if self.allowed_tools == 'ALL':
                    pass  # ì „ì²´ íˆ´ í—ˆìš©
                elif len(self.allowed_tools) == 0:
                    tools = []  # íˆ´ ì—†ìŒ
                else:
                    tools = [t for t in tools if t.name in self.allowed_tools]

            for tool in tools:
                schema = tool.inputSchema or {}
                props = schema.get("properties", {})
                if not props:
                    continue
                tools_spec.append({
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "parameters": {
                            "type": schema.get("type", "object"),
                            "properties": {
                                k: {
                                    "type": p.get("type", "string"),
                                    "description": p.get("description", "")
                                } for k, p in props.items()
                            },
                            "required": schema.get("required", [])
                        },
                    },
                })
            logger.debug(f"[{self.name}] Retrieved {len(tools_spec)} tools")
            return tools_spec
        except Exception as e:
            logger.error(f"[{self.name}] Failed to list MCP tools: {e}")
            return []
    
    def _convert_mcp_to_bedrock_toolspec(
        self,
        mcp_tools: List[Dict[str, Any]]
    ) -> Optional[Dict]:
        """
        MCP tool specì„ Bedrock toolConfig í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³ ,
        respond_intermediate, delegate_to_agent Tool ì¶”ê°€
        
        MCPëŠ” OpenAI function call í˜•ì‹:
        {
            "type": "function",
            "function": {
                "name": "get_user",
                "description": "...",
                "parameters": {
                    "type": "object",
                    "properties": {...},
                    "required": [...]
                }
            }
        }
        
        BedrockëŠ” toolSpec í˜•ì‹:
        {
            "tools": [
                {
                    "toolSpec": {
                        "name": "get_user",
                        "description": "...",
                        "inputSchema": {
                            "json": {...}  # MCP parameters ê·¸ëŒ€ë¡œ
                        }
                    }
                }
            ]
        }
        
        Args:
            mcp_tools: _list_mcp_tools()ì—ì„œ ë°˜í™˜ëœ tool ëª©ë¡
            
        Returns:
            Bedrock toolConfig ë”•ì…”ë„ˆë¦¬
        """
        bedrock_tools = []
        
        # 1. MCP Tools ë³€í™˜
        if mcp_tools:
            for tool in mcp_tools:
                func = tool.get("function", {})
                params = func.get("parameters", {})
                
                # descriptionì´ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆ ë˜ë¯€ë¡œ ê¸°ë³¸ê°’ ì œê³µ
                description = func.get("description", "").strip()
                if not description:
                    description = f"MCP tool: {func.get('name', 'unknown')}"
                
                bedrock_tools.append({
                    "toolSpec": {
                        "name": func.get("name"),
                        "description": description,
                        "inputSchema": {
                            "json": params
                        }
                    }
                })
        
        # 2. respond_intermediate Tool ì¶”ê°€
        bedrock_tools.append({
            "toolSpec": {
                "name": "respond_intermediate",
                "description": """ì¤‘ê°„ ë‹¨ê³„ ì‹ í˜¸. ì‚¬ìš©ìì—ê²Œ ìµœì¢… ì‘ë‹µì„ ì œê³µí•˜ê¸° ì „ì— ì¶”ê°€ ì‘ì—…(DB ì €ì¥, ë°ì´í„° ì²˜ë¦¬ ë“±)ì´ ë” í•„ìš”í•œ ê²½ìš° ì‚¬ìš©í•©ë‹ˆë‹¤.

ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ â†’ DB ì €ì¥ í•„ìš” â†’ ì €ì¥ í›„ ìµœì¢… ì‘ë‹µ
- ë°ì´í„° ì¡°íšŒ ì™„ë£Œ â†’ ì¶”ê°€ ê³„ì‚° í•„ìš” â†’ ê³„ì‚° í›„ ìµœì¢… ì‘ë‹µ
- ì¤‘ê°„ ê²°ê³¼ í™•ì¸ â†’ ê²€ì¦ í•„ìš” â†’ ê²€ì¦ í›„ ìµœì¢… ì‘ë‹µ

**ì¤‘ìš”**: 
- ì´ Tool ì‚¬ìš© í›„ í•„ìš”í•œ MCP Toolì„ í˜¸ì¶œí•˜ì—¬ ì‘ì—…ì„ ì™„ë£Œí•˜ì„¸ìš”
- ëª¨ë“  ì‘ì—… ì™„ë£Œ í›„ ìµœì¢… ì‘ë‹µì€ ë³„ë„ë¡œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤ (end_turn)
- ì´ Toolì€ "ì•„ì§ ì‘ì—…ì´ ë” í•„ìš”í•¨"ì„ ì•Œë¦¬ëŠ” ì‹ í˜¸ì¼ ë¿, ì‚¬ìš©ìì—ê²Œ ì§ì ‘ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤""",
                "inputSchema": {
                    "json": {
                        "type": "object",
                        "properties": {
                            "reason": {
                                "type": "string",
                                "description": "ì¶”ê°€ ì‘ì—…ì´ í•„ìš”í•œ ì´ìœ  (ì˜ˆ: 'DBì— ìƒë‹´ ë‚´ìš© ì €ì¥ í•„ìš”', 'í¬íŠ¸í´ë¦¬ì˜¤ ê³„ì‚° í›„ ì‘ë‹µ ìƒì„± í•„ìš”')"
                            }
                        },
                        "required": ["reason"]
                    }
                }
            }
        })
        
        # 3. delegate_to_agent Tool ì¶”ê°€
        available_agents = self._get_available_agents_list()
        if available_agents:
            bedrock_tools.append({
                "toolSpec": {
                    "name": "delegate",
                    "description": "ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—…ì„ ìœ„ì„í•©ë‹ˆë‹¤. í˜„ì¬ ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•  ìˆ˜ ì—†ê±°ë‚˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì „ë¬¸ì„±ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©í•©ë‹ˆë‹¤.",
                    "inputSchema": {
                        "json": {
                            "type": "object",
                            "properties": {
                                "agent_name": {
                                    "type": "string",
                                    "description": f"ìœ„ì„í•  ì—ì´ì „íŠ¸ ì´ë¦„. ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸: {', '.join(available_agents)}",
                                    "enum": available_agents
                                },
                                "reason": {
                                    "type": "string",
                                    "description": "ìœ„ì„ ì´ìœ  ë° ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸"
                                }
                            },
                            "required": ["agent_name", "reason"]
                        }
                    }
                }
            })
        
        logger.info(f"[{self.name}] âœ… Created Bedrock toolConfig: {len(bedrock_tools)} tools (MCP: {len(mcp_tools) if mcp_tools else 0}, respond_intermediate: 1, delegate: {1 if available_agents else 0})")
        
        return {
            "tools": bedrock_tools
        }

    async def _execute_mcp_tool(
        self,
        tool_name: str,
        tool_args: Dict[str, Any]
    ) -> Any:
        """MCP ë„êµ¬ ì‹¤í–‰
        
        Args:
            tool_name: ì‹¤í–‰í•  ë„êµ¬ ì´ë¦„
            tool_args: ë„êµ¬ ì¸ì ë”•ì…”ë„ˆë¦¬
            
        Returns:
            Any: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
            
        Raises:
            Exception: ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ
        """
        try:
            result = await self.mcp.call_tool(tool_name, tool_args)
            logger.info(f"[{self.name}] Tool '{tool_name}' Result : {result}")
            logger.info(f"[{self.name}] Tool '{tool_name}' executed successfully")
            return result
        except Exception as e:
            logger.error(f"[{self.name}] Tool '{tool_name}' execution failed: {e}")
            raise
    
    def _remove_think_tag(self, text: str) -> str:
        """</think> íƒœê·¸ ì œê±° ë° JSON ì¶”ì¶œ
        
        LLM ì‘ë‹µì—ì„œ <think> íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ìˆœìˆ˜í•œ JSONë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            str: íƒœê·¸ê°€ ì œê±°ëœ ê¹¨ë—í•œ í…ìŠ¤íŠ¸
        """
        # 1. </think>ê°€ ìˆë‹¤ë©´, ê·¸ ë’¤ì˜ ë‚´ìš©ë§Œ ì·¨í•©ë‹ˆë‹¤.
        if "</think>" in text:
            text = text.rsplit("</think>", 1)[-1]
        
        # 2. í˜¹ì‹œë¼ë„ <think>ë§Œ ìˆê³  ë‹«ëŠ” íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì•ˆì „ì¥ì¹˜ë¡œ ì‹œì‘ íƒœê·¸ ì²˜ë¦¬
        elif "<think>" in text:
            text = text.rsplit("<think>", 1)[-1]

        # 3. ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        # 4. ìˆœìˆ˜í•œ JSON ê°ì²´ë§Œ ì¶”ì¶œ (ì²« '{' ë¶€í„° ë§ˆì§€ë§‰ '}' ê¹Œì§€)
        start_idx = text.find("{")
        end_idx = text.rfind("}")
        
        if start_idx != -1 and end_idx != -1:
            text = text[start_idx : end_idx + 1]
        
        return text


    # =============================
    # ê¸°íƒ€ ê³µí†µ ë©”ì„œë“œ
    # =============================
    
    def validate_input(self, state: AgentState) -> bool:
        """ì…ë ¥ ìƒíƒœ ê²€ì¦"""
        if "messages" not in state or not isinstance(state["messages"], list):
            logger.error(f"[{self.name}] Invalid messages field")
            return False
        
        is_valid, error_msg = StateValidator.validate_execution_state(state)
        if not is_valid:
            logger.error(f"[{self.name}] Invalid execution state: {error_msg}")
            return False
        
        return True

    def pre_execute(self, state: AgentState) -> AgentState:
        """ì‹¤í–‰ ì „ ì „ì²˜ë¦¬"""
        return state

    def _validate_config(self):
        """ì„¤ì • ê²€ì¦"""
        if not self.config.name:
            raise ValueError("Agent name is required")

    def _log_start(self, state: AgentState):
        """ì‹¤í–‰ ì‹œì‘ ë¡œê¹…"""
        logger.info(f"[{self.name}] Starting execution")
        logger.info(f"   Session ID: {state.get('session_id', 'unknown')}")
        logger.info(f"   Messages: {len(state.get('messages', []))}")

    def _log_end(self, state: AgentState):
        """ì‹¤í–‰ ì™„ë£Œ ë¡œê¹…"""
        logger.info(f"[{self.name}] Execution completed")
        logger.info(f"   Final Status: {state.get('status', 'unknown')}")
        logger.info(f"   Iterations: {state.get('iteration', 0)}")
        logger.info(f"   Tool Calls: {len(state.get('tool_calls', []))}")