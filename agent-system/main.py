import asyncio
import logging
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_core.messages import HumanMessage

from agents.registry.agent_registry import AgentRegistry
from graph.builder.graph_builder import GraphBuilder
from core.llm.llm_manger import LLMManager
from core.logging.logger import setup_logger
from graph.factory import mk_graph

logger = setup_logger()
app = FastAPI(title="Multi-Agent Planner")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ê·¸ë˜í”„ ì´ˆê¸°í™”
# graph = create_graph()
graph = mk_graph("graph.yaml")  # UserRegistrationAgent í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•¨

class ChatRequest(BaseModel):
    message: str
    session_id: str = "default-session"

class ChatResponse(BaseModel):
    response: str

#ì˜ˆë„ ë³€ê²½í•´ì•¼ í• ë“¯
@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """Front â†’ LLM Graph â†’ Response"""
    if not graph:
        return ChatResponse(response="âŒ Agent graph is not initialized properly.")

    config = {"configurable": {"thread_id": request.session_id}}
    # # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    # initial_state = {
    #     "query": "ê³„íšì„ ìˆ˜ì •í•˜ê³  ì‹¶ì–´"
    # }
    try:
        logger.info(f"ìœ ì € ë©”ì‹œì§€ request : {request.message}")
        messages = [HumanMessage(content=request.message)]
        result = await graph.ainvoke(
            {"messages": messages},
            config=config
        )
        # result = await graph.ainvoke({"messages": [HumanMessage(content=request.message)]}, config=config)

        final_response = result.get("messages")

        if not final_response:
            return ChatResponse(response="ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if isinstance(final_response, list):
            # Simple join for now.
            final_response = " ".join(map(str, final_response))

        return ChatResponse(response=final_response)

    except Exception as e:
        logger.error(f"âŒ Chat processing failed: {e}")
        return ChatResponse(response=f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
@app.get("/")
async def root():
    return {"status": "ok", "message": "AI Agent API is running ğŸš€"}

# ----------------------------
# ì„œë²„ ì§ì ‘ ì‹¤í–‰ìš© (ì„ íƒ)
# ----------------------------
if __name__ == "__main__":
    import uvicorn

    logger.info("ğŸš€ Starting API Server on http://localhost:8080")
    uvicorn.run("main:app", host="0.0.0.0", port=8080, reload=True)