from state import AgentState
from llm.ollama_llm import ollama_llm
from langchain_core.messages import SystemMessage, HumanMessage

##########################################
###  LLM í™œìš©ì´ í•„ìš”í•œ ë…¸ë“œë“¤ì„ ì •ì˜í•˜ëŠ” íŒŒì¼   ###
##########################################

def compare_changes(state: AgentState):
    print("ğŸ” ë³€ë™ ì‚¬í•­ ë¹„êµ ì¤‘...")

    prompt = f"""
    ì•„ë˜ëŠ” ì´ì „ ë‹¬ ë°ì´í„°ì™€ ìƒˆë¡œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ì…ë‹ˆë‹¤.
    ë³€ë™ ì‚¬í•­ì„ ê°„ê²°í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.

    [ì´ì „ ë‹¬ ë°ì´í„°]: {state.get('report_data')}
    [ì£¼íƒ ì •ë³´]: {state.get('house_info')}
    [ì •ì±… ì •ë³´]: {state.get('policy_info')}
    [ì‹ ìš© ì •ë³´]: {state.get('credit_info')}
    """

    response = ollama_llm.invoke([
        SystemMessage(content="ë„ˆëŠ” ë°ì´í„° ë¶„ì„ê³¼ ë¦¬í¬íŠ¸ ìš”ì•½ì— ëŠ¥ìˆ™í•œ í•œêµ­ì–´ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼."),
        HumanMessage(content=prompt)
    ])

    state["comparison_result"] = response.content
    return state

